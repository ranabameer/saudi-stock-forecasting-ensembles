{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4dxrlBqpWtb1",
        "outputId": "99c75738-b511-49d8-dc81-d174063849de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'numpy' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pandas-ta\n",
            "  Downloading pandas_ta-0.4.71b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting numba==0.61.2 (from pandas-ta)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting numpy>=2.2.6 (from pandas-ta)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pandas>=2.3.2 (from pandas-ta)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas-ta) (4.67.1)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->pandas-ta)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting numpy>=2.2.6 (from pandas-ta)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas-ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas-ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas-ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.3.2->pandas-ta) (1.17.0)\n",
            "Downloading pandas_ta-0.4.71b0-py3-none-any.whl (240 kB)\n",
            "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, llvmlite, pandas, numba, pandas-ta\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: llvmlite\n",
            "\u001b[2K    Found existing installation: llvmlite 0.43.0\n",
            "\u001b[2K    Uninstalling llvmlite-0.43.0:\n",
            "\u001b[2K      Successfully uninstalled llvmlite-0.43.0\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: numba\n",
            "\u001b[2K    Found existing installation: numba 0.60.0\n",
            "\u001b[2K    Uninstalling numba-0.60.0:\n",
            "\u001b[2K      Successfully uninstalled numba-0.60.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [pandas-ta]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llvmlite-0.44.0 numba-0.61.2 numpy-2.2.6 pandas-2.3.3 pandas-ta-0.4.71b0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1dbf9eababcc46e79354677ca540e6c7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install numpy==1.24.4\n",
        "!pip install pandas-ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-UO7oi1xreG",
        "outputId": "baa36265-2387-4d1b-9975-fa791b7b755c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jUHUoanqkM5_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "from pandas import read_csv\n",
        "from pandas.core.frame import DataFrame\n",
        "#from tensorflow.keras.models import Model, Sequential,load_model\n",
        "#import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import split, array, dstack\n",
        "import math\n",
        "from math import sqrt\n",
        "import seaborn as sns\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Activation, Flatten, Dropout\n",
        "from keras.layers import LSTM , GRU\n",
        "from keras.optimizers import Adam\n",
        "import csv\n",
        "from scipy.stats import zscore\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from warnings import simplefilter\n",
        "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Blk_Izkxj2w"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-SHYsfcWRmw"
      },
      "source": [
        "### Company data feature engineering functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "27KNIpHvHgZd"
      },
      "outputs": [],
      "source": [
        "# fill missing values with a value at the same time one day ago\n",
        "def fill_missing2(values):\n",
        " one_day = 1\n",
        " for row in range(values.shape[0]):\n",
        "  for col in range(values.shape[1]):\n",
        "    if np.isnan(values[row, col]):\n",
        "     values[row, col] = values[row - one_day, col]\n",
        "\n",
        "def fill_missing(values):\n",
        "  return pd.DataFrame(values).fillna(method='ffill').values\n",
        "\n",
        "def normalized_df(df):\n",
        "    normalized_df=(df-df.mean())/df.std()\n",
        "    return normalized_df\n",
        "\n",
        "#def zlema(src, length):\n",
        "#    lag = round((length - 1) / 2)\n",
        "#    ema_data = src + (src - src[lag])\n",
        "#    zl= ta.ema(ema_data,length = 5)\n",
        "#    return zl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XowkDNfZca00"
      },
      "outputs": [],
      "source": [
        "def get_company_df(dataset,company_name,start_date):\n",
        "  company = dataset[(dataset['trading_name '] == company_name)]\n",
        "  new_date_range = pd.date_range(start=start_date, end=\"2020-03-05\", freq=\"D\")\n",
        "  company = company.reindex(new_date_range, fill_value=np.nan)\n",
        "  company = company.drop([\"symbol\",'name','trading_name ','sectoer'], axis='columns')\n",
        "  company.replace('?', np.nan, inplace=True)\n",
        "  company = company.astype('float32')\n",
        "  company[:] = fill_missing(company.values)\n",
        "  company['zg'],company['sg'],company['xg'],company['atr'] = ta.aberration(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['lower'],company['mid'],company['upper'] = ta.accbands(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['ad'] = ta.ad(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
        "  company['adosc'] = ta.adosc(high=company['high'],low= company['low'],volume=company['volume_traded '],close=company['close'],fast=1,slow=5)\n",
        "  # company['adx'],company['dmp'],company['dmn'] = ta.adx(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['alma'] = ta.alma(company['close'],length=5)\n",
        "  company['amat1'], company['amat2']= ta.amat(company['close'],length=5)\n",
        "  # company['ao'] = ta.ao(high=company['high'],low= company['low'],close=company['close'],fast=1,slow=5)\n",
        "  company['aobv1'],company['aobv2'],company['aobv3'],company['aobv4'],company['aobv5'],company['aobv6'],company['aobv7'] = ta.aobv(company['close'],company['volume_traded '])\n",
        "  # company['apo'] = ta.apo(company['close'],fast=1,slow=5)\n",
        "  company['aroon_up'],company['aroon_down'],company['aroon_osc'] = ta.aroon(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['atr']= ta.atr(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['bbands_lower'],company['bbands_mid'],company['bbands_upper'],company['bbands_bandwidth'],company['bbands_percent'] = ta.bbands(company['close'],length=5)\n",
        "  company['bias'] = ta.bias(company['close'],length=5)\n",
        "  company['bop']= ta.bop(open_=company['open'],high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['ar'],company['br']= ta.brar(open_ = company['open'],high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['cci']= ta.cci(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['cfo'] = ta.cfo(company['close'],length=5)\n",
        "  company['cg'] = ta.cg(company['close'],length=5)\n",
        "  company['chop']= ta.chop(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['cksp_long'], company['cksp_short']= ta.cksp(high=company['high'],low= company['low'],close=company['close'])\n",
        "  company['cmf']= ta.cmf(high=company['high'],low= company['low'],close=company['close'],volume = company['volume_traded '],open = company['open'],length=5)\n",
        "  company['cmo'] = ta.cmo(company['close'],length=5)\n",
        "  company['coppock'] = ta.coppock(company['close'],length=5,fast=6,slow=11)\n",
        "  company['cti'] = ta.cti(company['close'],length=5)\n",
        "  company['decay'] = ta.decay(company['close'],length=5)\n",
        "  company['decreasing'] = ta.decreasing(company['close'],length=5)\n",
        "  company['dema'] = ta.dema(company['close'],length=5)\n",
        "  company['dmp'],company['dmn']= ta.dm(high=company['high'],low= company['low'],length=5)\n",
        "  company['doncian_lower'],company['doncian_mid'],company['doncian_upper']= ta.donchian(high=company['high'],low= company['low'],lower_length=5,upper_length=5)\n",
        "  company['dpo'] = ta.dpo(company['close'],length=5)\n",
        "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
        "  company['efi'] = ta.efi(company['close'],company['volume_traded '],length=5)\n",
        "  company['ema'] = ta.ema(company['close'],length=5)\n",
        "  company['entropy'] = ta.entropy(company['close'],length=5)\n",
        "  company['eom']= ta.eom(high=company['high'],low= company['low'],close=company['close'],volume = company['volume_traded '],length=5)\n",
        "  company['er'] = ta.er(company['close'],length=5)\n",
        "  company['eri_bull'],company['eri_bear'] = ta.eri(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['fisher1'],company['fisher2'] = ta.fisher(high=company['high'],low= company['low'],length=5)\n",
        "  company['fwma'] = ta.fwma(company['close'],length=5)\n",
        "  company['hilo'],company['hilol'],company['hilos']=ta.hilo(close=company['close'],high=company['high'],low= company['low'],high_length=5,low_length=5)\n",
        "  company['hma'] = ta.hma(company['close'],length=5)\n",
        "  company['hl2'] = ta.hl2(company['high'],company['low'])\n",
        "  company['hlc3'] = ta.hlc3(company['high'],company['low'],company['close'])\n",
        "  # company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
        "  company['hwma '] = ta.dema(company['close'])\n",
        "  company['increasing'] = ta.increasing(company['close'],length=5)\n",
        "  company['inertia'] = ta.inertia(high=company['high'],low= company['low'],close=company['close'],open = company['open'],rvi_length=5,length=5)\n",
        "  company['jma'] = ta.jma(company['close'],length=5)\n",
        "  company['kama'] = ta.kama(company['close'],length=5)\n",
        "  company['kcl'],company['kcb'],company['kcu']= ta.kc(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['kdj1'],company['kdj2'],company['kdj3'] = ta.kdj(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['kurtosis'] = ta.kurtosis(company['close'],length=5)\n",
        "  company['kvo'],company['kvo_s'] = ta.kvo(high=company['high'],low= company['low'],close=company['close'],volume = company['volume_traded '])\n",
        "  company['linreg'] = ta.linreg(company['close'],length=5)\n",
        "  company['log_return'] = ta.log_return(company['close'],length=5)\n",
        "  company['macd'],company['macd_hist'],company['macd_sig'] = ta.macd(company['close'])\n",
        "  company['mad'] = ta.mad(company['close'],length=5)\n",
        "  company['massi'] = ta.massi(high=company['high'],low= company['low'],fast=1,slow=5)\n",
        "  company['median'] = ta.median(company['close'],length=5)\n",
        "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
        "  company['midpoint'] = ta.midpoint(company['close'],length=5)\n",
        "  company['midprice'] = ta.midprice(high=company['high'],low= company['low'],length=5)\n",
        "  company['mom'] = ta.mom(company['close'],length=5)\n",
        "  company['natr'] = ta.natr(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['nvi'] = ta.nvi(company['close'],company['volume_traded '],length=5)\n",
        "  company['obv'] = ta.obv(company['close'],company['volume_traded '])\n",
        "  company['pdist'] = ta.pdist(open_=company['open'],high=company['high'],low= company['low'],close=company['close'])\n",
        "  company['percent_return'] = ta.percent_return(company['close'],length=5)\n",
        "  company['pgo'] = ta.pgo(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['psl'] = ta.psl(company['close'],company['open'],length=5)\n",
        "  # company['pvi'] = ta.pvi(company['close'],company['volume_traded '],length=5)\n",
        "  company['pvol'] = ta.pvol(company['close'],company['volume_traded '])\n",
        "  company['pvt'] = ta.pvt(company['close'],company['volume_traded '])\n",
        "  company['pwma'] = ta.pwma(company['close'],length=5)\n",
        "  company['qqe'],company['rsi_ma'] ,company['qqel'] ,company['qqes']  = ta.qqe(company['close'],length=5)\n",
        "  company['qstick'] = ta.qstick(company['open'],company['close'],length=5)\n",
        "  company['quantile'] = ta.quantile(company['close'],length=5)\n",
        "  company['rma'] = ta.rma(company['close'],length=5)\n",
        "  company['roc'] = ta.roc(company['close'],length=5)\n",
        "  company['rsi'] = ta.rsi(company['close'],length=5)\n",
        "  company['rsx'] = ta.rsx(company['close'],length=5)\n",
        "  # company['rvgi1'],company['rvgi2'] = ta.rvgi(open_=company['open'],high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  #company['rvil'],company['rvib'],company['rviu'],company['rvi1'],company['rvi2'],company['rvi3'],company['rvi4'],company['rvi5'],company['rvi6'],company['rvi7'],company['rvi8'],company['rvi9'],company['rvi10'],company['rvi11'] = ta.rvi(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['sinwma'] = ta.sinwma(company['close'],length=5)\n",
        "  company['skew'] = ta.skew(company['close'],length=5)\n",
        "  company['slope'] = ta.slope(company['close'],length=5)\n",
        "  company['sma'] = ta.sma(company['close'],length=5)\n",
        "  company['smi'],company['smi_s'],company['smi_osc'] = ta.smi(company['close'])\n",
        "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
        "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
        "  company['stdev'] = ta.stdev(company['close'],length=5)\n",
        "  # company['stoch_k'],company['stoch_d'] = ta.momentum.stoch(high=company['high'],low= company['low'],close=company['close'])\n",
        "  company['stochrsi_k'],company['stochrsi_d']= ta.stochrsi(company['close'],length=5)\n",
        "  company['swma'] = ta.swma(company['close'],length=5)\n",
        "  company['t3'] = ta.t3(company['close'],length=5)\n",
        "  company['tema'] = ta.tema(company['close'],length=5)\n",
        "  company['trima'] = ta.trima(company['close'],length=5)\n",
        "  company['trix1'],company['trix2']  = ta.trix(company['close'],length=5)\n",
        "  company['true_range'] = ta.true_range(high=company['high'],low= company['low'],close=company['close'])\n",
        "  company['tema'] = ta.tema(company['close'],length=5)\n",
        "  company['ui'] = ta.ui(high=company['high'],close =company['close'],length=5)\n",
        "  company['uo'] = ta.uo(company['high'],company['low'],company['close'],fast=1,medium=3,slow=5)\n",
        "  company['variance'] = ta.variance(company['close'],length=5)\n",
        "  company['vhf'] = ta.vhf(company['close'],length=5)\n",
        "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
        "  company['vortex1'],company['vortex2'] = ta.vortex(company['high'],company['low'],company['close'],length=5)\n",
        "  # company['vp1'],company['vp2'],company['vp3'],company['vp4'],company['vp5'],company['vp6'] = ta.vp(company['close'],company['volume_traded '])\n",
        "  company['vwap'] = ta.vwap(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '])\n",
        "  company['vmwa'] = ta.vwma(volume=company['volume_traded '],close=company['close'],length=5)\n",
        "  company['wcp'] = ta.wcp(high=company['high'],low= company['low'],close=company['close'])\n",
        "  company['willr'] = ta.willr(high=company['high'],low= company['low'],close=company['close'],length=5)\n",
        "  company['wma'] = ta.wma(company['close'],length=5)\n",
        "  company['zlma'] = ta.zlma(company['close'],length=5)\n",
        "  company['zscore'] = ta.zscore(company['close'],length=5)\n",
        "  #company['zlema'] = zlema(company['close'],length=5)\n",
        "  company = company.fillna(0)\n",
        "  #selected features based on corrlation sheet\n",
        "  selected_ti = ['open','high','low','close','alma','decay','dema','ema','fwma','hma','hl2','hlc3','hwma ','jma','kama','linreg','median','midpoint','midprice','pwma','quantile','rma','sinwma','sma','ssf','swma','t3','tema','trima','vwap','vmwa','wcp','wma','zlma']\n",
        "  new_company_df =  company[selected_ti]\n",
        "  return new_company_df, selected_ti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkibQhFkXVab"
      },
      "source": [
        "### Company data prepration functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yluxk4_QLoT3"
      },
      "outputs": [],
      "source": [
        "# convert history into inputs and outputs\n",
        "def to_supervised(X, y, n_input, n_output):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - n_input - n_output + 1):\n",
        "        Xs.append(X.iloc[i:i+n_input].values)\n",
        "        ys.append(y.iloc[i+n_input:i+n_input+n_output].values)\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "def get_last_val_set_features(data):\n",
        "  # flatten data\n",
        "  X = list()\n",
        "  X.append(data.iloc[len(data)-5:, :])\n",
        "  return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7bjq76eAGSxv"
      },
      "outputs": [],
      "source": [
        "  def prepare_company_for_training_and_testing(company, selected_ti, target_col = 'close',\n",
        "                                              n_input=5, n_output=5):\n",
        "\n",
        "    # ===============================\n",
        "    # 1. Split data temporally\n",
        "    # ===============================\n",
        "    train = company.loc[:'2015-12-31']\n",
        "    val   = company.loc['2016-01-01':'2016-12-31']\n",
        "    test  = company.loc['2017-01-01':]\n",
        "\n",
        "    print(f'Train shape: {train.shape}, Val shape: {val.shape}, Test shape: {test.shape}')\n",
        "\n",
        "    # ===============================\n",
        "    # 2. Feature scaler (X)\n",
        "    # ===============================\n",
        "    feature_scaler = StandardScaler()\n",
        "    feature_scaler.fit(train[selected_ti])\n",
        "\n",
        "    train_x_scaled = DataFrame(\n",
        "        feature_scaler.transform(train[selected_ti]),\n",
        "        columns=selected_ti,\n",
        "        index=train.index\n",
        "    )\n",
        "\n",
        "    val_x_scaled = DataFrame(\n",
        "        feature_scaler.transform(val[selected_ti]),\n",
        "        columns=selected_ti,\n",
        "        index=val.index\n",
        "    )\n",
        "\n",
        "    test_x_scaled = DataFrame(\n",
        "        feature_scaler.transform(test[selected_ti]),\n",
        "        columns=selected_ti,\n",
        "        index=test.index\n",
        "    )\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Target scaler (y)\n",
        "    # ===============================\n",
        "    global target_scaler\n",
        "    target_scaler = StandardScaler()\n",
        "    target_scaler.fit(train[[target_col]])\n",
        "\n",
        "    train_y_scaled = DataFrame(\n",
        "        target_scaler.transform(train[[target_col]]),\n",
        "        columns=[target_col],\n",
        "        index=train.index\n",
        "    )\n",
        "\n",
        "    val_y_scaled = DataFrame(\n",
        "        target_scaler.transform(val[[target_col]]),\n",
        "        columns=[target_col],\n",
        "        index=val.index\n",
        "    )\n",
        "\n",
        "    test_y_scaled = DataFrame(\n",
        "        target_scaler.transform(test[[target_col]]),\n",
        "        columns=[target_col],\n",
        "        index=test.index\n",
        "    )\n",
        "\n",
        "    print(\"*******************************************\")\n",
        "    print(\"Train data after multistep approach\")\n",
        "\n",
        "    # ===============================\n",
        "    # 4. Supervised transformation\n",
        "    # ===============================\n",
        "    train_x, train_y = to_supervised(train_x_scaled, train_y_scaled,\n",
        "                                     n_input, n_output)\n",
        "\n",
        "    print(\"Validation multistep approach\")\n",
        "    val_x, val_y = to_supervised(val_x_scaled, val_y_scaled,\n",
        "                                 n_input, n_output)\n",
        "\n",
        "    print(\"Test multistep approach\")\n",
        "    test_x, test_y = to_supervised(test_x_scaled, test_y_scaled,\n",
        "                                   n_input, n_output)\n",
        "\n",
        "    return (\n",
        "        train_x, train_y,\n",
        "        val_x, val_y,\n",
        "        test_x, test_y,\n",
        "        test,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RxWj3V2c-ff"
      },
      "source": [
        "### Company prdiction prepration for ensemble function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9lUm8a0CKZLP"
      },
      "outputs": [],
      "source": [
        "def true_y_to_evaluation_form(y_true, n_input, n_out):\n",
        "  y = list()\n",
        "  for i in range(len(y_true) - n_input - n_out + 1):\n",
        "      y.append(y_true.iloc[i+n_input:i+n_input+n_out].values)\n",
        "  return np.array(y)\n",
        "\n",
        "# make a forecast\n",
        "def forecast(model, history):\n",
        "  yhat = model.predict(history, verbose=0)\n",
        "  return yhat\n",
        "\n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "  predicted_not_normlized = target_scaler.inverse_transform(predicted)\n",
        "  predicted_not_normlized_rounded = [np.round(num,2) for num in predicted_not_normlized]\n",
        "  print(\"Actual\",actual[1000])\n",
        "  print(\"Predicted_not_normlized\",predicted_not_normlized_rounded[1000])\n",
        "  mse_score= mse(actual,predicted_not_normlized_rounded)\n",
        "  rmse_score = sqrt(mse_score)\n",
        "  mae_score = mae(actual,predicted_not_normlized_rounded)\n",
        "  final_r2_score = r2_score(actual,predicted_not_normlized_rounded,multioutput='variance_weighted')\n",
        "  return mse_score, rmse_score,mae_score,final_r2_score,predicted_not_normlized_rounded\n",
        "\n",
        "# summarize scores\n",
        "def summarize_scores(name, mse_score, rmse_score,mae_score,final_r2_score):\n",
        "  #s_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "  #print('%s: [%.3f] %s' % (name, score, s_scores))\n",
        "  print(f'*************{name}**********')\n",
        "  print(\"MAE: \",mae_score)\n",
        "  print(\"MSE: \",mse_score)\n",
        "  print(\"RMSE: \",rmse_score)\n",
        "  print(\"R2: \",final_r2_score)\n",
        "\n",
        "# evaluate a single model\n",
        "def evaluate_model(test_x,test_y,model):\n",
        "\t# walk-forward validation over each week\n",
        "  predictions = list()\n",
        "  predictions = forecast(model, test_x)\n",
        "  # evaluate predictions days for each week\n",
        "  predictions = array(predictions)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score, y_hat_not_normlized = evaluate_forecasts(test_y, predictions)\n",
        "  return mse_score, rmse_score,mae_score,final_r2_score,y_hat_not_normlized\n",
        "\n",
        "# def load_all_models(n_models,company_name):\n",
        "#   import pickle\n",
        "#   all_models = list()\n",
        "#   all_models_orgnized = list()\n",
        "#   dirname = '/content/drive/MyDrive/KFUPM/Graduation/best_models/'+company_name\n",
        "#   for filename in os.listdir(dirname):\n",
        "#     root, ext = os.path.splitext(filename)\n",
        "#     if root.startswith(str(company_name)) and ext == '.pkl':\n",
        "#       with open(dirname+'/'+root+ext,'rb') as file:\n",
        "#         print(dirname+'/'+root+ext)\n",
        "#         model = pickle.load(file)\n",
        "\n",
        "#       #model_path = os.path.join(dirname,filename)\n",
        "#       # print(model_path)\n",
        "#       # model =tf.keras.models.load_model(model_path)\n",
        "#       all_models.append(model)\n",
        "#   return all_models\n",
        "\n",
        "def load_all_models(n_models, company_name):\n",
        "    all_models = []\n",
        "\n",
        "    # Define the order of the models\n",
        "    model_order = [\"BRNN\", \"GRU\", \"LSTM\"]\n",
        "\n",
        "    dirname = '/content/drive/MyDrive/KFUPM/Graduation/final_experiments/best_models/' + company_name\n",
        "\n",
        "    for filename in os.listdir(dirname):\n",
        "        root, ext = os.path.splitext(filename)\n",
        "        if root.startswith(str(company_name)) and ext == '.pkl':\n",
        "            with open(os.path.join(dirname, filename), 'rb') as file:\n",
        "                #print(os.path.join(dirname, filename))\n",
        "                model = pickle.load(file)\n",
        "                all_models.append((root, model))  # Store the root and model together\n",
        "\n",
        "    # Sort the models according to the predefined order\n",
        "    all_models_sorted = sorted(all_models, key=lambda x: model_order.index(x[0].split('_')[-2]))\n",
        "    print(\"**********Models Order***************\")\n",
        "    [print(x[0]) for x in all_models_sorted]\n",
        "    print(\"*************************************\")\n",
        "    # Extract the sorted models\n",
        "    all_models_sorted = [model for _, model in all_models_sorted]\n",
        "\n",
        "    return all_models_sorted\n",
        "\n",
        "# create stacked model input dataset as outputs from the ensemble\n",
        "def stacked_dataset(members, inputX):\n",
        "\tstackX = None\n",
        "\tfor model in members:\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.predict(inputX, verbose=0)\n",
        "\t\t# stack predictions into [rows, members, probabilities]\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = yhat #\n",
        "\t\telse:\n",
        "\t\t\tstackX = dstack((stackX, yhat))\n",
        "\t# flatten predictions to [rows, members x probabilities]\n",
        "\t#stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\treturn stackX\n",
        "\n",
        "def stacking_process(dataset,selected_companies_dic,company_name):\n",
        "  #Get company and selected TIs\n",
        "  company, company_selected_ti = get_company_df(dataset,selected_companies_dic[company_name][0],selected_companies_dic[company_name][1])\n",
        "  train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test = prepare_company_for_training_and_testing(company, company_selected_ti)\n",
        "  n_members = 3\n",
        "  members = load_all_models(n_members,company_name)\n",
        "  print('Loaded %d models' % len(members))\n",
        "  # # ANN\n",
        "  # train_eval_stacking_model(company_name,members,len(members),train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\", \"LSTM\"])\n",
        "  # train_eval_stacking_model(company_name,[members[0],members[1]] ,len(members)-1, train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\"])\n",
        "  # train_eval_stacking_model(company_name,[members[0],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"LSTM\"])\n",
        "  # train_eval_stacking_model(company_name,[members[1],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"GRU\", \"LSTM\"])\n",
        "  # # LSTM\n",
        "  # train_eval_stacking_model_lstm(company_name,members,len(members),train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\", \"LSTM\"])\n",
        "  # train_eval_stacking_model_lstm(company_name,[members[0],members[1]] ,len(members)-1, train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\"])\n",
        "  # train_eval_stacking_model_lstm(company_name,[members[0],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"LSTM\"])\n",
        "  # train_eval_stacking_model_lstm(company_name,[members[1],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"GRU\", \"LSTM\"])\n",
        "  # # GRU\n",
        "  # train_eval_stacking_model_gru(company_name,members,len(members),train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\", \"LSTM\"])\n",
        "  # train_eval_stacking_model_gru(company_name,[members[0],members[1]] ,len(members)-1, train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\"])\n",
        "  # train_eval_stacking_model_gru(company_name,[members[0],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"LSTM\"])\n",
        "  # train_eval_stacking_model_gru(company_name,[members[1],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"GRU\", \"LSTM\"])\n",
        "  # BiRNN\n",
        "  train_eval_stacking_model_birnn(company_name,members,len(members),train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\", \"LSTM\"])\n",
        "  train_eval_stacking_model_birnn(company_name,[members[0],members[1]] ,len(members)-1, train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"GRU\"])\n",
        "  train_eval_stacking_model_birnn(company_name,[members[0],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"BRNN\", \"LSTM\"])\n",
        "  train_eval_stacking_model_birnn(company_name,[members[1],members[2]],len(members)-1,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,[\"GRU\", \"LSTM\"])\n",
        "\n",
        "  # Define the model\n",
        "def train_eval_stacking_model(company_name,members,members_num,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,models_names):\n",
        "  # Shape: (samples, timesteps, features)\n",
        "  stacked_train = stacked_dataset(members, train_x_normlized)\n",
        "  stacked_val = stacked_dataset(members, val_x_normlized)\n",
        "  stacked_test = stacked_dataset(members, test_x_normlized)\n",
        "  model = Sequential()\n",
        "  # Input layer - Flatten the (timesteps, features) into a 1D vector\n",
        "  model.add(Flatten(input_shape=(5, members_num)))  # 5 timesteps and 3 features per timestep\n",
        "  # Hidden layers\n",
        "  model.add(Dense(128, activation='relu'))  # First hidden layer\n",
        "  model.add(Dense(64, activation='relu'))  # First hidden layer\n",
        "  model.add(Dense(32, activation='relu'))  # Second hidden layer\n",
        "  # Output layer - Regression example (single output for simplicity)\n",
        "  model.add(Dense(5))  # Adjust the output size based on your specific task\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # Model summary\n",
        "  model.summary()\n",
        "  model.fit(\n",
        "    stacked_train,\n",
        "    train_y_normlized,\n",
        "    epochs=100,\n",
        "    validation_data=(stacked_val,val_y_normlized))\n",
        "  predictions_normlized = model.predict(stacked_test)\n",
        "  test_y_for_evaluation = true_y_to_evaluation_form(test.iloc[:,3], 5, 5)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predictions = evaluate_model(stacked_test,test_y_for_evaluation,model)\n",
        "  separator = '_'  # Using a dash as the separator\n",
        "  models_names_str = separator.join(models_names)\n",
        "  pickle.dump(model , open(f'/content/drive/MyDrive/KFUPM/Graduation/best_models/{company_name}/{models_names_str}_meta_learner_ann' , 'wb'))\n",
        "  summarize_scores(f'Prposed ANN of {str(models_names)}', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "\n",
        "    # Define the model\n",
        "def train_eval_stacking_model_lstm(company_name,members,members_num,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,models_names):\n",
        "  # Shape: (samples, timesteps, features)\n",
        "  n_timesteps = 5\n",
        "  stacked_train = stacked_dataset(members, train_x_normlized)\n",
        "  stacked_val = stacked_dataset(members, val_x_normlized)\n",
        "  stacked_test = stacked_dataset(members, test_x_normlized)\n",
        "  # Define the model\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, activation='relu', input_shape=(n_timesteps, members_num)))\n",
        "  model.add(Dense(n_timesteps))  # n_outputs is the number of steps to forecast\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # Compile the model\n",
        "  # Model summary\n",
        "  model.summary()\n",
        "  model.fit(\n",
        "    stacked_train,\n",
        "    train_y_normlized,\n",
        "    epochs=100,\n",
        "    validation_data=(stacked_val,val_y_normlized))\n",
        "  predictions_normlized = model.predict(stacked_test)\n",
        "  test_y_for_evaluation = true_y_to_evaluation_form(test.iloc[:,3], 5, 5)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predictions = evaluate_model(stacked_test,test_y_for_evaluation,model)\n",
        "  separator = '_'  # Using a dash as the separator\n",
        "  models_names_str = separator.join(models_names)\n",
        "  pickle.dump(model , open(f'/content/drive/MyDrive/KFUPM/Graduation/best_models/{company_name}/{models_names_str}_meta_learner_lstm' , 'wb'))\n",
        "  summarize_scores(f'Prposed LSTM of {str(models_names)}', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "\n",
        "def train_eval_stacking_model_gru(company_name,members,members_num,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,models_names):\n",
        "  # Shape: (samples, timesteps, features)\n",
        "  n_timesteps = 5\n",
        "  stacked_train = stacked_dataset(members, train_x_normlized)\n",
        "  stacked_val = stacked_dataset(members, val_x_normlized)\n",
        "  stacked_test = stacked_dataset(members, test_x_normlized)\n",
        "  # Define the model\n",
        "  model = Sequential()\n",
        "  model.add(GRU(128, activation='relu', input_shape=(n_timesteps, members_num)))\n",
        "  model.add(Dense(n_timesteps))  # n_outputs is the number of steps to forecast\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # Compile the model\n",
        "  # Model summary\n",
        "  model.summary()\n",
        "  model.fit(\n",
        "    stacked_train,\n",
        "    train_y_normlized,\n",
        "    epochs=100,\n",
        "    validation_data=(stacked_val,val_y_normlized))\n",
        "  predictions_normlized = model.predict(stacked_test)\n",
        "  test_y_for_evaluation = true_y_to_evaluation_form(test.iloc[:,3], 5, 5)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predictions = evaluate_model(stacked_test,test_y_for_evaluation,model)\n",
        "  separator = '_'  # Using a dash as the separator\n",
        "  models_names_str = separator.join(models_names)\n",
        "  pickle.dump(model , open(f'/content/drive/MyDrive/KFUPM/Graduation/best_models/{company_name}/{models_names_str}_meta_learner_gru' , 'wb'))\n",
        "  summarize_scores(f'Prposed GRU of {str(models_names)}', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "\n",
        "def train_eval_stacking_model_birnn(company_name,members,members_num,train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test,models_names):\n",
        "  # Shape: (samples, timesteps, features)\n",
        "  n_timesteps = 5\n",
        "  stacked_train = stacked_dataset(members, train_x_normlized)\n",
        "  stacked_val = stacked_dataset(members, val_x_normlized)\n",
        "  stacked_test = stacked_dataset(members, test_x_normlized)\n",
        "  # Define the model\n",
        "  model = Sequential()\n",
        "  model.add(BRNN(128, activation='relu', input_shape=(n_timesteps, members_num)))\n",
        "  model.add(Dense(n_timesteps))  # n_outputs is the number of steps to forecast\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # Compile the model\n",
        "  # Model summary\n",
        "  model.summary()\n",
        "  model.fit(\n",
        "    stacked_train,\n",
        "    train_y_normlized,\n",
        "    epochs=100,\n",
        "    validation_data=(stacked_val,val_y_normlized))\n",
        "  predictions_normlized = model.predict(stacked_test)\n",
        "  test_y_for_evaluation = true_y_to_evaluation_form(test.iloc[:,3], 5, 5)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predictions = evaluate_model(stacked_test,test_y_for_evaluation,model)\n",
        "  separator = '_'  # Using a dash as the separator\n",
        "  models_names_str = separator.join(models_names)\n",
        "  pickle.dump(model , open(f'/content/drive/MyDrive/KFUPM/Graduation/best_models/{company_name}/{models_names_str}_meta_learner_gru' , 'wb'))\n",
        "  summarize_scores(f'Prposed GRU of {str(models_names)}', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "\n",
        "\n",
        "def averaging_process(dataset,selected_companies_dic,company_name):\n",
        "  #Get company and selected TIs\n",
        "  company, company_selected_ti = get_company_df(dataset,selected_companies_dic[company_name][0],selected_companies_dic[company_name][1])\n",
        "  train_x_normlized,train_y_normlized,val_x_normlized,val_y_normlized,test_x_normlized,test_y_normlized,test = prepare_company_for_training_and_testing(company, company_selected_ti)\n",
        "  n_members = 3\n",
        "  members = load_all_models(n_members,company_name)\n",
        "  print('Loaded %d models' % len(members))\n",
        "  stacked_train = stacked_dataset(members, train_x_normlized)\n",
        "  stacked_val = stacked_dataset(members, val_x_normlized)\n",
        "  stacked_test_3 = stacked_dataset(members, test_x_normlized)\n",
        "  means_stacked_test_3 = np.mean(stacked_test_3, axis=2)\n",
        "  stacked_test_b_g = stacked_dataset([members[0],members[1]], test_x_normlized)\n",
        "  means_stacked_test_b_g = np.mean(stacked_test_b_g, axis=2)\n",
        "  stacked_test_b_l = stacked_dataset([members[0],members[2]], test_x_normlized)\n",
        "  means_stacked_test_b_l = np.mean(stacked_test_b_l, axis=2)\n",
        "  stacked_test_g_l = stacked_dataset([members[1],members[2]], test_x_normlized)\n",
        "  means_stacked_test_g_l = np.mean(stacked_test_g_l, axis=2)\n",
        "  test_y_for_evaluation = true_y_to_evaluation_form(test.iloc[:,3], 5, 5)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predicted_not_normlized = evaluate_forecasts(test_y_for_evaluation, means_stacked_test_3)\n",
        "  summarize_scores('Prposed Averaging (BRNN,GRU,LSTM) Ensemble', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predicted_not_normlized = evaluate_forecasts(test_y_for_evaluation, means_stacked_test_b_g)\n",
        "  summarize_scores('Prposed Averaging (BRNN,GRU) Ensemble', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predicted_not_normlized = evaluate_forecasts(test_y_for_evaluation, means_stacked_test_b_l)\n",
        "  summarize_scores('Prposed Averaging (BRNN,LSTM) Ensemble', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "  mse_score, rmse_score,mae_score,final_r2_score,predicted_not_normlized = evaluate_forecasts(test_y_for_evaluation, means_stacked_test_g_l)\n",
        "  summarize_scores('Prposed Averaging (GRU,LSTM) Ensemble', mse_score, rmse_score,mae_score,final_r2_score)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jw4FrVLKmsD"
      },
      "source": [
        "## Excution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BaG7X0_AdR4o"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/KFUPM/Graduation/data/Saudi/Tadawul_stcks.csv\",index_col='date',parse_dates=True)\n",
        "dataset.sort_values(by='date', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZvkvfoCEH2S4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "1a365609-a2da-4eac-f565-b475e7110174"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            symbol                      name trading_name   \\\n",
              "date                                                         \n",
              "2001-12-31    2050              Savola Group  SAVOLA GROUP   \n",
              "2001-12-31    2110           Saudi Cable Co.   SAUDI CABLE   \n",
              "2001-12-31    4150  Arriyadh Development Co.         ARDCO   \n",
              "2001-12-31    4010       Dur Hospitality Co.           DUR   \n",
              "2001-12-31    1060        Saudi British Bank          SABB   \n",
              "\n",
              "                           sectoer   open   high    low  close  change  \\\n",
              "date                                                                     \n",
              "2001-12-31        Consumer Staples   5.25   5.50   5.25   5.25    5.25   \n",
              "2001-12-31             Industrials  27.76  27.76  27.76  27.76  -24.99   \n",
              "2001-12-31             Real Estate   3.94   3.94   3.94   3.94  -31.56   \n",
              "2001-12-31  Consumer Discretionary   9.50   9.50   9.30   9.30    9.30   \n",
              "2001-12-31              Financials   8.90   8.90   8.90   8.90 -323.10   \n",
              "\n",
              "            perc_Change  volume_traded   value_traded  no_trades   \n",
              "date                                                               \n",
              "2001-12-31         0.00       1077466.0    5741161.25        47.0  \n",
              "2001-12-31       -47.37         27227.0     754050.00        18.0  \n",
              "2001-12-31       -88.90       1667214.0    6634241.75       124.0  \n",
              "2001-12-31         0.00         40524.0     381406.50         7.0  \n",
              "2001-12-31       -97.32        516587.0    4613774.75        21.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c20e7c8-b0b9-4c03-864b-ea77e6714242\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>name</th>\n",
              "      <th>trading_name</th>\n",
              "      <th>sectoer</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>change</th>\n",
              "      <th>perc_Change</th>\n",
              "      <th>volume_traded</th>\n",
              "      <th>value_traded</th>\n",
              "      <th>no_trades</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-12-31</th>\n",
              "      <td>2050</td>\n",
              "      <td>Savola Group</td>\n",
              "      <td>SAVOLA GROUP</td>\n",
              "      <td>Consumer Staples</td>\n",
              "      <td>5.25</td>\n",
              "      <td>5.50</td>\n",
              "      <td>5.25</td>\n",
              "      <td>5.25</td>\n",
              "      <td>5.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1077466.0</td>\n",
              "      <td>5741161.25</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-31</th>\n",
              "      <td>2110</td>\n",
              "      <td>Saudi Cable Co.</td>\n",
              "      <td>SAUDI CABLE</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>27.76</td>\n",
              "      <td>27.76</td>\n",
              "      <td>27.76</td>\n",
              "      <td>27.76</td>\n",
              "      <td>-24.99</td>\n",
              "      <td>-47.37</td>\n",
              "      <td>27227.0</td>\n",
              "      <td>754050.00</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-31</th>\n",
              "      <td>4150</td>\n",
              "      <td>Arriyadh Development Co.</td>\n",
              "      <td>ARDCO</td>\n",
              "      <td>Real Estate</td>\n",
              "      <td>3.94</td>\n",
              "      <td>3.94</td>\n",
              "      <td>3.94</td>\n",
              "      <td>3.94</td>\n",
              "      <td>-31.56</td>\n",
              "      <td>-88.90</td>\n",
              "      <td>1667214.0</td>\n",
              "      <td>6634241.75</td>\n",
              "      <td>124.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-31</th>\n",
              "      <td>4010</td>\n",
              "      <td>Dur Hospitality Co.</td>\n",
              "      <td>DUR</td>\n",
              "      <td>Consumer Discretionary</td>\n",
              "      <td>9.50</td>\n",
              "      <td>9.50</td>\n",
              "      <td>9.30</td>\n",
              "      <td>9.30</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40524.0</td>\n",
              "      <td>381406.50</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-31</th>\n",
              "      <td>1060</td>\n",
              "      <td>Saudi British Bank</td>\n",
              "      <td>SABB</td>\n",
              "      <td>Financials</td>\n",
              "      <td>8.90</td>\n",
              "      <td>8.90</td>\n",
              "      <td>8.90</td>\n",
              "      <td>8.90</td>\n",
              "      <td>-323.10</td>\n",
              "      <td>-97.32</td>\n",
              "      <td>516587.0</td>\n",
              "      <td>4613774.75</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c20e7c8-b0b9-4c03-864b-ea77e6714242')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c20e7c8-b0b9-4c03-864b-ea77e6714242 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c20e7c8-b0b9-4c03-864b-ea77e6714242');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f645a90-541b-436c-af93-47639fdac4b7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f645a90-541b-436c-af93-47639fdac4b7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f645a90-541b-436c-af93-47639fdac4b7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3OT8-5kCdT_p"
      },
      "outputs": [],
      "source": [
        "selected_companies_dic = {\"ADC\":[\"ADC\",\"2001-12-31\"], \"ALRAJHI\":[\"ALRAJHI\",\"2001-12-31\"], \"GACO\":[\"GACO\",\"2002-01-01\"], \"EMAAR EC\":[\"EMAAR EC\",\"2006-10-06\"], \"FITAIHI GROUP\":[\"FITAIHI GROUP\",\"2002-01-26\"], \"SARCO\":[\"SARCO\",\"2002-01-23\"], \"SAUDI ELECTRICITY\":[\"SAUDI ELECTRICITY\",\"2002-06-08\"], \"SPIMACO\":[\"SPIMACO\",\"2001-12-31\"], \"STC\":[\"STC\",\"2003-01-25\"], \"TASNEE\":[\"TASNEE\",\"2001-12-31\"] }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbHLvWAcK5wq"
      },
      "source": [
        "### Avergaing ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrKIdrSLvntv"
      },
      "outputs": [],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"ADC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PP-sju4Aphp",
        "outputId": "69ac565b-703b-4c2c-d003-dd68b95d826d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[7.0141305e+06 7.4680130e+06 1.8801990e+06 ... 6.6797702e+08 5.2220595e+08\n",
            " 4.9499958e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.0842633e+07 1.2384565e+07 3.0207682e+06 ... 4.8401754e+08 6.1145216e+08\n",
            " 5.6644448e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '29.268453028761417' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.149999936421712' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "ALRAJHI_BRNN_900\n",
            "ALRAJHI_GRU_800\n",
            "ALRAJHI_LSTM_400\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.7400903\n",
            "MSE:  1.1457332\n",
            "RMSE:  1.0703892923915768\n",
            "R2:  0.989652156829834\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.74094236\n",
            "MSE:  1.1409229\n",
            "RMSE:  1.068139927169932\n",
            "R2:  0.9896956086158752\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.74532765\n",
            "MSE:  1.1544065\n",
            "RMSE:  1.0744331284665354\n",
            "R2:  0.9895738363265991\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.74542934\n",
            "MSE:  1.1662134\n",
            "RMSE:  1.0799136045125854\n",
            "R2:  0.989467203617096\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"ALRAJHI\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Whhp6DRApxl",
        "outputId": "f9dab202-1091-4ba2-d6f9-8a936d61b0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1436968.9  1954695.   1804565.5 ... 10433096.   6165209.5  6906568.5]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 635100.    440960.16 7183365.5  ... 7097985.   8172819.   6029505.5 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.417775183016466' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5113, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5103, 5, 34)\n",
            "y shape: (5103, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "GACO_BRNN_900\n",
            "GACO_GRU_700\n",
            "GACO_LSTM_1000\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.17309861\n",
            "MSE:  0.069779634\n",
            "RMSE:  0.2641583511375478\n",
            "R2:  0.9602474570274353\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.17267756\n",
            "MSE:  0.06974802\n",
            "RMSE:  0.26409850749717473\n",
            "R2:  0.9602655172348022\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.17372598\n",
            "MSE:  0.06976582\n",
            "RMSE:  0.2641322038284641\n",
            "R2:  0.9602553844451904\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.17440668\n",
            "MSE:  0.070549704\n",
            "RMSE:  0.2656119427557132\n",
            "R2:  0.9598087668418884\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"GACO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFNUxgaBAp87",
        "outputId": "3a3dc89e-cb4f-4126-aee9-ad3a2f10f5ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2.9433349e+09 9.3617434e+08 2.3272646e+08 ... 6.9893285e+06 2.0652268e+07\n",
            " 1.0014314e+07]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.9365795e+09 3.2430423e+09 2.0840685e+09 ... 1.7410878e+07 1.6748700e+07\n",
            " 9.7858370e+06]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '8.694779310034392' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.580948399942262' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (3374, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (3364, 5, 34)\n",
            "y shape: (3364, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "EMAAR EC_BRNN_1024\n",
            "EMAAR EC_GRU_600\n",
            "EMAAR EC_LSTM_1000\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.21529675\n",
            "MSE:  0.106433846\n",
            "RMSE:  0.32624200535256237\n",
            "R2:  0.9874013662338257\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.21539669\n",
            "MSE:  0.106215075\n",
            "RMSE:  0.3259065428284524\n",
            "R2:  0.9874273538589478\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.21983957\n",
            "MSE:  0.10867927\n",
            "RMSE:  0.32966539435378994\n",
            "R2:  0.9871355891227722\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.21529837\n",
            "MSE:  0.1076092\n",
            "RMSE:  0.32803840857035\n",
            "R2:  0.9872622489929199\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"EMAAR EC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuVP8R0lAqKl",
        "outputId": "07b2bc6e-d775-4f1f-f6c3-41a32b55cb9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 316177.03    17490.201   53645.805 ... 2453663.8   2737328.5\n",
            " 1359601.   ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  79106.305  544345.8    103876.51  ... 2063065.4   2230830.8\n",
            " 1354219.5  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.789691886246692' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '3.1000000635782876' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5088, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5078, 5, 34)\n",
            "y shape: (5078, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "FITAIHI GROUP_BRNN_200\n",
            "FITAIHI GROUP_GRU_512\n",
            "FITAIHI GROUP_LSTM_900\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.12593569\n",
            "MSE:  0.03647279\n",
            "RMSE:  0.1909785064954123\n",
            "R2:  0.9490616321563721\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.12736279\n",
            "MSE:  0.036679614\n",
            "RMSE:  0.19151922706427815\n",
            "R2:  0.9487727284431458\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.12671553\n",
            "MSE:  0.03687301\n",
            "RMSE:  0.19202345964973366\n",
            "R2:  0.9485026001930237\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.12520136\n",
            "MSE:  0.036394913\n",
            "RMSE:  0.1907745075987064\n",
            "R2:  0.9491702914237976\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"FITAIHI GROUP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0C3wgkIAq43",
        "outputId": "f840dd02-3a53-4273-cae8-2c3cb55452c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  221250.     216125.02   132300.   ... 17127760.   25927482.\n",
            " 15375914.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  217500.03   160409.2    152250.02 ... 13769432.   25706238.\n",
            " 25434224.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '16.22719515561002' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5091, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5081, 5, 34)\n",
            "y shape: (5081, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SARCO_BRNN_500\n",
            "SARCO_GRU_800\n",
            "SARCO_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.75871354\n",
            "MSE:  1.5187334\n",
            "RMSE:  1.23236901219766\n",
            "R2:  0.9381060004234314\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.7603718\n",
            "MSE:  1.5144908\n",
            "RMSE:  1.2306465141620537\n",
            "R2:  0.9382789731025696\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.76340216\n",
            "MSE:  1.514319\n",
            "RMSE:  1.230576670924523\n",
            "R2:  0.9382859468460083\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.77046454\n",
            "MSE:  1.5549471\n",
            "RMSE:  1.2469751953558024\n",
            "R2:  0.9366301894187927\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"SARCO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaDCsI-MArH3",
        "outputId": "1f17da33-88fd-417c-9edd-e98ff478757e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[24583906. 88294848. 52870988. ... 26448874. 28826730. 31028048.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[48515368. 67965992. 77909728. ... 37179800. 19583160. 40787484.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '13.794545052578236' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.3333333333333333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (4955, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (4945, 5, 34)\n",
            "y shape: (4945, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SAUDI ELECTRICITY_BRNN_300\n",
            "SAUDI ELECTRICITY_GRU_243\n",
            "SAUDI ELECTRICITY_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.3084051\n",
            "MSE:  0.21846446\n",
            "RMSE:  0.46740182279191367\n",
            "R2:  0.9748988747596741\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.30826384\n",
            "MSE:  0.21800585\n",
            "RMSE:  0.4669109667925358\n",
            "R2:  0.9749515056610107\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.31104514\n",
            "MSE:  0.22023132\n",
            "RMSE:  0.46928810387040537\n",
            "R2:  0.9746958613395691\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.3098505\n",
            "MSE:  0.21982436\n",
            "RMSE:  0.4688543044709254\n",
            "R2:  0.9747427105903625\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"SAUDI ELECTRICITY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lflNJBB2ArW1",
        "outputId": "1fe34890-6c6e-453b-9ca2-8dd257b13cd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[12713900.   13733807.   37350652.   ...  1696735.8    909617.25\n",
            "  2446316.2 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[20073634.   9659883.   2466405.  ...  1372106.6  4646211.5  3383550.2]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '18.000413521171446' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.369999885559082' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SPIMACO_BRNN_900\n",
            "SPIMACO_GRU_256\n",
            "SPIMACO_LSTM_600\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.34916484\n",
            "MSE:  0.27027065\n",
            "RMSE:  0.5198756059082199\n",
            "R2:  0.9778169393539429\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.34838063\n",
            "MSE:  0.26960796\n",
            "RMSE:  0.5192378657010926\n",
            "R2:  0.9778713583946228\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.35168386\n",
            "MSE:  0.27407718\n",
            "RMSE:  0.5235238075271549\n",
            "R2:  0.977504551410675\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.35388014\n",
            "MSE:  0.273493\n",
            "RMSE:  0.5229655743204192\n",
            "R2:  0.9775525331497192\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"SPIMACO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--I7xZXBAriZ",
        "outputId": "cb04ebf3-e7e7-4054-8175-7d73e6df94da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.9316651e+08 2.8920675e+08 1.8334110e+08 ... 9.4469936e+07 8.9680896e+07\n",
            " 5.9570704e+07]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[6.6367450e+08 7.2399955e+08 1.6893843e+08 ... 1.1727689e+08 9.4607304e+07\n",
            " 1.0791855e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '52.75059357527347' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '10.416666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (4724, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (4714, 5, 34)\n",
            "y shape: (4714, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "STC_BRNN_1024\n",
            "STC_GRU_729\n",
            "STC_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  1.280864\n",
            "MSE:  3.8261273\n",
            "RMSE:  1.956048897836071\n",
            "R2:  0.9816406965255737\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  1.2660339\n",
            "MSE:  3.7393646\n",
            "RMSE:  1.9337436810558521\n",
            "R2:  0.9820570349693298\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  1.293748\n",
            "MSE:  3.8837037\n",
            "RMSE:  1.970711472704384\n",
            "R2:  0.9813644886016846\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  1.3048966\n",
            "MSE:  3.9191716\n",
            "RMSE:  1.979689766537062\n",
            "R2:  0.981194257736206\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"STC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFB-Qtp-ArvG",
        "outputId": "78bfc5bb-5f98-4960-972b-79184483e657"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  840945.6  9626038.   7505411.5 ... 17834854.  21154470.  16853946. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  490900.94  1736300.    2911981.8  ... 26082650.   21951994.\n",
            " 12363582.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.538689886576379' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "TASNEE_BRNN_1024\n",
            "TASNEE_GRU_512\n",
            "TASNEE_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "*************Prposed Averaging (BRNN,GRU,LSTM) Ensemble**********\n",
            "MAE:  0.31186083\n",
            "MSE:  0.19771595\n",
            "RMSE:  0.4446526205842481\n",
            "R2:  0.9727327823638916\n",
            "*************Prposed Averaging (BRNN,GRU) Ensemble**********\n",
            "MAE:  0.30798748\n",
            "MSE:  0.19497578\n",
            "RMSE:  0.4415606169717841\n",
            "R2:  0.9731106758117676\n",
            "*************Prposed Averaging (BRNN,LSTM) Ensemble**********\n",
            "MAE:  0.31522378\n",
            "MSE:  0.20012769\n",
            "RMSE:  0.44735633563246013\n",
            "R2:  0.9724001288414001\n",
            "*************Prposed Averaging (GRU,LSTM) Ensemble**********\n",
            "MAE:  0.31591642\n",
            "MSE:  0.20087488\n",
            "RMSE:  0.44819067366049176\n",
            "R2:  0.9722970724105835\n"
          ]
        }
      ],
      "source": [
        "averaging_process(dataset,selected_companies_dic,\"TASNEE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxZ3ObeJLCIP"
      },
      "source": [
        "### Stacking ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMsCDp35Pndf"
      },
      "outputs": [],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"ADC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrQpDfiILCIQ",
        "outputId": "7b705d52-457b-462b-f038-7e8be5206251"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-7-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[7.0141305e+06 7.4680130e+06 1.8801990e+06 ... 6.6797702e+08 5.2220595e+08\n",
            " 4.9499958e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.0842633e+07 1.2384565e+07 3.0207682e+06 ... 4.8401754e+08 6.1145216e+08\n",
            " 5.6644448e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '29.268453028761417' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-7-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.149999936421712' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "ALRAJHI_BRNN_900\n",
            "ALRAJHI_GRU_800\n",
            "ALRAJHI_LSTM_400\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0778 - val_loss: 0.0758\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0765\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0794\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0798\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0779\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0772\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0766\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0791\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0762\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0761\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0774\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0752\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0795\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0768\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0763\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0762\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0770\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0773\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0766\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0769\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0756\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0755\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0775\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0769\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0758\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0753\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0797\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0763\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0761\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0780\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0754\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0766\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0763\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0751\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0758\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0817\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0755\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0803\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0754\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0755\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0753\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0766\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0767\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0772\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0812\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0761\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0761\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0753\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0765\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0757\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0767\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0754\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0758\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.18 62.07 62.33 62.41 62.5 ]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.7686211\n",
            "MSE:  1.1955794\n",
            "RMSE:  1.0934255391197447\n",
            "R2:  0.9892019629478455\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0975 - val_loss: 0.0748\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0756\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0756\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0761\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0757\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0754\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0754\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0759\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0762\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0755\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0751\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0752\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0784\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0749\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0755\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0766\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0757\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0755\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0799\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0760\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0750\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0750\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0763\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0750\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0762\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0769\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0763\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0760\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0758\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0753\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0758\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0770\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0752\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0759\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0776\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0752\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0769\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0756\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0753\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0756\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0759\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0771\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0758\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0778\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0770\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0756\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0765\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0773\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0798\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0767\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0759\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0755\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0797\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0773\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0765\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0763\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.41 62.51 62.63 62.63 62.71]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.73896515\n",
            "MSE:  1.1810316\n",
            "RMSE:  1.0867527707531668\n",
            "R2:  0.9893332719802856\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1030 - val_loss: 0.0771\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0758\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0775\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0797\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0784\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0786\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0772\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0787\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0764\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0766\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0790\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0773\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0779\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0764\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0764\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0774\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0798\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0768\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0768\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0755\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0759\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0764\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0754\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0770\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0763\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0759\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0753\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0784\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0756\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0754\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0764\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0764\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0753\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0761\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0762\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0753\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0773\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0760\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0748\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0759\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0754\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0754\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0756\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0759\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0764\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0779\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0770\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0755\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0787\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0754\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0754\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0757\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0763\n",
            "36/36 [==============================] - 0s 1ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.09 62.12 62.12 62.18 62.21]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.785664\n",
            "MSE:  1.2396139\n",
            "RMSE:  1.113379490851115\n",
            "R2:  0.9888042211532593\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0805 - val_loss: 0.0775\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0789\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0789\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0778\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0777\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0767\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0768\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0787\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0765\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0768\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0768\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0766\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0764\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0761\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0759\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0761\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0759\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0750\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0766\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0750\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0766\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0763\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0749\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0744\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0774\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0750\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0755\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0737\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0768\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0738\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0741\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0727\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0733\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0728\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0738\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0754\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0739\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0728\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0730\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0730\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0735\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0742\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0744\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0739\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0739\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0733\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0722\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0741\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0740\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0738\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0738\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0753\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0719\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0749\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0728\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0726\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0735\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0732\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0725\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0731\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0730\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0726\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0746\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0731\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0725\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0728\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0723\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0740\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0724\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0743\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0720\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0729\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0730\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0724\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0724\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0717\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0740\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0722\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0719\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0712\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0723\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0722\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0722\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0722\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0725\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0720\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0748\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0719\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0732\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0719\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0740\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0736\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0713\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0718\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0718\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0722\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0724\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0712\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.43 62.33 62.44 62.51 62.33]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.7500974\n",
            "MSE:  1.1532164\n",
            "RMSE:  1.0738791188953771\n",
            "R2:  0.9895846247673035\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.1246 - val_loss: 0.0922\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0808\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0100 - val_loss: 0.0796\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0779\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0095 - val_loss: 0.0793\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0767\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0789\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0760\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0100 - val_loss: 0.0787\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0767\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0783\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0105 - val_loss: 0.0768\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.0762\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0770\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0755\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0778\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0763\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0753\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0762\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0754\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0766\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0749\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0756\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0094 - val_loss: 0.0762\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0759\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0779\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0096 - val_loss: 0.0757\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0754\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0750\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0765\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0086 - val_loss: 0.0755\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0754\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0760\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0755\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0746\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0753\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0752\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0753\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0088 - val_loss: 0.0747\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0088 - val_loss: 0.0750\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0752\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0750\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0753\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0758\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0751\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0086 - val_loss: 0.0753\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0761\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0748\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0747\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0086 - val_loss: 0.0753\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0748\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.0746\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0087 - val_loss: 0.0750\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0086 - val_loss: 0.0752\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0086 - val_loss: 0.0749\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.0746\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0750\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0750\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.0751\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0750\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0751\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0086 - val_loss: 0.0747\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0747\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.76 62.66 62.69 62.72 62.58]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.74675846\n",
            "MSE:  1.1651099\n",
            "RMSE:  1.0794025536462257\n",
            "R2:  0.9894770979881287\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1202 - val_loss: 0.0919\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0871\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0800\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0093 - val_loss: 0.0802\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0099 - val_loss: 0.0807\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0782\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0100 - val_loss: 0.0771\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0764\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0768\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0099 - val_loss: 0.0782\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0100 - val_loss: 0.0778\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0097 - val_loss: 0.0755\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0096 - val_loss: 0.0754\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0757\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0757\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0099 - val_loss: 0.0753\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0099 - val_loss: 0.0749\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0752\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0100 - val_loss: 0.0755\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0092 - val_loss: 0.0751\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0753\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0755\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0750\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0774\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0755\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0756\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0088 - val_loss: 0.0752\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0096 - val_loss: 0.0751\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0753\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0748\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0750\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0749\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0094 - val_loss: 0.0747\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0746\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0752\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0753\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0748\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0747\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0763\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0753\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0755\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0754\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0750\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0094 - val_loss: 0.0755\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0749\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0762\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0761\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0762\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0090 - val_loss: 0.0752\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0756\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0748\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0752\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0754\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0754\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0752\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0758\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0755\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0752\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0761\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0760\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0752\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0757\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0752\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0753\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0755\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0753\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0759\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0755\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0768\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0752\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0754\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0085 - val_loss: 0.0752\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0772\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0756\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.13 62.24 62.31 62.47 62.42]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.76290447\n",
            "MSE:  1.168947\n",
            "RMSE:  1.0811785150612518\n",
            "R2:  0.9894424676895142\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 5s 24ms/step - loss: 0.1336 - val_loss: 0.0887\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0098 - val_loss: 0.0892\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0820\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0823\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0816\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0796\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0791\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0097 - val_loss: 0.0787\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0097 - val_loss: 0.0805\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0802\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0785\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0774\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.0765\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0097 - val_loss: 0.0781\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0101 - val_loss: 0.0791\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0098 - val_loss: 0.0766\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0783\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0778\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0781\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0785\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0096 - val_loss: 0.0768\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0098 - val_loss: 0.0780\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0766\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0774\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0098 - val_loss: 0.0772\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0095 - val_loss: 0.0771\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0763\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0759\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0780\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0763\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0763\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0753\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0778\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0761\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0764\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0756\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0085 - val_loss: 0.0762\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0087 - val_loss: 0.0775\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0758\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0790\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0086 - val_loss: 0.0768\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0085 - val_loss: 0.0762\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0767\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0767\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0088 - val_loss: 0.0778\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0751\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0765\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0756\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0754\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0087 - val_loss: 0.0760\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0085 - val_loss: 0.0761\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0084 - val_loss: 0.0767\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0757\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0767\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [61.89 61.95 62.01 62.04 61.99]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.79107314\n",
            "MSE:  1.2514539\n",
            "RMSE:  1.118683993134505\n",
            "R2:  0.9886972308158875\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_11 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 5s 19ms/step - loss: 0.1055 - val_loss: 0.0883\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0819\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0806\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0819\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0840\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0798\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0100 - val_loss: 0.0825\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0096 - val_loss: 0.0788\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0098 - val_loss: 0.0804\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0792\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0791\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0786\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0784\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0803\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0105 - val_loss: 0.0780\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0099 - val_loss: 0.0769\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0774\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0810\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0781\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0785\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0096 - val_loss: 0.0769\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0784\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0767\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0101 - val_loss: 0.0768\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0100 - val_loss: 0.0769\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0768\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0779\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0097 - val_loss: 0.0768\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0783\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0769\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0775\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0101 - val_loss: 0.0768\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0761\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0766\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0767\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0762\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0762\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0086 - val_loss: 0.0774\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0767\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0761\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0755\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0767\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0759\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0087 - val_loss: 0.0756\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0754\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0754\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0753\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0088 - val_loss: 0.0756\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0092 - val_loss: 0.0749\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0745\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0747\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0770\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0753\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0743\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0746\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0742\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0087 - val_loss: 0.0748\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0747\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.42 62.37 62.54 62.66 62.66]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.73448\n",
            "MSE:  1.1502016\n",
            "RMSE:  1.072474502758351\n",
            "R2:  0.989611804485321\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_7 (GRU)                 (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 10ms/step - loss: 0.0863 - val_loss: 0.0792\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0787\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0789\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0778\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0796\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0778\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0779\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0767\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0777\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0772\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0768\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0777\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0765\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0766\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0764\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0763\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0771\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0763\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0765\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0767\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0762\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0758\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0758\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0763\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0754\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0759\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0757\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0759\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0759\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0772\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0759\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0754\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0767\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0754\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0762\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0758\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0764\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0758\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0085 - val_loss: 0.0761\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0756\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0754\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0759\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0760\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0762\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0753\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0085 - val_loss: 0.0765\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0755\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0760\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0757\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0753\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0755\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0754\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0757\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0761\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0755\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0084 - val_loss: 0.0769\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0757\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0083 - val_loss: 0.0755\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.42 62.35 62.39 62.38 62.39]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.7315115\n",
            "MSE:  1.1471622\n",
            "RMSE:  1.071056580681145\n",
            "R2:  0.989639163017273\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_8 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 5s 16ms/step - loss: 0.1563 - val_loss: 0.0770\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0825\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0773\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0098 - val_loss: 0.0787\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0756\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0785\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0097 - val_loss: 0.0791\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0759\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0752\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0759\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0758\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0756\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0763\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0756\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0756\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0755\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0755\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0763\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0757\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0779\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0758\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0755\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0757\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0763\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0756\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0766\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0756\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0763\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0752\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0759\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0755\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0768\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0764\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0772\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0762\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0762\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0760\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0773\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0775\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0773\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0763\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0762\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0766\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0758\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0086 - val_loss: 0.0759\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0772\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0762\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0767\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0765\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0763\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0757\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0767\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0763\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0762\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0771\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0765\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0769\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0764\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.45 62.4  62.49 62.42 62.35]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.7268938\n",
            "MSE:  1.1423804\n",
            "RMSE:  1.0688219481226213\n",
            "R2:  0.9896824955940247\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_9 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.0977 - val_loss: 0.0801\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0792\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0786\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0796\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0809\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0787\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0096 - val_loss: 0.0791\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0786\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0793\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0799\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0778\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0786\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0798\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0794\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0097 - val_loss: 0.0801\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0781\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0789\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0791\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0777\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0778\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0767\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0773\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0784\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0087 - val_loss: 0.0779\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.0781\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0779\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0774\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0787\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0772\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0086 - val_loss: 0.0773\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0772\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0085 - val_loss: 0.0772\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0773\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0087 - val_loss: 0.0769\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0768\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0772\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.0774\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0768\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0767\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0084 - val_loss: 0.0776\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0083 - val_loss: 0.0771\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0760\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0764\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0764\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0766\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0086 - val_loss: 0.0773\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0770\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0774\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0083 - val_loss: 0.0772\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0764\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0084 - val_loss: 0.0773\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0765\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0085 - val_loss: 0.0772\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.0777\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0084 - val_loss: 0.0779\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0086 - val_loss: 0.0769\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0084 - val_loss: 0.0767\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0085 - val_loss: 0.0768\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0772\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0769\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0763\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0766\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.6  62.7  62.61 62.71 62.69]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.7385583\n",
            "MSE:  1.1522231\n",
            "RMSE:  1.0734165594954155\n",
            "R2:  0.9895935654640198\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_10 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.1269 - val_loss: 0.0803\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0812\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0799\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0097 - val_loss: 0.0795\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0097 - val_loss: 0.0797\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0787\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0795\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0802\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0799\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0791\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0811\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0788\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0792\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0096 - val_loss: 0.0793\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0782\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0098 - val_loss: 0.0789\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0785\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0791\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0787\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0798\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0779\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0780\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0785\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0779\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0777\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0793\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0784\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0778\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0782\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0091 - val_loss: 0.0788\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0779\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0786\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0092 - val_loss: 0.0783\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0774\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0777\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0781\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0087 - val_loss: 0.0777\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0088 - val_loss: 0.0766\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0763\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0766\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [61.5 61.5 61.5 61.7 61. ]\n",
            "Predicted_not_normlized [62.59 62.68 62.69 62.9  62.99]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.75424194\n",
            "MSE:  1.1988299\n",
            "RMSE:  1.0949109047303736\n",
            "R2:  0.9891725778579712\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"ALRAJHI\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt5nTsP4LCIR",
        "outputId": "93a4e744-368f-43d1-8e77-3d9c285e58f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-7-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-7-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1436968.9  1954695.   1804565.5 ... 10433096.   6165209.5  6906568.5]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 635100.    440960.16 7183365.5  ... 7097985.   8172819.   6029505.5 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.417775183016466' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5113, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5103, 5, 34)\n",
            "y shape: (5103, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "GACO_BRNN_900\n",
            "GACO_GRU_700\n",
            "GACO_LSTM_1000\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 4ms/step - loss: 0.0885 - val_loss: 0.0839\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0720\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0884\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0769\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0805\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0724\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0767\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0788\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0807\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0752\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0868\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0796\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0885\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0819\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0823\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0794\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0857\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0810\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0835\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0752\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0873\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0820\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0751\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0775\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0853\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0859\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0781\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0774\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0756\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0780\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0866\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0780\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0749\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0739\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0863\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0885\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0784\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0915\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0808\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0817\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0806\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0852\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0875\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0756\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0792\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0761\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0812\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0800\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0777\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0817\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0772\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0833\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0832\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0822\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0798\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0800\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0781\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0811\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0788\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0801\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0748\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0809\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0808\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0798\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0784\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0774\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0808\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0768\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0771\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0749\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0875\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0811\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0771\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0755\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0771\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0810\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0851\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0844\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0748\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0767\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0780\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0770\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0762\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0875\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0740\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0772\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0822\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0815\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0864\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0773\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0733\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0856\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0823\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0777\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0746\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0754\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0790\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0827\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0763\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0869\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.38 10.39 10.41 10.4  10.41]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.18015642\n",
            "MSE:  0.07319059\n",
            "RMSE:  0.27053759855030557\n",
            "R2:  0.9583043456077576\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0960 - val_loss: 0.0774\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0819\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0761\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0767\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0879\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0910\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0927\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0843\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0770\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0833\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0869\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0830\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0800\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0820\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0832\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0770\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0821\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0846\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0777\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0865\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0831\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0741\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0786\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0806\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0903\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0759\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0805\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0802\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0803\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0808\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0844\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0726\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0854\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0807\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0772\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0782\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0763\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0779\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0780\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0771\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0806\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0798\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0811\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0902\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0857\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0790\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0820\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0797\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0812\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0818\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0821\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0768\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0772\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0730\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0846\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0853\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0883\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0897\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0856\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0750\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0782\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0763\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0815\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0814\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0782\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0819\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0774\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0790\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0816\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0747\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0792\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0843\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0712\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0755\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0752\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0774\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0829\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0799\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0868\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0748\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0766\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0957\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0792\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0835\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0761\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0824\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0852\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0862\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0831\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0903\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0803\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0784\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0772\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0772\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0881\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0811\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0760\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0894\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0756\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.42 10.37 10.37 10.4  10.4 ]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.17945907\n",
            "MSE:  0.071394905\n",
            "RMSE:  0.267198251206777\n",
            "R2:  0.959327220916748\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0809 - val_loss: 0.0793\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0868\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0800\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0711\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0759\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0744\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0815\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0822\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0750\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0805\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0729\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0940\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0893\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0954\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0763\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0777\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0810\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0822\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0771\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0805\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0793\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0816\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0759\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0769\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0789\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0776\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0744\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0824\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0747\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0806\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0892\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0811\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0848\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0761\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0725\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0736\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0803\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0791\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0789\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0782\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0793\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0785\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0832\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0770\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0898\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0822\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0818\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0815\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0891\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0840\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0867\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0816\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0882\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0803\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0785\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0827\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0813\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0746\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0897\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0852\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0823\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0769\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0764\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0836\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0797\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0803\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0803\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0930\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0727\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0837\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0850\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0739\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0856\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0865\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0768\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0769\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0737\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0780\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0764\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0819\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0838\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0747\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0775\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0822\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0781\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0782\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0763\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0801\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0769\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0798\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0810\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0939\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0779\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0761\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0785\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0859\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0840\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0776\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0770\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0713\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.37 10.39 10.38 10.37 10.4 ]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.19038424\n",
            "MSE:  0.078721404\n",
            "RMSE:  0.28057334883346025\n",
            "R2:  0.9551534652709961\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0774 - val_loss: 0.0742\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0779\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0806\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0943\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0811\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.1018\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0843\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0872\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0766\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0782\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0820\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0894\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0884\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0791\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0832\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0891\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0834\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0811\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0749\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0853\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0734\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0892\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0730\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0766\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0798\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0942\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0782\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0839\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0775\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0778\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0134 - val_loss: 0.0735\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0835\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0756\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0773\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0842\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0796\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0795\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0768\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0758\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0757\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0814\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0759\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0810\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0771\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0788\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0793\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0813\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0766\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0802\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0806\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0818\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0773\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0830\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0834\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0761\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0801\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0833\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0745\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0788\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0774\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0802\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0794\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0763\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0802\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0800\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0824\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0837\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0794\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0779\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0794\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0805\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0811\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0814\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0793\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0914\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0797\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0755\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0749\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0791\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0938\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0820\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0828\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0796\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0746\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0856\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0876\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0850\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0855\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0781\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0835\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0756\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0805\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0809\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0883\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0813\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0810\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0771\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0863\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0836\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.4  10.41 10.41 10.43 10.41]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.17488162\n",
            "MSE:  0.07095115\n",
            "RMSE:  0.2663665685997534\n",
            "R2:  0.9595800042152405\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.1831 - val_loss: 0.1177\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1211\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0165 - val_loss: 0.1250\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.1138\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1021\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0160 - val_loss: 0.0918\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.1338\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1088\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0829\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.0903\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0156 - val_loss: 0.0804\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0148 - val_loss: 0.0815\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0146 - val_loss: 0.0898\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0873\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0841\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0843\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0814\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0827\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0135 - val_loss: 0.0773\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0142 - val_loss: 0.0778\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0141 - val_loss: 0.0747\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0140 - val_loss: 0.0746\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0714\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0823\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0839\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.0816\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0753\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0132 - val_loss: 0.0795\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0133 - val_loss: 0.0779\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0127 - val_loss: 0.0794\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0802\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0803\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0701\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0863\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0138 - val_loss: 0.0870\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0775\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0139 - val_loss: 0.0854\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0129 - val_loss: 0.0738\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0785\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0804\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0731\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0136 - val_loss: 0.0806\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0773\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0763\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0136 - val_loss: 0.0747\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0131 - val_loss: 0.0811\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0136 - val_loss: 0.0808\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0786\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0737\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0829\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0779\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0726\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0134 - val_loss: 0.0775\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0131 - val_loss: 0.0791\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0126 - val_loss: 0.0765\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0800\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0834\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0810\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0875\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0794\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0774\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0128 - val_loss: 0.0808\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0129 - val_loss: 0.0853\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0131 - val_loss: 0.0771\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0764\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0768\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0829\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0771\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0771\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0124 - val_loss: 0.0747\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0767\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0123 - val_loss: 0.0791\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0847\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0767\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0785\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0778\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0766\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.0791\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0121 - val_loss: 0.0767\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0122 - val_loss: 0.0809\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0775\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0803\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0121 - val_loss: 0.0768\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0845\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0747\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0777\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0121 - val_loss: 0.0792\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0122 - val_loss: 0.0790\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0799\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0781\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0764\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0780\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0780\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0771\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0126 - val_loss: 0.0804\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0795\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0784\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0122 - val_loss: 0.0823\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0120 - val_loss: 0.0779\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0122 - val_loss: 0.0758\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.4  10.38 10.39 10.38 10.36]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.1775999\n",
            "MSE:  0.07090522\n",
            "RMSE:  0.2662803475452285\n",
            "R2:  0.9596061706542969\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1495 - val_loss: 0.1241\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1338\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0165 - val_loss: 0.0987\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1218\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0151 - val_loss: 0.1483\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0158 - val_loss: 0.1037\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1083\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1133\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1011\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0138 - val_loss: 0.1300\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.1178\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1055\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.1043\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.0994\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0832\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.0851\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0944\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0783\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.0780\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0788\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0151 - val_loss: 0.0878\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0182 - val_loss: 0.0826\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0139 - val_loss: 0.0789\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0136 - val_loss: 0.0897\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.0781\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0773\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.0742\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0782\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.0780\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0137 - val_loss: 0.0727\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0139 - val_loss: 0.0785\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0137 - val_loss: 0.0759\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0136 - val_loss: 0.0808\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0138 - val_loss: 0.0719\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0827\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0132 - val_loss: 0.0807\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0799\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0140 - val_loss: 0.0798\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0132 - val_loss: 0.0764\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0136 - val_loss: 0.0853\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0132 - val_loss: 0.0770\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0817\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0792\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0795\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0814\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0759\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0142 - val_loss: 0.0835\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.0748\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0138 - val_loss: 0.0745\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0798\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0810\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0832\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0774\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0774\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0130 - val_loss: 0.0831\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0125 - val_loss: 0.0817\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.0836\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0841\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0787\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0775\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0789\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0771\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0134 - val_loss: 0.0794\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0132 - val_loss: 0.0798\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0131 - val_loss: 0.0786\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0759\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0823\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0786\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0810\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0793\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0126 - val_loss: 0.0746\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0131 - val_loss: 0.0795\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0125 - val_loss: 0.0803\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0827\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0828\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0769\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0821\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0132 - val_loss: 0.0766\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0785\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0127 - val_loss: 0.0796\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0129 - val_loss: 0.0785\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0785\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0789\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0812\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0725\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0122 - val_loss: 0.0741\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0748\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0125 - val_loss: 0.0765\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0770\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0818\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0754\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0749\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0748\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0767\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0744\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0132 - val_loss: 0.0723\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0127 - val_loss: 0.0802\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0129 - val_loss: 0.0777\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0122 - val_loss: 0.0799\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0789\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.38 10.36 10.36 10.37 10.36]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.17464344\n",
            "MSE:  0.070755415\n",
            "RMSE:  0.2659988997434864\n",
            "R2:  0.95969158411026\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_14 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 12ms/step - loss: 0.1736 - val_loss: 0.1906\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1345\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0141 - val_loss: 0.1427\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0141 - val_loss: 0.1186\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.1042\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1310\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1474\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1316\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1019\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0140 - val_loss: 0.1041\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0136 - val_loss: 0.1444\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0144 - val_loss: 0.1039\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1191\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0977\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.1184\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1019\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1023\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0141 - val_loss: 0.0839\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.0827\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0162 - val_loss: 0.0892\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0876\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0135 - val_loss: 0.0941\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0954\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0137 - val_loss: 0.0878\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0812\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0144 - val_loss: 0.0926\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0130 - val_loss: 0.0811\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.0870\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0816\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0138 - val_loss: 0.0787\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0135 - val_loss: 0.0823\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0913\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0856\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0829\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0128 - val_loss: 0.0730\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0140 - val_loss: 0.0742\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0865\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.0774\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0845\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0810\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.0789\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0871\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0130 - val_loss: 0.0834\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0127 - val_loss: 0.0798\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0882\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.0864\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0869\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0883\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0793\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0129 - val_loss: 0.0888\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0131 - val_loss: 0.0740\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0131 - val_loss: 0.0820\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0125 - val_loss: 0.0852\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0135 - val_loss: 0.0845\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0781\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0787\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0868\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0134 - val_loss: 0.0800\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0129 - val_loss: 0.0808\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0138 - val_loss: 0.0783\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0820\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0834\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0799\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0752\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0129 - val_loss: 0.0819\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0121 - val_loss: 0.0789\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0133 - val_loss: 0.0819\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0789\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0782\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0892\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0901\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0809\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0767\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0128 - val_loss: 0.0811\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0123 - val_loss: 0.0729\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0123 - val_loss: 0.0823\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0790\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0811\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0759\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0742\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0783\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0123 - val_loss: 0.0758\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0129 - val_loss: 0.0763\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0122 - val_loss: 0.0772\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0785\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0786\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0723\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0871\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0821\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0126 - val_loss: 0.0784\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0125 - val_loss: 0.0795\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0126 - val_loss: 0.0810\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0785\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0770\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0120 - val_loss: 0.0779\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0123 - val_loss: 0.0784\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0814\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0126 - val_loss: 0.0778\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0123 - val_loss: 0.0883\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0124 - val_loss: 0.0772\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.4  10.4  10.4  10.4  10.39]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.1752886\n",
            "MSE:  0.069525644\n",
            "RMSE:  0.2636771590091923\n",
            "R2:  0.96039217710495\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_15 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1915 - val_loss: 0.1399\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.1317\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.1402\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0203 - val_loss: 0.1742\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0150 - val_loss: 0.1250\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1062\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1020\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1123\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0903\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1008\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.1339\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.0887\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0145 - val_loss: 0.0936\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0169 - val_loss: 0.0950\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0941\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.0949\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0903\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1112\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0789\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.0889\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0141 - val_loss: 0.0920\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0157 - val_loss: 0.0889\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.0904\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.0874\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.0863\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.0863\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.0892\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0821\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.0791\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.0825\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.0807\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0138 - val_loss: 0.0928\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0861\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.0833\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.0758\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0790\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0135 - val_loss: 0.0773\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.0782\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0135 - val_loss: 0.0785\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0815\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.0762\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.0808\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.0833\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0903\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0816\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0144 - val_loss: 0.0987\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0139 - val_loss: 0.0758\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0142 - val_loss: 0.0770\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0135 - val_loss: 0.0842\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0138 - val_loss: 0.0910\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0782\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0779\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0809\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0136 - val_loss: 0.0801\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0137 - val_loss: 0.0808\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0129 - val_loss: 0.0772\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0779\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0802\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.0797\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0807\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0872\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0130 - val_loss: 0.0789\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0136 - val_loss: 0.0781\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0129 - val_loss: 0.0811\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0819\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0838\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0800\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0863\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0801\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0131 - val_loss: 0.0798\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0129 - val_loss: 0.0853\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0133 - val_loss: 0.0813\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0830\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0802\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0853\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0804\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0893\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0133 - val_loss: 0.0834\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0128 - val_loss: 0.0845\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0130 - val_loss: 0.0868\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0923\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0848\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0797\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0820\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0129 - val_loss: 0.0813\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0133 - val_loss: 0.0777\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0127 - val_loss: 0.0885\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0127 - val_loss: 0.0943\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0136 - val_loss: 0.0827\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0819\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0775\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0878\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0871\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0809\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0131 - val_loss: 0.0813\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0128 - val_loss: 0.0777\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0127 - val_loss: 0.0758\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0797\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0764\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0809\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.44 10.43 10.41 10.39 10.42]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.17659295\n",
            "MSE:  0.07014566\n",
            "RMSE:  0.26485025797362005\n",
            "R2:  0.9600390195846558\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_11 (GRU)                (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.1194 - val_loss: 0.0887\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0808\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.0896\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0953\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0831\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0862\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0134 - val_loss: 0.0855\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0137 - val_loss: 0.0771\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.0803\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0142 - val_loss: 0.0827\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0868\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0137 - val_loss: 0.0877\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0765\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0814\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0850\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0776\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0830\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0778\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0133 - val_loss: 0.0737\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0133 - val_loss: 0.0788\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0797\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0824\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0867\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0747\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0766\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0800\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0835\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0842\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0138 - val_loss: 0.0789\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0135 - val_loss: 0.0784\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0790\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0867\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0858\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0764\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0770\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0783\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0771\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0816\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0833\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0848\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0132 - val_loss: 0.0801\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0862\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0722\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0769\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0835\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0771\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0802\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0898\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0784\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0838\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0742\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0125 - val_loss: 0.0835\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0766\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0804\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0792\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0756\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0814\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0901\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0748\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0780\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0804\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0729\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.0751\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0739\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0742\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0802\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0786\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0754\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0787\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0790\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0784\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0126 - val_loss: 0.0781\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0125 - val_loss: 0.0773\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0123 - val_loss: 0.0845\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0755\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0781\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0752\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0766\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0774\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0771\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0782\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0792\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0802\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0741\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0784\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.0789\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0778\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0761\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0792\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0758\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0121 - val_loss: 0.0764\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0753\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0123 - val_loss: 0.0803\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0768\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.0774\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.0776\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0123 - val_loss: 0.0795\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0814\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0774\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0791\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.4  10.41 10.41 10.42 10.41]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.17558782\n",
            "MSE:  0.070055105\n",
            "RMSE:  0.264679248888382\n",
            "R2:  0.9600905179977417\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_12 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 10ms/step - loss: 0.1213 - val_loss: 0.0757\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0808\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0807\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.0761\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.0812\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0135 - val_loss: 0.0865\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.0858\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0849\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0842\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0868\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.0833\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0883\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0744\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0141 - val_loss: 0.0822\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0134 - val_loss: 0.0739\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.0779\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0138 - val_loss: 0.0767\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0140 - val_loss: 0.0845\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0809\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.0731\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0854\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0747\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0778\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0817\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0779\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.0774\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0140 - val_loss: 0.0775\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0834\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0801\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0804\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0818\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0831\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0811\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0785\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0759\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0133 - val_loss: 0.0763\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0752\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0130 - val_loss: 0.0743\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0750\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0780\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0754\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0742\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0134 - val_loss: 0.0816\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0794\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0791\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0135 - val_loss: 0.0772\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0785\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0137 - val_loss: 0.0765\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0781\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0780\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0794\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0767\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0739\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0789\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0738\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0727\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0133 - val_loss: 0.0739\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0771\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0125 - val_loss: 0.0745\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0798\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0889\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0797\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0714\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0760\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0758\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0779\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0126 - val_loss: 0.0763\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0126 - val_loss: 0.0800\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0765\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0794\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0758\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0777\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0728\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0771\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0814\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0749\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0755\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0130 - val_loss: 0.0768\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0755\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.0803\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0126 - val_loss: 0.0753\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0757\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0766\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0739\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0778\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0784\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0774\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0127 - val_loss: 0.0770\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0773\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0792\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0122 - val_loss: 0.0770\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0785\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0762\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0760\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0748\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0774\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0733\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0805\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0126 - val_loss: 0.0792\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0766\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.39 10.4  10.42 10.37 10.45]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.17624341\n",
            "MSE:  0.07016959\n",
            "RMSE:  0.2648954329798277\n",
            "R2:  0.9600253105163574\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_13 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 10ms/step - loss: 0.1179 - val_loss: 0.1075\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0918\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0968\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0138 - val_loss: 0.0901\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0137 - val_loss: 0.0874\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0138 - val_loss: 0.0880\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0928\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0946\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0901\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0786\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0787\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0827\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0132 - val_loss: 0.0780\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0133 - val_loss: 0.0898\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0140 - val_loss: 0.0791\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0132 - val_loss: 0.0898\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0132 - val_loss: 0.0801\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0789\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0746\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0762\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0776\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0946\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0891\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0785\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0805\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0782\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0812\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0794\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0834\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0784\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0767\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0811\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0764\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0765\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0132 - val_loss: 0.0723\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0743\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.0773\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0780\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0125 - val_loss: 0.0828\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0811\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0766\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0771\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0779\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0838\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0124 - val_loss: 0.0767\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0137 - val_loss: 0.0808\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.0814\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0762\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0767\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0121 - val_loss: 0.0762\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0796\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0125 - val_loss: 0.0737\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0812\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0126 - val_loss: 0.0806\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0792\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0761\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0779\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0123 - val_loss: 0.0755\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0792\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0788\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0123 - val_loss: 0.0780\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0797\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0784\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0783\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0822\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0122 - val_loss: 0.0745\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0124 - val_loss: 0.0767\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0772\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0122 - val_loss: 0.0773\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0781\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0852\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0795\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0123 - val_loss: 0.0750\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0121 - val_loss: 0.0810\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0126 - val_loss: 0.0788\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0124 - val_loss: 0.0803\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.0807\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0782\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0121 - val_loss: 0.0781\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0122 - val_loss: 0.0772\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0121 - val_loss: 0.0794\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0122 - val_loss: 0.0785\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0121 - val_loss: 0.0792\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0756\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0812\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0811\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0124 - val_loss: 0.0774\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0764\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0813\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0121 - val_loss: 0.0803\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0786\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0121 - val_loss: 0.0788\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0749\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0798\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0123 - val_loss: 0.0820\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0122 - val_loss: 0.0802\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0120 - val_loss: 0.0775\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0121 - val_loss: 0.0756\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0763\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0125 - val_loss: 0.0814\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.33 10.34 10.36 10.36 10.39]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.17633915\n",
            "MSE:  0.07094079\n",
            "RMSE:  0.26634712793754206\n",
            "R2:  0.9595859050750732\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_14 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.1284 - val_loss: 0.0912\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0870\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0142 - val_loss: 0.0780\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0142 - val_loss: 0.0832\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.0828\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0137 - val_loss: 0.0855\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0851\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0735\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0155 - val_loss: 0.0861\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0984\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.0754\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0788\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0141 - val_loss: 0.0843\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.0774\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0138 - val_loss: 0.0797\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0139 - val_loss: 0.0776\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0760\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0769\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0818\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0135 - val_loss: 0.0749\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0764\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0806\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.0750\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0135 - val_loss: 0.0786\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0138 - val_loss: 0.0752\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0139 - val_loss: 0.0807\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0777\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0137 - val_loss: 0.0767\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0746\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0922\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.0773\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0148 - val_loss: 0.0784\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0136 - val_loss: 0.0807\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0136 - val_loss: 0.0753\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0137 - val_loss: 0.0761\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0137 - val_loss: 0.0896\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0137 - val_loss: 0.0832\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0834\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0814\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0777\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0132 - val_loss: 0.0788\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0133 - val_loss: 0.0819\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0803\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0135 - val_loss: 0.0784\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0131 - val_loss: 0.0738\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0132 - val_loss: 0.0825\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0131 - val_loss: 0.0760\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0817\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0127 - val_loss: 0.0750\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0773\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0787\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0745\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0783\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0136 - val_loss: 0.0848\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0844\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0139 - val_loss: 0.0844\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.0850\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0131 - val_loss: 0.0777\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0819\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0788\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0130 - val_loss: 0.0782\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0130 - val_loss: 0.0895\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0815\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0765\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0133 - val_loss: 0.0793\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0129 - val_loss: 0.0852\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0774\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0131 - val_loss: 0.0797\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0748\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0772\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0798\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0833\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0132 - val_loss: 0.0800\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0759\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0124 - val_loss: 0.0860\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0130 - val_loss: 0.0757\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0130 - val_loss: 0.0780\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0797\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0805\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0831\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0127 - val_loss: 0.0823\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0749\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0131 - val_loss: 0.0806\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0764\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.0830\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0855\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0128 - val_loss: 0.0775\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0810\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0822\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0833\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0811\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0126 - val_loss: 0.0836\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0813\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0796\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0854\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0131 - val_loss: 0.0785\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0818\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0127 - val_loss: 0.0758\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0128 - val_loss: 0.0804\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0126 - val_loss: 0.0799\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [10.32 10.32 10.32 10.38 10.6 ]\n",
            "Predicted_not_normlized [10.38 10.39 10.4  10.39 10.39]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.17486772\n",
            "MSE:  0.07052364\n",
            "RMSE:  0.2655628776834899\n",
            "R2:  0.9598236680030823\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"GACO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXBuyLRXLCIR",
        "outputId": "a3efcc67-6299-4f0e-99cb-4863b9a6ccbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-7-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2.9433349e+09 9.3617434e+08 2.3272646e+08 ... 6.9893285e+06 2.0652268e+07\n",
            " 1.0014314e+07]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.9365795e+09 3.2430423e+09 2.0840685e+09 ... 1.7410878e+07 1.6748700e+07\n",
            " 9.7858370e+06]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '8.694779310034392' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-7-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.580948399942262' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (3374, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (3364, 5, 34)\n",
            "y shape: (3364, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "EMAAR EC_BRNN_1024\n",
            "EMAAR EC_GRU_600\n",
            "EMAAR EC_LSTM_1000\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 4ms/step - loss: 0.1089 - val_loss: 0.1213\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1202\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1200\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1191\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1213\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1191\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1219\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1211\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1248\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1223\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1228\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1222\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1219\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1215\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1269\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1236\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1241\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1235\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1229\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1248\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1254\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1312\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1229\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1226\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1229\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1235\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1250\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1222\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1225\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1232\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1217\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1225\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.1220\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1220\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.1260\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1215\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1259\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1234\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.1260\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.1224\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1228\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1241\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1249\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1288\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1269\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1261\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1239\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1234\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1242\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1298\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1235\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1217\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1235\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1215\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1256\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1262\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1257\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1259\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1228\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1245\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1264\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1251\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1307\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1259\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1250\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1267\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1249\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1344\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1239\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1228\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1228\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1234\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1265\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1249\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1279\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.1274\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1267\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.1248\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1262\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1226\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1231\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0138 - val_loss: 0.1231\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.1258\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.1223\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1252\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1279\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1242\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1239\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1253\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1247\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1257\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1239\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1260\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1246\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1245\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1251\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1283\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.84 9.84 9.84 9.82 9.81]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.23046593\n",
            "MSE:  0.123417035\n",
            "RMSE:  0.35130760701302266\n",
            "R2:  0.9853910803794861\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 4ms/step - loss: 0.1271 - val_loss: 0.1207\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1210\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1212\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1219\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1201\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1311\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1232\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1226\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1221\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1216\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1225\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1237\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1220\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1222\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1289\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1236\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1281\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1245\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1252\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1249\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1236\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1228\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1231\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1372\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.1208\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1263\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1216\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1226\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1216\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1227\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.1255\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1227\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.1230\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.1223\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1235\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1228\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.1211\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1223\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.1245\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1276\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.1229\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1240\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1235\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1227\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1207\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1254\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1255\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1225\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1214\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1226\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1249\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1215\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1230\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1241\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1217\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1221\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1237\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1265\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1215\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1228\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1240\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1225\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1236\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1199\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1216\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1234\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1224\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1224\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1240\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1224\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1209\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1230\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1216\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.1221\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1235\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1269\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1220\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1246\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.1241\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.1214\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1213\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.1227\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1215\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1211\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1237\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1252\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1238\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1247\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1207\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1244\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1265\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1235\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1276\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1207\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1241\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1271\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.86 9.84 9.87 9.85 9.79]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.24198084\n",
            "MSE:  0.13890788\n",
            "RMSE:  0.37270347407958\n",
            "R2:  0.9835574626922607\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 0.1212 - val_loss: 0.1248\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1235\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1240\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1246\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1214\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1221\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1237\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1264\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1254\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1215\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1253\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1215\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1227\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.1231\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1273\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1221\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1233\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1243\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1249\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1320\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1222\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1216\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1269\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1225\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1210\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1223\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1227\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1231\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1285\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1219\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1236\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1216\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1224\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1244\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1245\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1242\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1247\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1234\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1218\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1208\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.1236\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1225\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1206\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.1230\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.1232\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.1226\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.1249\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1246\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1222\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1273\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1244\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1236\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1203\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1240\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1206\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1248\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1222\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1228\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1243\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1249\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1237\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1221\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1266\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1220\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1269\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1248\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1229\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1288\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1249\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1238\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1259\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1248\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1216\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1238\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1233\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1281\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1247\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1234\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1235\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1245\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1240\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1218\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0137 - val_loss: 0.1213\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.1232\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1253\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.1242\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1249\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.1249\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1238\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1244\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1246\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1236\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1256\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1234\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1249\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1225\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1233\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1237\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.83 9.85 9.79 9.82 9.85]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.22216327\n",
            "MSE:  0.11404808\n",
            "RMSE:  0.337710051162527\n",
            "R2:  0.986500084400177\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 4ms/step - loss: 0.1415 - val_loss: 0.1310\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1311\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1316\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1320\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1317\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1340\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1336\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1354\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1325\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1338\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1329\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1340\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1342\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1346\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1360\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1334\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1340\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1344\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1344\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1340\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1346\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1331\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1364\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1351\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1352\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1331\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.1350\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.1352\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.1340\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.1357\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.1361\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.1336\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.1349\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.1341\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.1373\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.1361\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.1377\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1379\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1351\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1348\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1357\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1334\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1361\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1347\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1337\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1340\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1359\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1336\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1355\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1341\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1353\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1339\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1371\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1359\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1347\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1391\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1373\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1361\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1337\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1363\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1345\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1337\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1345\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1359\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1341\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1361\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1388\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1329\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1335\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.1369\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0143 - val_loss: 0.1352\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.1368\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.1359\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.1331\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.1347\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 0.0142 - val_loss: 0.1347\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.1335\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.1327\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.1341\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.1343\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1329\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1346\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1343\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1324\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1353\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1354\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1326\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1352\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1325\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1368\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1328\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1338\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1329\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1335\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1343\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1341\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1321\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1338\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1339\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1335\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.87 9.87 9.86 9.87 9.84]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.23050234\n",
            "MSE:  0.1159812\n",
            "RMSE:  0.3405601251575026\n",
            "R2:  0.986271321773529\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 15ms/step - loss: 0.1632 - val_loss: 0.1400\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0169 - val_loss: 0.1284\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1260\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0147 - val_loss: 0.1261\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1258\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1242\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1275\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1237\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1244\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0141 - val_loss: 0.1243\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0140 - val_loss: 0.1244\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 2s 20ms/step - loss: 0.0140 - val_loss: 0.1239\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1244\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1221\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1216\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1220\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.1212\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1223\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1203\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.1226\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1215\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0140 - val_loss: 0.1201\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0140 - val_loss: 0.1281\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0200 - val_loss: 0.1218\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0139 - val_loss: 0.1191\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0147 - val_loss: 0.1224\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1233\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1246\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1235\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.1269\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0150 - val_loss: 0.1197\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1210\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1194\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0139 - val_loss: 0.1229\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0141 - val_loss: 0.1201\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0138 - val_loss: 0.1222\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0143 - val_loss: 0.1208\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1202\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1234\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1210\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1220\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1213\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1207\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1241\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1228\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0146 - val_loss: 0.1206\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0142 - val_loss: 0.1239\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0142 - val_loss: 0.1243\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0137 - val_loss: 0.1219\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1217\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1250\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1204\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1207\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1203\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1248\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1225\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1213\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1189\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0139 - val_loss: 0.1202\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0138 - val_loss: 0.1202\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0138 - val_loss: 0.1206\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0143 - val_loss: 0.1229\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1204\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1237\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1234\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1228\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1215\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1222\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1200\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0138 - val_loss: 0.1210\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1232\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0139 - val_loss: 0.1221\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0139 - val_loss: 0.1193\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1231\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1251\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1192\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1213\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1210\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1215\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1234\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1238\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0137 - val_loss: 0.1219\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0139 - val_loss: 0.1237\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0151 - val_loss: 0.1216\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1221\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1195\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1204\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1202\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1257\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0133 - val_loss: 0.1210\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1215\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0135 - val_loss: 0.1216\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.0137 - val_loss: 0.1222\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0134 - val_loss: 0.1237\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0135 - val_loss: 0.1227\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1212\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1220\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.84 9.84 9.85 9.84 9.83]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.22746602\n",
            "MSE:  0.11742978\n",
            "RMSE:  0.34268028536793704\n",
            "R2:  0.9860997796058655\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_17 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 3s 18ms/step - loss: 0.1558 - val_loss: 0.1366\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0151 - val_loss: 0.1284\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0144 - val_loss: 0.1310\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0144 - val_loss: 0.1257\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1271\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.1251\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1276\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1239\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1219\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1236\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1203\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1216\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0143 - val_loss: 0.1240\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.0145 - val_loss: 0.1197\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0143 - val_loss: 0.1226\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0144 - val_loss: 0.1235\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1205\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1217\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0154 - val_loss: 0.1225\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1240\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1190\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1234\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1208\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1225\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0140 - val_loss: 0.1222\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0140 - val_loss: 0.1228\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0146 - val_loss: 0.1183\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0142 - val_loss: 0.1231\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1235\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1190\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1216\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1241\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1196\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1208\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1199\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0146 - val_loss: 0.1297\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0141 - val_loss: 0.1208\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0140 - val_loss: 0.1234\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0137 - val_loss: 0.1210\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1225\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1231\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1220\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1243\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1187\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1244\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1193\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1197\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1209\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0139 - val_loss: 0.1215\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0138 - val_loss: 0.1234\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1227\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1197\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1237\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1203\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1206\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1207\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1225\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1215\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1221\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0138 - val_loss: 0.1188\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0135 - val_loss: 0.1210\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1247\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1214\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1202\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1204\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1259\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1205\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1220\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1205\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0140 - val_loss: 0.1203\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0138 - val_loss: 0.1219\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0136 - val_loss: 0.1205\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0139 - val_loss: 0.1200\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1215\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1184\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1259\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1197\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1191\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1229\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1234\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1224\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0134 - val_loss: 0.1188\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0135 - val_loss: 0.1188\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0145 - val_loss: 0.1229\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1211\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1233\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1198\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1198\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0133 - val_loss: 0.1228\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1236\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1236\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1206\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1205\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0138 - val_loss: 0.1210\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0136 - val_loss: 0.1221\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.9  9.88 9.88 9.89 9.87]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.23177898\n",
            "MSE:  0.11883603\n",
            "RMSE:  0.3447260221741848\n",
            "R2:  0.9859333634376526\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_18 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 17ms/step - loss: 0.2154 - val_loss: 0.1399\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0170 - val_loss: 0.1327\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.1284\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1269\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1264\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.1295\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1305\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0150 - val_loss: 0.1267\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0152 - val_loss: 0.1238\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0142 - val_loss: 0.1233\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0142 - val_loss: 0.1248\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1252\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0159 - val_loss: 0.1237\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1222\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1236\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1234\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1245\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1247\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1223\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1248\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1214\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0147 - val_loss: 0.1239\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0140 - val_loss: 0.1246\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0155 - val_loss: 0.1215\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0141 - val_loss: 0.1197\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0147 - val_loss: 0.1265\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1220\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1214\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1204\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1205\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1208\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1224\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0142 - val_loss: 0.1225\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0139 - val_loss: 0.1263\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0142 - val_loss: 0.1214\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0142 - val_loss: 0.1245\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1221\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1214\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1260\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1242\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1240\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1252\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1222\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1222\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0140 - val_loss: 0.1225\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0143 - val_loss: 0.1208\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0138 - val_loss: 0.1231\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0142 - val_loss: 0.1221\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1234\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1233\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1234\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1197\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1201\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1222\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1210\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1218\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0141 - val_loss: 0.1227\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0140 - val_loss: 0.1225\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0136 - val_loss: 0.1220\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0145 - val_loss: 0.1207\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1234\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1196\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1201\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1206\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1211\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1229\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1194\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1222\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1213\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0136 - val_loss: 0.1224\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0137 - val_loss: 0.1194\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0140 - val_loss: 0.1219\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1236\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1205\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1209\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1213\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1237\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1222\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.1198\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0139 - val_loss: 0.1209\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0141 - val_loss: 0.1207\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0135 - val_loss: 0.1226\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0139 - val_loss: 0.1240\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0139 - val_loss: 0.1213\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0139 - val_loss: 0.1218\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1215\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1237\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.1225\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1209\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1215\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1185\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0138 - val_loss: 0.1225\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0143 - val_loss: 0.1216\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0138 - val_loss: 0.1257\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0139 - val_loss: 0.1239\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0140 - val_loss: 0.1220\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0135 - val_loss: 0.1204\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1213\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.88 9.9  9.9  9.9  9.87]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.2275461\n",
            "MSE:  0.11505629\n",
            "RMSE:  0.3391994858819399\n",
            "R2:  0.9863807559013367\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_19 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 20ms/step - loss: 0.1939 - val_loss: 0.1481\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0262 - val_loss: 0.1418\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0159 - val_loss: 0.1361\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1360\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1337\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1346\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1344\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1350\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1348\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1345\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1330\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0149 - val_loss: 0.1355\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.0151 - val_loss: 0.1339\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0155 - val_loss: 0.1342\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0151 - val_loss: 0.1337\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0145 - val_loss: 0.1335\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1345\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1317\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1360\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1333\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1333\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1350\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1334\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1343\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0148 - val_loss: 0.1336\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0153 - val_loss: 0.1315\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0144 - val_loss: 0.1329\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0148 - val_loss: 0.1344\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1328\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1345\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0150 - val_loss: 0.1337\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1332\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1335\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1310\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1340\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1349\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0147 - val_loss: 0.1325\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1349\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0151 - val_loss: 0.1369\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0152 - val_loss: 0.1338\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1319\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1339\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1351\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1366\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0149 - val_loss: 0.1353\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1331\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1334\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1337\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0145 - val_loss: 0.1343\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0149 - val_loss: 0.1349\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0145 - val_loss: 0.1322\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0148 - val_loss: 0.1342\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1337\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1333\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1319\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1319\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1341\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1323\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1334\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0153 - val_loss: 0.1322\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0147 - val_loss: 0.1333\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1325\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.0146 - val_loss: 0.1320\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1336\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1361\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1331\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1332\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1322\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1333\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1328\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1330\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0147 - val_loss: 0.1344\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0148 - val_loss: 0.1334\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0144 - val_loss: 0.1353\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0147 - val_loss: 0.1344\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0145 - val_loss: 0.1354\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1326\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1342\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1331\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1344\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.1336\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0145 - val_loss: 0.1327\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0147 - val_loss: 0.1365\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0146 - val_loss: 0.1320\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1339\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0145 - val_loss: 0.1333\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0147 - val_loss: 0.1330\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1327\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1337\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1347\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1334\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1345\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1382\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1343\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - val_loss: 0.1320\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0148 - val_loss: 0.1324\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1334\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0142 - val_loss: 0.1323\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.0143 - val_loss: 0.1343\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1348\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.78 9.79 9.76 9.76 9.76]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.22993031\n",
            "MSE:  0.11714566\n",
            "RMSE:  0.34226547815893976\n",
            "R2:  0.9861335158348083\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_15 (GRU)                (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 16ms/step - loss: 0.1622 - val_loss: 0.1320\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0149 - val_loss: 0.1276\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0143 - val_loss: 0.1301\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1267\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1268\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1268\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1279\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1261\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1285\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1266\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1257\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1265\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1251\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0141 - val_loss: 0.1240\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0142 - val_loss: 0.1244\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0142 - val_loss: 0.1249\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0142 - val_loss: 0.1233\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0141 - val_loss: 0.1256\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1245\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1262\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1240\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1233\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1218\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1238\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1233\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1233\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1232\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1203\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1220\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0145 - val_loss: 0.1203\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0141 - val_loss: 0.1219\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1242\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0138 - val_loss: 0.1211\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0141 - val_loss: 0.1213\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1216\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1209\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1218\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1276\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1222\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1215\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1201\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1237\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1217\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1194\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0139 - val_loss: 0.1212\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1202\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1219\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1241\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1229\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1197\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1232\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1219\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1203\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1234\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1219\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1224\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1240\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1219\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0136 - val_loss: 0.1216\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1215\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1232\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0135 - val_loss: 0.1219\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1223\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0134 - val_loss: 0.1216\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1222\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1215\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1211\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1225\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1226\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1226\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1214\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1243\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1241\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1223\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0132 - val_loss: 0.1206\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0139 - val_loss: 0.1224\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0134 - val_loss: 0.1228\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1232\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1222\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0133 - val_loss: 0.1239\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1233\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.1211\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.1226\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1213\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1228\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1249\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1228\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1235\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.1233\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.1227\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1243\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0131 - val_loss: 0.1232\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1231\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0133 - val_loss: 0.1250\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1237\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1230\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.1263\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1240\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.1237\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.88 9.88 9.85 9.84 9.82]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.2231112\n",
            "MSE:  0.11121504\n",
            "RMSE:  0.33348919036109687\n",
            "R2:  0.9868354797363281\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_16 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 3s 11ms/step - loss: 0.1236 - val_loss: 0.1237\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1239\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.1252\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1217\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1223\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0143 - val_loss: 0.1225\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0139 - val_loss: 0.1223\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1235\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0140 - val_loss: 0.1219\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0142 - val_loss: 0.1236\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1231\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1200\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1198\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1200\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1206\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1230\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1228\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.1206\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1259\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1239\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1220\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0137 - val_loss: 0.1221\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0141 - val_loss: 0.1188\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0140 - val_loss: 0.1197\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0140 - val_loss: 0.1215\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0139 - val_loss: 0.1219\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1216\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1211\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1226\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.1210\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.1193\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1210\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1197\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1213\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.1197\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1220\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.1207\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0140 - val_loss: 0.1221\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1211\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0138 - val_loss: 0.1201\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0135 - val_loss: 0.1204\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0138 - val_loss: 0.1215\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0139 - val_loss: 0.1238\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1211\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1201\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1224\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1213\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0137 - val_loss: 0.1206\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1208\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1199\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.1221\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1225\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1219\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1228\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1182\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1202\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0140 - val_loss: 0.1221\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0137 - val_loss: 0.1198\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1218\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1227\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1209\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1194\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1222\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1189\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1206\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1216\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1210\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1191\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1185\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0137 - val_loss: 0.1225\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0136 - val_loss: 0.1190\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1195\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0137 - val_loss: 0.1210\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0134 - val_loss: 0.1201\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1219\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1224\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1197\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1212\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1203\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.1199\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1214\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1214\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.1207\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1209\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1208\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1191\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1207\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0135 - val_loss: 0.1209\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0134 - val_loss: 0.1216\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0136 - val_loss: 0.1206\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1225\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1204\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.1218\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1215\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1237\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.1219\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1213\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1202\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1195\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.1212\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.85 9.83 9.83 9.83 9.84]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.22062424\n",
            "MSE:  0.11187645\n",
            "RMSE:  0.3344793722773209\n",
            "R2:  0.9867571592330933\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_17 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 18ms/step - loss: 0.1934 - val_loss: 0.1393\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0160 - val_loss: 0.1282\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1293\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1277\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1258\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1279\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1259\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1265\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0150 - val_loss: 0.1250\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1253\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1258\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0166 - val_loss: 0.1246\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0142 - val_loss: 0.1246\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0139 - val_loss: 0.1239\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0140 - val_loss: 0.1270\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0143 - val_loss: 0.1225\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1278\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1242\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1230\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1225\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1236\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1224\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1231\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.1231\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1220\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1228\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0138 - val_loss: 0.1220\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0141 - val_loss: 0.1232\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0139 - val_loss: 0.1218\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0138 - val_loss: 0.1233\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1249\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1216\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1230\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1226\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1260\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1227\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1279\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1244\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.1224\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0142 - val_loss: 0.1228\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0136 - val_loss: 0.1225\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1221\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0138 - val_loss: 0.1226\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1240\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0145 - val_loss: 0.1225\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1233\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1232\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.1229\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1230\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.1269\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0134 - val_loss: 0.1223\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1229\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1262\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1221\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1225\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0137 - val_loss: 0.1215\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0136 - val_loss: 0.1237\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0135 - val_loss: 0.1220\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1224\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0135 - val_loss: 0.1234\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1217\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1231\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0134 - val_loss: 0.1225\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1230\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1237\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1227\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1236\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1231\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0140 - val_loss: 0.1215\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0138 - val_loss: 0.1229\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1244\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0135 - val_loss: 0.1239\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0141 - val_loss: 0.1234\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0136 - val_loss: 0.1225\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1230\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1230\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.1239\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1240\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.1247\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0140 - val_loss: 0.1239\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1238\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0133 - val_loss: 0.1242\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0134 - val_loss: 0.1238\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0137 - val_loss: 0.1244\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0136 - val_loss: 0.1258\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0134 - val_loss: 0.1237\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0138 - val_loss: 0.1229\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0133 - val_loss: 0.1247\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0137 - val_loss: 0.1230\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0132 - val_loss: 0.1246\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1234\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1258\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1269\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0139 - val_loss: 0.1241\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0134 - val_loss: 0.1238\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0135 - val_loss: 0.1239\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.1241\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0134 - val_loss: 0.1260\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0133 - val_loss: 0.1274\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0134 - val_loss: 0.1282\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.84 9.83 9.8  9.79 9.81]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.22666943\n",
            "MSE:  0.1169651\n",
            "RMSE:  0.3420016084306941\n",
            "R2:  0.9861548542976379\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_18 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 3s 13ms/step - loss: 0.1670 - val_loss: 0.1426\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0151 - val_loss: 0.1426\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0148 - val_loss: 0.1397\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0149 - val_loss: 0.1404\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0146 - val_loss: 0.1417\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0148 - val_loss: 0.1398\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0152 - val_loss: 0.1404\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.1389\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1417\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.1401\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1390\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0155 - val_loss: 0.1386\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1400\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1393\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1385\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.1427\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0146 - val_loss: 0.1402\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0148 - val_loss: 0.1408\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0146 - val_loss: 0.1400\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1377\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.1407\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1407\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.1414\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1391\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1366\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1381\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1384\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.1403\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1379\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1397\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0145 - val_loss: 0.1398\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0144 - val_loss: 0.1379\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1393\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0146 - val_loss: 0.1412\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0150 - val_loss: 0.1390\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1381\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1398\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1402\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1385\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1388\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1379\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1368\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1382\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1381\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1388\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0145 - val_loss: 0.1386\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0146 - val_loss: 0.1388\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0143 - val_loss: 0.1378\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0144 - val_loss: 0.1365\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0146 - val_loss: 0.1399\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 0.0143 - val_loss: 0.1378\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1373\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1381\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1384\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1390\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1382\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1392\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1397\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1392\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1376\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1386\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0141 - val_loss: 0.1386\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1378\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0146 - val_loss: 0.1383\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0148 - val_loss: 0.1396\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 0.0142 - val_loss: 0.1377\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1363\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1376\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0146 - val_loss: 0.1387\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1381\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1369\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1365\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1370\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1370\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1384\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0144 - val_loss: 0.1386\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0142 - val_loss: 0.1368\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0141 - val_loss: 0.1382\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0144 - val_loss: 0.1378\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1377\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.1389\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1366\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1359\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1374\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1373\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1365\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1354\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1379\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0144 - val_loss: 0.1351\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1374\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0142 - val_loss: 0.1366\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0142 - val_loss: 0.1351\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.0143 - val_loss: 0.1361\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.0140 - val_loss: 0.1357\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.0141 - val_loss: 0.1377\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1362\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1343\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1363\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.0143 - val_loss: 0.1360\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1351\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [9.76 9.76 9.76 9.91 9.71]\n",
            "Predicted_not_normlized [9.82 9.78 9.78 9.79 9.78]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.22015119\n",
            "MSE:  0.10865955\n",
            "RMSE:  0.3296354813238402\n",
            "R2:  0.987138032913208\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"EMAAR EC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ZCwAdmaLCIR",
        "outputId": "aa73761b-51d0-458b-96eb-1841e1f2278e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-7-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 316177.03    17490.201   53645.805 ... 2453663.8   2737328.5\n",
            " 1359601.   ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  79106.305  544345.8    103876.51  ... 2063065.4   2230830.8\n",
            " 1354219.5  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-7-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.789691886246692' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-7-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-7-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '3.1000000635782876' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5088, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5078, 5, 34)\n",
            "y shape: (5078, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "FITAIHI GROUP_BRNN_200\n",
            "FITAIHI GROUP_GRU_512\n",
            "FITAIHI GROUP_LSTM_900\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.1051 - val_loss: 0.0701\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0730\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0681\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0717\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0724\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0712\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0720\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0730\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0705\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0713\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0722\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0753\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0730\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0747\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0728\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0726\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0732\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0182 - val_loss: 0.0722\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0728\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0729\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0745\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0191 - val_loss: 0.0729\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0783\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0745\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0741\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0732\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0733\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0730\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0753\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0750\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0746\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0745\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0751\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0773\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0751\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0743\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0760\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0785\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0772\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0773\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0760\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0745\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0784\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0834\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0769\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0782\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0744\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0780\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0755\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0754\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0771\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0752\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0759\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0763\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0756\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0778\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0773\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0766\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0773\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0756\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0755\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0770\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0754\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0770\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0764\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0787\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0754\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0788\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0773\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0801\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0790\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0790\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0780\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0753\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0847\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0788\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0778\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0778\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0756\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0771\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0761\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0785\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0762\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0772\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0813\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0765\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0790\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0775\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0789\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0776\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0800\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0778\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0771\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0782\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0777\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0770\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0800\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0798\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0815\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0773\n",
            "36/36 [==============================] - 0s 1ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.12 11.12 11.12 11.11 11.13]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.13343127\n",
            "MSE:  0.040120568\n",
            "RMSE:  0.2003011935222555\n",
            "R2:  0.9439670443534851\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0730\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0693\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0702\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0701\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0700\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0711\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0713\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0713\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0704\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0707\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0729\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0700\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0710\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0741\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0723\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0717\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0734\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0767\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0730\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0748\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0758\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0733\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0732\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0744\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0733\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0737\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0744\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0750\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0735\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0753\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0750\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0746\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0740\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0758\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0743\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0740\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0746\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0745\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0745\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0750\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0759\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0752\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0749\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0757\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0767\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0752\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0767\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0770\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0744\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0750\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0760\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0783\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0750\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0753\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0739\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0774\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0752\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0752\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0804\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0766\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0760\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0758\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0758\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0754\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0763\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0747\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0764\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0769\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0779\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0748\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0760\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0794\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0764\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0761\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0751\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0787\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0763\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0769\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0767\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0756\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0763\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0764\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0764\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0760\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0783\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0783\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0772\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0785\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0784\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0767\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0763\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0758\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0772\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0794\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0769\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0769\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0788\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0804\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0762\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0773\n",
            "36/36 [==============================] - 0s 1ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.11 11.12 11.12 11.14 11.14]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.13229561\n",
            "MSE:  0.040597647\n",
            "RMSE:  0.2014885789034023\n",
            "R2:  0.9433007836341858\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.1093 - val_loss: 0.0686\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0708\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0691\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0716\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0711\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0713\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0719\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0722\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0785\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0729\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0724\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0738\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0753\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0183 - val_loss: 0.0735\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0748\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0756\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0184 - val_loss: 0.0799\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0787\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0739\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0741\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0765\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0742\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0758\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0769\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0774\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0751\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0739\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0781\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0754\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0762\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0746\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0749\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0766\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0783\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0753\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0751\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0827\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0755\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0759\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0789\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0759\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0755\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0767\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0767\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0795\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0775\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0187 - val_loss: 0.0810\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0774\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0770\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0776\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0777\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0784\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0795\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0783\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0767\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0781\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0787\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0777\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0761\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0767\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0780\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0766\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0797\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0781\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0786\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0776\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0776\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0768\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0759\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0780\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0796\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0777\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0774\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0774\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0783\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0764\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0784\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0766\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0781\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0822\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0798\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0760\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0772\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0784\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0771\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0801\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0782\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0771\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0797\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0779\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0775\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0805\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0798\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0783\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0781\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0770\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0779\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0782\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0772\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0775\n",
            "36/36 [==============================] - 0s 1ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.1  11.1  11.11 11.11 11.12]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.13101217\n",
            "MSE:  0.039781116\n",
            "RMSE:  0.19945203922034466\n",
            "R2:  0.9444411993026733\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_24 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0557 - val_loss: 0.0746\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0679\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0694\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0724\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0681\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0677\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0687\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0670\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0672\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0677\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0733\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0678\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0199 - val_loss: 0.0692\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0196 - val_loss: 0.0684\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0677\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0202 - val_loss: 0.0675\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0676\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0699\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0673\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0683\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0689\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0670\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0667\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0796\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0681\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0680\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0675\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0668\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0699\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0687\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0712\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0672\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0671\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0671\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0687\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0677\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0702\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0673\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0682\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0673\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0677\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0683\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0695\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0685\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0670\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0676\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0678\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0666\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0687\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0671\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0685\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0723\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0678\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0674\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0687\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0679\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0670\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0705\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0671\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0675\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0692\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0688\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0674\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0698\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0674\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0682\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0668\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0668\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0691\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0677\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0703\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0672\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0679\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0682\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0673\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0192 - val_loss: 0.0675\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0674\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0190 - val_loss: 0.0672\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0684\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0670\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0701\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0672\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0194 - val_loss: 0.0675\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0672\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0689\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0672\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0677\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0670\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0673\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0669\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0695\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0673\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0670\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0672\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0677\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0676\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0681\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0679\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0671\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0669\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.12 11.12 11.11 11.1  11.1 ]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.1252574\n",
            "MSE:  0.036004685\n",
            "RMSE:  0.18974900491300264\n",
            "R2:  0.9497153759002686\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 11ms/step - loss: 0.1213 - val_loss: 0.0974\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0196 - val_loss: 0.0796\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0191 - val_loss: 0.0767\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0199 - val_loss: 0.0716\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0759\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0204 - val_loss: 0.0728\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0202 - val_loss: 0.0723\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0195 - val_loss: 0.0731\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0188 - val_loss: 0.0702\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0194 - val_loss: 0.0690\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0198 - val_loss: 0.0701\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0201 - val_loss: 0.0702\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0715\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0195 - val_loss: 0.0695\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0188 - val_loss: 0.0713\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0693\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0190 - val_loss: 0.0696\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0756\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0191 - val_loss: 0.0696\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0183 - val_loss: 0.0698\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0190 - val_loss: 0.0699\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0189 - val_loss: 0.0695\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0190 - val_loss: 0.0695\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0191 - val_loss: 0.0701\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0193 - val_loss: 0.0708\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0183 - val_loss: 0.0730\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0184 - val_loss: 0.0725\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0180 - val_loss: 0.0722\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0183 - val_loss: 0.0722\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0190 - val_loss: 0.0701\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0181 - val_loss: 0.0694\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0193 - val_loss: 0.0720\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0708\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0177 - val_loss: 0.0739\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0721\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0704\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0181 - val_loss: 0.0732\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0186 - val_loss: 0.0706\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0715\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0708\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0697\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0712\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0183 - val_loss: 0.0713\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0714\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0184 - val_loss: 0.0702\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0187 - val_loss: 0.0724\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0183 - val_loss: 0.0708\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0700\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0737\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0706\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0185 - val_loss: 0.0715\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0714\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0705\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0178 - val_loss: 0.0714\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0185 - val_loss: 0.0717\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0720\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0184 - val_loss: 0.0705\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0183 - val_loss: 0.0727\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0726\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0180 - val_loss: 0.0758\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0722\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0179 - val_loss: 0.0705\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0178 - val_loss: 0.0713\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0720\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0715\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0182 - val_loss: 0.0722\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0181 - val_loss: 0.0709\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0721\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0177 - val_loss: 0.0730\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0726\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0180 - val_loss: 0.0739\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0179 - val_loss: 0.0731\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0177 - val_loss: 0.0749\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0714\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0733\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0184 - val_loss: 0.0764\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0715\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0183 - val_loss: 0.0733\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0175 - val_loss: 0.0716\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0177 - val_loss: 0.0727\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0727\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0735\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0757\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0716\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0773\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0177 - val_loss: 0.0719\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0716\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0179 - val_loss: 0.0725\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0180 - val_loss: 0.0726\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0178 - val_loss: 0.0715\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0181 - val_loss: 0.0740\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0176 - val_loss: 0.0726\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0736\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0746\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0177 - val_loss: 0.0735\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0181 - val_loss: 0.0751\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0175 - val_loss: 0.0744\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0177 - val_loss: 0.0734\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0730\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0176 - val_loss: 0.0731\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.1  11.1  11.11 11.11 11.12]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.1301966\n",
            "MSE:  0.038649946\n",
            "RMSE:  0.19659589632336463\n",
            "R2:  0.9460209608078003\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_21 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 12ms/step - loss: 0.1139 - val_loss: 0.1074\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0202 - val_loss: 0.0924\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0194 - val_loss: 0.0922\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0196 - val_loss: 0.0877\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0188 - val_loss: 0.0821\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0193 - val_loss: 0.0771\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0198 - val_loss: 0.0809\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0189 - val_loss: 0.0734\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0184 - val_loss: 0.0750\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0206 - val_loss: 0.0858\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0188 - val_loss: 0.0771\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0197 - val_loss: 0.0889\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0858\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0186 - val_loss: 0.0759\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0733\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0774\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0742\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0196 - val_loss: 0.0735\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0186 - val_loss: 0.0717\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0189 - val_loss: 0.0744\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0715\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0708\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0185 - val_loss: 0.0745\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0719\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0185 - val_loss: 0.0711\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0730\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0184 - val_loss: 0.0708\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0189 - val_loss: 0.0718\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0185 - val_loss: 0.0714\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0728\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0717\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0706\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0191 - val_loss: 0.0737\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0707\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0181 - val_loss: 0.0732\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0183 - val_loss: 0.0723\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0186 - val_loss: 0.0713\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0183 - val_loss: 0.0709\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0743\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0716\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0186 - val_loss: 0.0711\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0717\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0180 - val_loss: 0.0725\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0181 - val_loss: 0.0730\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0182 - val_loss: 0.0720\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0718\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0714\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0738\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0184 - val_loss: 0.0710\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0745\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0178 - val_loss: 0.0719\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0726\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0177 - val_loss: 0.0713\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.0725\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0715\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0729\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0712\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0719\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0183 - val_loss: 0.0719\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0762\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0721\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0183 - val_loss: 0.0766\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0734\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0743\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0715\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0718\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0725\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0181 - val_loss: 0.0730\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0181 - val_loss: 0.0735\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0178 - val_loss: 0.0729\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0723\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0176 - val_loss: 0.0722\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0741\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0174 - val_loss: 0.0757\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0727\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0179 - val_loss: 0.0716\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0180 - val_loss: 0.0722\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0737\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0176 - val_loss: 0.0730\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0717\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0725\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0722\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0725\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0176 - val_loss: 0.0721\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0177 - val_loss: 0.0743\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0175 - val_loss: 0.0734\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0727\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0752\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0720\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0739\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0176 - val_loss: 0.0730\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0177 - val_loss: 0.0721\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0175 - val_loss: 0.0731\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0175 - val_loss: 0.0732\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0732\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0175 - val_loss: 0.0736\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0758\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0175 - val_loss: 0.0726\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0178 - val_loss: 0.0736\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.14 11.14 11.13 11.13 11.13]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.1367792\n",
            "MSE:  0.039296687\n",
            "RMSE:  0.19823391901822077\n",
            "R2:  0.9451176524162292\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_22 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 16ms/step - loss: 0.1124 - val_loss: 0.1056\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0866\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0218 - val_loss: 0.0881\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0879\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0193 - val_loss: 0.0809\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0190 - val_loss: 0.0794\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0192 - val_loss: 0.0766\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0191 - val_loss: 0.0735\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0203 - val_loss: 0.0774\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0204 - val_loss: 0.0832\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0726\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0197 - val_loss: 0.0749\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0207 - val_loss: 0.0707\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0185 - val_loss: 0.0718\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0196 - val_loss: 0.0710\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0194 - val_loss: 0.0745\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0199 - val_loss: 0.0719\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0185 - val_loss: 0.0703\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0695\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0707\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0751\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0731\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0185 - val_loss: 0.0714\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0193 - val_loss: 0.0717\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0186 - val_loss: 0.0696\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0728\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0721\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0730\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0698\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0192 - val_loss: 0.0710\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0184 - val_loss: 0.0723\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0185 - val_loss: 0.0697\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0179 - val_loss: 0.0721\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0709\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0710\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0720\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0705\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0715\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0184 - val_loss: 0.0701\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0184 - val_loss: 0.0713\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0180 - val_loss: 0.0710\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0182 - val_loss: 0.0703\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0746\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0185 - val_loss: 0.0708\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0713\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0728\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0705\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0185 - val_loss: 0.0702\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0183 - val_loss: 0.0705\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0181 - val_loss: 0.0712\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0179 - val_loss: 0.0739\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 4s 26ms/step - loss: 0.0182 - val_loss: 0.0730\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0185 - val_loss: 0.0709\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0180 - val_loss: 0.0732\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0180 - val_loss: 0.0716\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0191 - val_loss: 0.0709\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0715\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0183 - val_loss: 0.0711\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0713\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0733\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0714\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0182 - val_loss: 0.0710\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0181 - val_loss: 0.0714\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0177 - val_loss: 0.0725\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0737\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0715\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0726\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0723\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0183 - val_loss: 0.0715\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0177 - val_loss: 0.0723\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0179 - val_loss: 0.0724\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0178 - val_loss: 0.0717\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0183 - val_loss: 0.0717\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0725\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0744\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0723\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0715\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0180 - val_loss: 0.0723\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0179 - val_loss: 0.0738\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0177 - val_loss: 0.0725\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0728\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0748\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0740\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0753\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0728\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0732\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0185 - val_loss: 0.0734\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0177 - val_loss: 0.0732\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0178 - val_loss: 0.0739\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0731\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0176 - val_loss: 0.0731\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0746\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0723\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0757\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0178 - val_loss: 0.0729\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0178 - val_loss: 0.0751\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0173 - val_loss: 0.0726\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0742\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0741\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0726\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.13 11.13 11.13 11.13 11.13]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.13000527\n",
            "MSE:  0.038294107\n",
            "RMSE:  0.19568880070632058\n",
            "R2:  0.9465178847312927\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_23 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 15ms/step - loss: 0.1167 - val_loss: 0.0963\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0202 - val_loss: 0.0827\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0202 - val_loss: 0.0826\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0199 - val_loss: 0.0733\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0201 - val_loss: 0.0719\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0205 - val_loss: 0.0793\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0211 - val_loss: 0.0716\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0761\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0206 - val_loss: 0.0766\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0213 - val_loss: 0.0722\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0193 - val_loss: 0.0692\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0210 - val_loss: 0.0741\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0199 - val_loss: 0.0685\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0692\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0196 - val_loss: 0.0688\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0760\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0196 - val_loss: 0.0700\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0194 - val_loss: 0.0675\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0198 - val_loss: 0.0691\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0678\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0680\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0195 - val_loss: 0.0692\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0198 - val_loss: 0.0678\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0196 - val_loss: 0.0684\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0196 - val_loss: 0.0674\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0197 - val_loss: 0.0679\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0196 - val_loss: 0.0677\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0718\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0677\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0681\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0193 - val_loss: 0.0681\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0678\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0195 - val_loss: 0.0704\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0193 - val_loss: 0.0685\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0189 - val_loss: 0.0687\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0191 - val_loss: 0.0679\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0677\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0198 - val_loss: 0.0671\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0199 - val_loss: 0.0691\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0673\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0188 - val_loss: 0.0689\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0192 - val_loss: 0.0670\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0192 - val_loss: 0.0672\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0192 - val_loss: 0.0678\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0671\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0194 - val_loss: 0.0700\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0200 - val_loss: 0.0691\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0674\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0196 - val_loss: 0.0673\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0190 - val_loss: 0.0677\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0187 - val_loss: 0.0683\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0188 - val_loss: 0.0673\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0669\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0676\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0669\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0681\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0189 - val_loss: 0.0675\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0188 - val_loss: 0.0670\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0191 - val_loss: 0.0681\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0191 - val_loss: 0.0681\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0682\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0191 - val_loss: 0.0668\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0670\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0192 - val_loss: 0.0683\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0682\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0190 - val_loss: 0.0672\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0191 - val_loss: 0.0675\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0190 - val_loss: 0.0681\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0674\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0683\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0695\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0693\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0191 - val_loss: 0.0699\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0675\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0191 - val_loss: 0.0673\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0186 - val_loss: 0.0673\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0671\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0673\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0672\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.0683\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0186 - val_loss: 0.0670\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0192 - val_loss: 0.0680\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0188 - val_loss: 0.0685\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0189 - val_loss: 0.0672\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0668\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0189 - val_loss: 0.0684\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0681\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.0666\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0698\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0187 - val_loss: 0.0666\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0191 - val_loss: 0.0699\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0190 - val_loss: 0.0674\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0185 - val_loss: 0.0670\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0676\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0681\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0704\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0678\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0191 - val_loss: 0.0675\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0189 - val_loss: 0.0673\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0187 - val_loss: 0.0697\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.12 11.13 11.12 11.12 11.12]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.12836005\n",
            "MSE:  0.037948232\n",
            "RMSE:  0.1948030598941335\n",
            "R2:  0.9470009803771973\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_19 (GRU)                (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 10ms/step - loss: 0.0803 - val_loss: 0.0714\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0190 - val_loss: 0.0707\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0794\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0191 - val_loss: 0.0684\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0197 - val_loss: 0.0717\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0696\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0690\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0723\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0686\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0687\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0691\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0696\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0188 - val_loss: 0.0700\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0181 - val_loss: 0.0700\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0182 - val_loss: 0.0728\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0191 - val_loss: 0.0704\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0708\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0712\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0743\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0714\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0708\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0713\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0709\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0181 - val_loss: 0.0721\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0183 - val_loss: 0.0722\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0181 - val_loss: 0.0713\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0721\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0713\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0726\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0728\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0736\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0732\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0743\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0180 - val_loss: 0.0732\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0182 - val_loss: 0.0717\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0181 - val_loss: 0.0754\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0722\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0727\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0746\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0723\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0740\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0730\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0730\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0177 - val_loss: 0.0740\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0738\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0178 - val_loss: 0.0730\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0727\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0734\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0737\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0753\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0740\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0758\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0728\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0179 - val_loss: 0.0735\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0176 - val_loss: 0.0734\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0740\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0738\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0742\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0749\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0731\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0755\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0731\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0181 - val_loss: 0.0745\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0179 - val_loss: 0.0752\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0180 - val_loss: 0.0757\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0733\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0738\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0737\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0738\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0727\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0738\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0735\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0735\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0175 - val_loss: 0.0757\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0174 - val_loss: 0.0750\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0725\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0745\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0742\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0738\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0740\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0738\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0746\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0180 - val_loss: 0.0735\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0175 - val_loss: 0.0745\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0175 - val_loss: 0.0751\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0734\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0745\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0757\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0732\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0741\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0751\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0176 - val_loss: 0.0734\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0739\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0741\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0740\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0750\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0734\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0742\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.11 11.11 11.11 11.11 11.11]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.13045919\n",
            "MSE:  0.03861354\n",
            "RMSE:  0.19650328035200904\n",
            "R2:  0.9460717439651489\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_20 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 15ms/step - loss: 0.1264 - val_loss: 0.0704\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0722\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0188 - val_loss: 0.0698\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0762\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0724\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0725\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0698\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0702\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0191 - val_loss: 0.0696\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0188 - val_loss: 0.0732\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0186 - val_loss: 0.0708\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0191 - val_loss: 0.0706\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0728\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0738\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0724\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0707\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0721\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0719\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0706\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0181 - val_loss: 0.0712\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0183 - val_loss: 0.0725\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0729\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0183 - val_loss: 0.0747\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0715\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0714\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0708\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0739\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0730\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0737\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0722\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0178 - val_loss: 0.0734\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0733\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0180 - val_loss: 0.0719\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0181 - val_loss: 0.0724\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0730\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0716\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0722\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0722\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0726\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0734\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0177 - val_loss: 0.0726\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0179 - val_loss: 0.0730\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0732\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0726\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0743\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0748\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0742\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0738\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0733\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0729\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0730\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0178 - val_loss: 0.0729\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0729\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0179 - val_loss: 0.0744\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0737\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0735\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0733\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0729\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0730\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0741\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0735\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0731\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0740\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0179 - val_loss: 0.0747\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0736\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0180 - val_loss: 0.0740\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0741\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0748\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0755\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0724\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0750\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0737\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0728\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0174 - val_loss: 0.0753\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0744\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0752\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0756\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0755\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0747\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0745\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0751\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0736\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0765\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0748\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0753\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0177 - val_loss: 0.0738\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0750\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0756\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0745\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0768\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0748\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0752\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0737\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0746\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0734\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0174 - val_loss: 0.0744\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0759\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0736\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0736\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.11 11.11 11.1  11.11 11.11]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.12984703\n",
            "MSE:  0.03845445\n",
            "RMSE:  0.19609806390401832\n",
            "R2:  0.9462939500808716\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_21 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 13ms/step - loss: 0.1223 - val_loss: 0.0698\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0191 - val_loss: 0.0696\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0194 - val_loss: 0.0731\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0187 - val_loss: 0.0701\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0704\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0700\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0695\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0192 - val_loss: 0.0698\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0698\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0696\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0185 - val_loss: 0.0695\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0185 - val_loss: 0.0696\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0187 - val_loss: 0.0710\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0183 - val_loss: 0.0720\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.0703\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0695\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0715\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0719\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0721\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0700\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0715\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0704\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0713\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0184 - val_loss: 0.0724\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0181 - val_loss: 0.0715\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0711\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0731\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0728\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0715\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0718\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0726\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0717\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0175 - val_loss: 0.0719\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0182 - val_loss: 0.0719\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0722\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0178 - val_loss: 0.0731\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0742\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0728\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0736\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0725\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0731\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0735\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0738\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0186 - val_loss: 0.0750\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0766\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0180 - val_loss: 0.0726\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0179 - val_loss: 0.0736\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0730\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0720\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0736\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0739\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0749\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0754\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0746\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0177 - val_loss: 0.0737\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0178 - val_loss: 0.0731\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0179 - val_loss: 0.0754\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0740\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0744\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0744\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0733\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0736\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0741\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0747\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0732\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0737\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0737\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0731\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0175 - val_loss: 0.0733\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0736\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0735\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0758\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0725\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0731\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0767\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0750\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0732\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0731\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0746\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0735\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0771\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0733\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0759\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0724\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0737\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0178 - val_loss: 0.0743\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0175 - val_loss: 0.0742\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.0729\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0175 - val_loss: 0.0751\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0175 - val_loss: 0.0733\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0743\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0726\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0733\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0735\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0746\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0740\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0179 - val_loss: 0.0746\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0745\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0173 - val_loss: 0.0745\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.1  11.11 11.12 11.12 11.12]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.13084348\n",
            "MSE:  0.039143424\n",
            "RMSE:  0.19784697238308574\n",
            "R2:  0.9453318119049072\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_22 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 10ms/step - loss: 0.1206 - val_loss: 0.0669\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0194 - val_loss: 0.0703\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0196 - val_loss: 0.0691\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0681\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0695\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0191 - val_loss: 0.0709\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0196 - val_loss: 0.0735\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0190 - val_loss: 0.0687\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0194 - val_loss: 0.0688\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0676\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0674\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0195 - val_loss: 0.0682\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0193 - val_loss: 0.0684\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0671\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0193 - val_loss: 0.0711\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0686\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0196 - val_loss: 0.0683\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0197 - val_loss: 0.0675\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0198 - val_loss: 0.0680\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0679\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0193 - val_loss: 0.0716\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0673\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0672\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0191 - val_loss: 0.0693\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0675\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0198 - val_loss: 0.0683\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0694\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0192 - val_loss: 0.0695\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0191 - val_loss: 0.0679\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0706\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0192 - val_loss: 0.0674\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0679\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0678\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0688\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0686\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0671\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0194 - val_loss: 0.0671\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0675\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0690\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0194 - val_loss: 0.0712\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0679\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0677\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0687\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0682\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0700\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0685\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0197 - val_loss: 0.0684\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0692\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0189 - val_loss: 0.0680\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0188 - val_loss: 0.0714\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0191 - val_loss: 0.0681\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0194 - val_loss: 0.0688\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0681\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0674\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0694\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0683\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0672\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0677\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.0672\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0189 - val_loss: 0.0676\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0186 - val_loss: 0.0678\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0186 - val_loss: 0.0675\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0681\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0676\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0692\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0678\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0670\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0684\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0187 - val_loss: 0.0673\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0689\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0188 - val_loss: 0.0687\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0688\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0689\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0676\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0695\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0684\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0678\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0693\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0189 - val_loss: 0.0681\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0186 - val_loss: 0.0680\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0187 - val_loss: 0.0674\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.0673\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0679\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0674\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0675\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0671\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0675\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0682\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0679\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0186 - val_loss: 0.0691\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0189 - val_loss: 0.0678\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0186 - val_loss: 0.0677\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0187 - val_loss: 0.0671\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0704\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0681\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0680\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0676\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0683\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0694\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0690\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [11.06 11.06 11.06 11.08 11.06]\n",
            "Predicted_not_normlized [11.12 11.12 11.12 11.12 11.12]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.12703128\n",
            "MSE:  0.037222594\n",
            "RMSE:  0.1929315786043095\n",
            "R2:  0.9480144381523132\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"FITAIHI GROUP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRf1xrXdLCIR",
        "outputId": "0b8a4129-2ba4-49e2-a985-b784e6722234"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  221250.     216125.02   132300.   ... 17127760.   25927482.\n",
            " 15375914.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  217500.03   160409.2    152250.02 ... 13769432.   25706238.\n",
            " 25434224.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '16.22719515561002' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5091, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5081, 5, 34)\n",
            "y shape: (5081, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SARCO_BRNN_500\n",
            "SARCO_GRU_800\n",
            "SARCO_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 15)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0896 - val_loss: 0.1035\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1003\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.1017\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.1094\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.1039\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1087\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.1025\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.1037\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0997\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.1008\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1031\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0162 - val_loss: 0.1018\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.1040\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.1012\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.1004\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.1003\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0177 - val_loss: 0.1042\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0997\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1048\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.1077\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.1037\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0992\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.1006\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1053\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1001\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1008\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1004\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1009\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.1034\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.1012\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1032\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1057\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1017\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1049\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1043\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.1010\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.1069\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1051\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0998\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.1032\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1016\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0995\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1005\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.0998\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1023\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.1047\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1001\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.1030\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.1015\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.1014\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1012\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1045\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.1116\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1042\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1037\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1009\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.1028\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1032\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1033\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1023\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1025\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1066\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1041\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1040\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1031\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1022\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1024\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1079\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1057\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1085\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1044\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.1059\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.1022\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0155 - val_loss: 0.1057\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0154 - val_loss: 0.1009\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.1067\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.1024\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0146 - val_loss: 0.1043\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.1058\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1033\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1025\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1093\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1081\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.1066\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1078\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1089\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1062\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1039\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1009\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1042\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.1022\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1016\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1055\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1029\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1102\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1033\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1082\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1045\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1021\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1032\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.31 46.31 46.44 46.61 46.69]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.7746\n",
            "MSE:  1.5748552\n",
            "RMSE:  1.2549323521197913\n",
            "R2:  0.9358187913894653\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 4ms/step - loss: 0.0601 - val_loss: 0.1012\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.1022\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1016\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0999\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.1010\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1006\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0996\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0993\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0175 - val_loss: 0.1000\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.1009\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.1001\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0998\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0162 - val_loss: 0.0994\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.1000\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0996\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.1028\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0994\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0994\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1002\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.1005\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1046\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0996\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0999\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1044\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0991\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.1006\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.1005\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.1015\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1025\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1000\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0982\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0998\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0993\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0999\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0988\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0994\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0999\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1036\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.1037\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0992\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0160 - val_loss: 0.1030\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.0998\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.1006\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.1100\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1023\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.1046\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1051\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0984\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.1000\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0989\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0993\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1012\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.1013\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0987\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.1007\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0987\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1016\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.1008\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.1027\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1039\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1014\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1030\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.1006\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1024\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0995\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0998\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0981\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.1010\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.1011\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1020\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0149 - val_loss: 0.1033\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0151 - val_loss: 0.1000\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.1021\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.1021\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1048\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0999\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.1018\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1014\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1010\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0998\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1033\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.1020\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1017\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1033\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1016\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1014\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1025\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1020\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1010\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1009\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1003\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0992\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1050\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1002\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0155 - val_loss: 0.1005\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.1021\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.1033\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0146 - val_loss: 0.1011\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.1029\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.1018\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.55 46.69 46.52 46.59 46.66]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.77290106\n",
            "MSE:  1.5641248\n",
            "RMSE:  1.2506497601713187\n",
            "R2:  0.9362561106681824\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 2s 4ms/step - loss: 0.0926 - val_loss: 0.1038\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.1000\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0984\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0990\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0997\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0990\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0996\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0990\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.1011\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1011\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0172 - val_loss: 0.1043\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0988\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0173 - val_loss: 0.0990\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0158 - val_loss: 0.0999\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1009\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1070\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0158 - val_loss: 0.0996\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0159 - val_loss: 0.1038\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0993\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1042\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0994\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0986\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.1010\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1003\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1037\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0988\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0983\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1073\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0985\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1003\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1010\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0995\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0986\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0984\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.1004\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0992\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1001\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.1075\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.1055\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.1018\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.0993\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0147 - val_loss: 0.1003\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0150 - val_loss: 0.0994\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0143 - val_loss: 0.1008\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0986\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.1055\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.0997\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.1029\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0992\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1011\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0999\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1043\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0987\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1034\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.1030\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1013\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0990\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.1009\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.1023\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0998\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.1016\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1012\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1055\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1010\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.1004\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1001\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0999\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0998\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.1006\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0142 - val_loss: 0.1056\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.1060\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0145 - val_loss: 0.1021\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0151 - val_loss: 0.1084\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0150 - val_loss: 0.1002\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0146 - val_loss: 0.1014\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.1002\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.1048\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0999\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1005\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1016\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1036\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1013\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1022\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1038\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1084\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.1009\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.1046\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1020\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.1052\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.1051\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.1036\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1057\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.1026\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1044\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.1022\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.1021\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.1008\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0147 - val_loss: 0.1054\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.1037\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0143 - val_loss: 0.1027\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.51 46.62 46.69 46.61 46.94]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.77097046\n",
            "MSE:  1.6087313\n",
            "RMSE:  1.268357705789824\n",
            "R2:  0.9344382286071777\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 2s 4ms/step - loss: 0.1146 - val_loss: 0.1058\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.1041\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.1088\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1049\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0175 - val_loss: 0.1073\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1052\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.1057\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.1047\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.1038\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.1060\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.1050\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1165\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0172 - val_loss: 0.1071\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.1055\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.1095\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.1127\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.1102\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1076\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1056\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.1065\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1082\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.1031\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.1064\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1028\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1039\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.1088\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1082\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1034\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1085\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1032\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1063\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1047\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.1042\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1047\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1039\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.1142\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1064\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1075\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.1050\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.1031\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1056\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0153 - val_loss: 0.1067\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0153 - val_loss: 0.1090\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.1073\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.1059\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.1035\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1141\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1085\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1057\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1069\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1084\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1068\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1046\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1091\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1073\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1043\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1054\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1041\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1083\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1061\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.1105\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.1044\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1049\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1031\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1050\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1052\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.1036\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.1062\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0158 - val_loss: 0.1069\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0157 - val_loss: 0.1068\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0151 - val_loss: 0.1103\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0153 - val_loss: 0.1114\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0157 - val_loss: 0.1051\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1063\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1054\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1040\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.1082\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1045\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1054\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.1091\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.1053\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.1033\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.1060\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1045\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1055\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.1051\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1061\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.1072\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1074\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1045\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1099\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.1057\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1077\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.1069\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 6ms/step - loss: 0.0145 - val_loss: 0.1059\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.1051\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0149 - val_loss: 0.1058\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.1045\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0149 - val_loss: 0.1057\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.0149 - val_loss: 0.1145\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.96 47.15 47.38 47.4  47.51]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.8681756\n",
            "MSE:  1.929087\n",
            "RMSE:  1.3889157795951965\n",
            "R2:  0.9213826060295105\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 13ms/step - loss: 0.1244 - val_loss: 0.1335\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0167 - val_loss: 0.1191\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0161 - val_loss: 0.1151\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0154 - val_loss: 0.1145\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.1165\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.1126\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0162 - val_loss: 0.1087\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0176 - val_loss: 0.1334\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.1145\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 3s 21ms/step - loss: 0.0161 - val_loss: 0.1022\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0175 - val_loss: 0.1052\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.1090\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0158 - val_loss: 0.1006\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.1045\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0149 - val_loss: 0.1092\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0157 - val_loss: 0.1020\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0165 - val_loss: 0.1017\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0167 - val_loss: 0.1015\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0161 - val_loss: 0.1018\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1023\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1054\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1068\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.1059\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0172 - val_loss: 0.1042\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0153 - val_loss: 0.1028\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0163 - val_loss: 0.1011\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.1012\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0156 - val_loss: 0.1003\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1069\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0147 - val_loss: 0.1013\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1003\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0149 - val_loss: 0.1026\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0155 - val_loss: 0.1022\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0153 - val_loss: 0.1006\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1105\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0152 - val_loss: 0.1010\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1006\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1018\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1067\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0151 - val_loss: 0.1012\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0146 - val_loss: 0.1024\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1057\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1041\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1027\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1056\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1082\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0151 - val_loss: 0.1006\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0149 - val_loss: 0.1030\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0151 - val_loss: 0.1050\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1029\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1065\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1043\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.1017\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1036\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0149 - val_loss: 0.1043\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0142 - val_loss: 0.1002\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1046\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.1035\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0148 - val_loss: 0.1001\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1041\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1031\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0145 - val_loss: 0.1027\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0145 - val_loss: 0.1017\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0145 - val_loss: 0.1007\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1024\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1080\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1076\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1081\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1050\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0148 - val_loss: 0.1060\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0145 - val_loss: 0.1033\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0143 - val_loss: 0.0998\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1057\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1035\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1030\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1075\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1061\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.1059\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0144 - val_loss: 0.1073\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.1062\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1033\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1044\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1037\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0141 - val_loss: 0.1013\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1052\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0142 - val_loss: 0.1039\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0148 - val_loss: 0.1066\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0144 - val_loss: 0.1029\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0141 - val_loss: 0.1050\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1028\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1062\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1038\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0145 - val_loss: 0.1057\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0142 - val_loss: 0.1070\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0147 - val_loss: 0.1088\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1073\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1051\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1057\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1101\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1097\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.36 46.34 46.67 46.9  47.23]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.7875881\n",
            "MSE:  1.6180022\n",
            "RMSE:  1.272007144745968\n",
            "R2:  0.9340603947639465\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 5s 23ms/step - loss: 0.1204 - val_loss: 0.1639\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0170 - val_loss: 0.1477\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.1495\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.1462\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.1536\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0170 - val_loss: 0.1219\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0182 - val_loss: 0.1267\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0168 - val_loss: 0.1058\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0178 - val_loss: 0.1179\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0166 - val_loss: 0.1200\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0166 - val_loss: 0.1108\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.1150\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1052\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.1149\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.1035\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0158 - val_loss: 0.1029\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0163 - val_loss: 0.1102\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0163 - val_loss: 0.1009\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0157 - val_loss: 0.1061\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0162 - val_loss: 0.1023\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1033\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.0991\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0159 - val_loss: 0.1029\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0156 - val_loss: 0.1040\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1030\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1082\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0158 - val_loss: 0.1006\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1097\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.1011\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.1033\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.1020\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0151 - val_loss: 0.1001\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.1031\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1006\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.1006\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0157 - val_loss: 0.0997\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.1040\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1087\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0148 - val_loss: 0.0996\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0151 - val_loss: 0.1018\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.1010\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1004\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1009\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0156 - val_loss: 0.1033\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1048\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0150 - val_loss: 0.1020\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0155 - val_loss: 0.1006\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1057\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0173 - val_loss: 0.1031\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0148 - val_loss: 0.1000\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1037\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0152 - val_loss: 0.1042\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0144 - val_loss: 0.1016\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0156 - val_loss: 0.1034\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0148 - val_loss: 0.1028\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1022\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1010\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0152 - val_loss: 0.1014\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1012\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0148 - val_loss: 0.1012\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.1012\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0155 - val_loss: 0.1035\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1027\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1039\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1010\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.1020\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.0995\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0146 - val_loss: 0.1022\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.1011\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1053\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1044\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1058\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1020\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1020\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1007\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0145 - val_loss: 0.0998\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0150 - val_loss: 0.1040\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1013\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1038\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1017\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1022\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1035\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1036\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0149 - val_loss: 0.1011\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0146 - val_loss: 0.1036\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1027\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1017\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1039\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1024\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1050\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1050\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0145 - val_loss: 0.1057\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0143 - val_loss: 0.1020\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0147 - val_loss: 0.1024\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1015\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1011\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1039\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1018\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.1020\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1035\n",
            "36/36 [==============================] - 1s 7ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.73 46.77 46.9  46.94 47.12]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.77211165\n",
            "MSE:  1.6146895\n",
            "RMSE:  1.270704320185252\n",
            "R2:  0.9341955184936523\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 5s 16ms/step - loss: 0.1739 - val_loss: 0.2326\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0218 - val_loss: 0.1730\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.1528\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.1500\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1494\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.1577\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0153 - val_loss: 0.1388\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0155 - val_loss: 0.1542\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.1461\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.1274\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1293\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1184\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1127\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.1213\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0155 - val_loss: 0.1150\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0165 - val_loss: 0.1151\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.1169\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1279\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.1069\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.1018\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.1061\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0165 - val_loss: 0.1054\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.1035\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0160 - val_loss: 0.1034\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.1051\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1053\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.1063\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1017\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1057\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0152 - val_loss: 0.1035\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 4s 24ms/step - loss: 0.0160 - val_loss: 0.1058\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.0159 - val_loss: 0.1020\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0149 - val_loss: 0.1003\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1071\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1037\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1079\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1017\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1051\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1010\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0152 - val_loss: 0.1011\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0152 - val_loss: 0.1048\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1005\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1030\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1041\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.1010\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1030\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0144 - val_loss: 0.1041\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0149 - val_loss: 0.1018\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0154 - val_loss: 0.0997\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0149 - val_loss: 0.1042\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1047\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1043\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1005\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1071\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1003\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0153 - val_loss: 0.1010\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0151 - val_loss: 0.1012\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1059\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1011\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0141 - val_loss: 0.0997\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1013\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1020\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1005\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.1063\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.1039\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0148 - val_loss: 0.1017\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1012\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1035\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1104\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1030\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0147 - val_loss: 0.1046\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0144 - val_loss: 0.1041\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0146 - val_loss: 0.1069\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1044\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1036\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1011\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1045\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1020\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1018\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0143 - val_loss: 0.0997\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.1013\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.0992\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0141 - val_loss: 0.1006\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1009\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1022\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1011\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1032\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0142 - val_loss: 0.1035\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0144 - val_loss: 0.1056\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.1019\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0141 - val_loss: 0.1017\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1057\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1069\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1047\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1023\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0149 - val_loss: 0.1050\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0144 - val_loss: 0.1042\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1023\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0140 - val_loss: 0.1031\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1022\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.31 46.49 46.75 47.18 47.41]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.7780765\n",
            "MSE:  1.6333374\n",
            "RMSE:  1.278020883437314\n",
            "R2:  0.9334354400634766\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 15ms/step - loss: 0.1618 - val_loss: 0.1578\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0190 - val_loss: 0.1615\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1433\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.1400\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.1170\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.1201\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0166 - val_loss: 0.1255\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0167 - val_loss: 0.1240\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.1168\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1184\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0171 - val_loss: 0.1129\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.1165\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1158\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0163 - val_loss: 0.1168\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0165 - val_loss: 0.1137\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0158 - val_loss: 0.1188\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.1121\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0171 - val_loss: 0.1209\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.1079\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1133\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.1078\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0152 - val_loss: 0.1053\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0169 - val_loss: 0.1092\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0151 - val_loss: 0.1102\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.1058\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1099\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1081\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.1030\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0175 - val_loss: 0.1119\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0151 - val_loss: 0.1078\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0150 - val_loss: 0.1056\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0152 - val_loss: 0.1035\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.1067\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.1043\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.1062\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.1057\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.1133\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0154 - val_loss: 0.1127\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0154 - val_loss: 0.1043\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0158 - val_loss: 0.1085\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1057\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1076\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1062\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1057\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.1048\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0151 - val_loss: 0.1074\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0155 - val_loss: 0.1053\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1062\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.1069\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1106\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1075\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1072\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.1062\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0154 - val_loss: 0.1088\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0144 - val_loss: 0.1060\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0163 - val_loss: 0.1062\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1056\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.1020\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1106\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1029\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0149 - val_loss: 0.1069\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0148 - val_loss: 0.1052\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0153 - val_loss: 0.1087\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.1073\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1051\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1076\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1065\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1075\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0148 - val_loss: 0.1095\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0147 - val_loss: 0.1100\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0148 - val_loss: 0.1059\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.1087\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1067\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1076\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1082\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1053\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.1097\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0146 - val_loss: 0.1083\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0149 - val_loss: 0.1094\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1066\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1124\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1063\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1069\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1065\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1107\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0147 - val_loss: 0.1045\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.0146 - val_loss: 0.1089\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1088\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1059\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1082\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0143 - val_loss: 0.1132\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.1071\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1099\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 3s 17ms/step - loss: 0.0153 - val_loss: 0.1056\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 3s 19ms/step - loss: 0.0145 - val_loss: 0.1107\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0144 - val_loss: 0.1063\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0153 - val_loss: 0.1137\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1087\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1053\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1078\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.25 46.43 46.5  46.54 46.68]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.7900937\n",
            "MSE:  1.6862881\n",
            "RMSE:  1.2985715684406565\n",
            "R2:  0.9312775135040283\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 11ms/step - loss: 0.1071 - val_loss: 0.1047\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.1157\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1093\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.1155\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.1068\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.1049\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.1037\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1040\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1055\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.1061\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1090\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.1078\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1052\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.1032\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.1053\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.1053\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0148 - val_loss: 0.1040\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1037\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1044\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.1024\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1035\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1024\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1039\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1031\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.1056\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0149 - val_loss: 0.1043\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.1013\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1053\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.1069\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1047\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1032\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1040\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1016\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.1041\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0147 - val_loss: 0.1029\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0156 - val_loss: 0.1030\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1033\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0148 - val_loss: 0.1038\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1027\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1029\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1014\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1035\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1023\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1027\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1030\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0141 - val_loss: 0.1074\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1009\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1098\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1055\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1064\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1046\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1056\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1039\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1022\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1044\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0149 - val_loss: 0.1033\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1042\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1014\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1009\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.1014\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0144 - val_loss: 0.1030\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.1075\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1043\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1023\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1054\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1042\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1047\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1024\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1027\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1055\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1061\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1023\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1021\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0141 - val_loss: 0.1022\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1053\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.1048\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1052\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1015\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1020\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0141 - val_loss: 0.1051\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1060\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1031\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1023\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 0.1052\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1050\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1074\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1075\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0142 - val_loss: 0.1047\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1025\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1042\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1063\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1039\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.1068\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1028\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.1066\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1043\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1046\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1044\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1044\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0140 - val_loss: 0.1056\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.21 46.52 47.01 47.21 48.04]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.78408015\n",
            "MSE:  1.6674793\n",
            "RMSE:  1.2913091328791508\n",
            "R2:  0.9320440888404846\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_1 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 11ms/step - loss: 0.1100 - val_loss: 0.1101\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.1169\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1068\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.1040\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.1023\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.1166\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.1052\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.1027\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.1159\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.1137\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.1107\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0150 - val_loss: 0.1044\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.1020\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.1138\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0165 - val_loss: 0.1051\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.1023\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.1059\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.1019\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0148 - val_loss: 0.1058\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0151 - val_loss: 0.1039\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.1092\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.1018\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.1036\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0156 - val_loss: 0.1015\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.1029\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1009\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.1019\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0149 - val_loss: 0.1051\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1011\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.1015\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1028\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1032\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0148 - val_loss: 0.1000\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.1019\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1039\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1022\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.1023\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.1051\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1010\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1018\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1032\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1022\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1029\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1048\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1018\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1018\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0148 - val_loss: 0.1026\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1023\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0149 - val_loss: 0.1029\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1030\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1060\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1036\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.1048\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1050\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.1045\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1029\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.1014\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0142 - val_loss: 0.1018\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1021\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1028\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1021\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1008\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1019\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1021\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1043\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1015\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1037\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1043\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1026\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1038\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1027\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1024\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.1019\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1008\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.1019\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0148 - val_loss: 0.1018\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.1044\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1022\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.1039\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1063\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1012\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1013\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1016\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.1026\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1042\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.1025\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1036\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1045\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1015\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0142 - val_loss: 0.1028\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1011\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1025\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1034\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1027\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1024\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.1044\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1034\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0142 - val_loss: 0.1042\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1040\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1032\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.92 46.82 46.89 47.22 47.59]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.78166276\n",
            "MSE:  1.6143719\n",
            "RMSE:  1.2705793543852741\n",
            "R2:  0.934208333492279\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_2 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 11ms/step - loss: 0.1220 - val_loss: 0.1203\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.1109\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.1296\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.1109\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.1167\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.1190\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0154 - val_loss: 0.1059\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.1172\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1152\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.1181\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0155 - val_loss: 0.1116\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.1095\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1153\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1064\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1112\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.1109\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0153 - val_loss: 0.1040\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.1045\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1059\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1036\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.1088\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1086\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0155 - val_loss: 0.1079\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0149 - val_loss: 0.1068\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1044\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1060\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.1075\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1043\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1012\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1033\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1056\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.1033\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1053\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1017\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0141 - val_loss: 0.1032\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0144 - val_loss: 0.1016\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1007\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1022\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1020\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1047\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1067\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1055\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1014\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1026\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0144 - val_loss: 0.1038\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1004\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1042\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.1047\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1011\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1021\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1028\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.1043\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.1071\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1056\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.1020\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0153 - val_loss: 0.1015\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0141 - val_loss: 0.1037\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1000\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1060\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1029\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1063\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.1035\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.1001\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1015\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0143 - val_loss: 0.1035\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1013\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0141 - val_loss: 0.1036\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1042\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.1018\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1041\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1030\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1019\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1015\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0146 - val_loss: 0.1020\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0145 - val_loss: 0.1028\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0140 - val_loss: 0.1034\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0141 - val_loss: 0.1029\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.1039\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1024\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.1044\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1074\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.1027\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.1024\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0143 - val_loss: 0.1079\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1037\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0140 - val_loss: 0.1049\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0142 - val_loss: 0.1047\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0142 - val_loss: 0.1038\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.1029\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.1027\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1044\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.1049\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.1035\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0145 - val_loss: 0.1046\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0139 - val_loss: 0.1036\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0141 - val_loss: 0.1005\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0139 - val_loss: 0.1046\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.1031\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1045\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1040\n",
            "36/36 [==============================] - 1s 6ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [46.65 46.93 47.19 47.54 47.93]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.782694\n",
            "MSE:  1.6682765\n",
            "RMSE:  1.2916178027518899\n",
            "R2:  0.9320115447044373\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 4s 12ms/step - loss: 0.1429 - val_loss: 0.1112\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0165 - val_loss: 0.1122\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.1142\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0159 - val_loss: 0.1241\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1212\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.1187\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1144\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1127\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1092\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1051\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.1190\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.1057\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0150 - val_loss: 0.1099\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0160 - val_loss: 0.1100\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.1097\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0160 - val_loss: 0.1063\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1079\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.1087\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.1067\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1075\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1058\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.1060\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.1063\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0153 - val_loss: 0.1114\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.1053\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1052\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.1066\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1054\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1063\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.1081\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.1084\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1079\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0143 - val_loss: 0.1088\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0152 - val_loss: 0.1082\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.1051\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.1055\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1044\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.1086\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.1061\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.1081\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0148 - val_loss: 0.1044\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0147 - val_loss: 0.1060\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0151 - val_loss: 0.1046\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0145 - val_loss: 0.1059\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.1065\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1126\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1042\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1052\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1068\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.1051\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0148 - val_loss: 0.1063\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0148 - val_loss: 0.1056\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1077\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0147 - val_loss: 0.1095\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1045\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1104\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1056\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.1077\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1082\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.1070\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0149 - val_loss: 0.1114\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.1062\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0148 - val_loss: 0.1092\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0149 - val_loss: 0.1041\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.1090\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1054\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.1034\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.1079\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.1048\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1081\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1058\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0146 - val_loss: 0.1056\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 3s 16ms/step - loss: 0.0147 - val_loss: 0.1059\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1066\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1076\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1054\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1078\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1090\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1069\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1040\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1061\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 2s 16ms/step - loss: 0.0143 - val_loss: 0.1076\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0145 - val_loss: 0.1075\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0147 - val_loss: 0.1126\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.1061\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0143 - val_loss: 0.1073\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0146 - val_loss: 0.1067\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.1059\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.1077\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0146 - val_loss: 0.1064\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0143 - val_loss: 0.1052\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 2s 14ms/step - loss: 0.0144 - val_loss: 0.1077\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1075\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1105\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 2s 11ms/step - loss: 0.0142 - val_loss: 0.1112\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0146 - val_loss: 0.1084\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.1088\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.1102\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 2s 12ms/step - loss: 0.0147 - val_loss: 0.1091\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 2s 15ms/step - loss: 0.0145 - val_loss: 0.1090\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [45.3 45.3 45.3 47.5 47. ]\n",
            "Predicted_not_normlized [45.99 46.21 46.37 46.51 47.2 ]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.8024818\n",
            "MSE:  1.7032429\n",
            "RMSE:  1.305083483148632\n",
            "R2:  0.9305864572525024\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"SARCO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBKXOctLLCIS",
        "outputId": "5a84a25b-1954-45b1-89e8-1e04c8a4f8f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[24583906. 88294848. 52870988. ... 26448874. 28826730. 31028048.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[48515368. 67965992. 77909728. ... 37179800. 19583160. 40787484.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '13.794545052578236' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.3333333333333333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (4955, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (4945, 5, 34)\n",
            "y shape: (4945, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SAUDI ELECTRICITY_BRNN_300\n",
            "SAUDI ELECTRICITY_GRU_243\n",
            "SAUDI ELECTRICITY_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0621 - val_loss: 0.0741\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0738\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0739\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0732\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0736\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0173 - val_loss: 0.0758\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0175 - val_loss: 0.0734\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0747\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0740\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0742\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0735\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0747\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0747\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0749\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0730\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0729\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0731\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0730\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0733\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0751\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0732\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0771\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0727\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0750\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0734\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0789\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0739\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0754\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0801\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0736\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0744\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0727\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0735\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0164 - val_loss: 0.0746\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0746\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0735\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0733\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0725\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0735\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0734\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0725\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0754\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0727\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0731\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0742\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0745\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0753\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0750\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0741\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0734\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0735\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0756\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0741\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0735\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0746\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0740\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0746\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0763\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0734\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0733\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0737\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0757\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0748\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0747\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0742\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0164 - val_loss: 0.0757\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0744\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0736\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0744\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0741\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0747\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0735\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0741\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0763\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0742\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0743\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0740\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0739\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0748\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0738\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0739\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0745\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0751\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0742\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0743\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0740\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0743\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.0772\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0747\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0747\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0740\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0743\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0159 - val_loss: 0.0748\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0755\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0157 - val_loss: 0.0741\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0157 - val_loss: 0.0744\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.87 20.85 20.87 20.85 20.78]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.30886075\n",
            "MSE:  0.22099602\n",
            "RMSE:  0.47010214020404784\n",
            "R2:  0.9746079444885254\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 2s 3ms/step - loss: 0.0675 - val_loss: 0.0742\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0727\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0750\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0732\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0767\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0734\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0743\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0727\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0736\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0733\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0723\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0736\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0736\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0739\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0184 - val_loss: 0.0734\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0726\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0724\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0164 - val_loss: 0.0730\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0177 - val_loss: 0.0777\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0173 - val_loss: 0.0745\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0746\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0724\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0727\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0719\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0732\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0727\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0719\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0722\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0766\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0729\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0739\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0747\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0747\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0724\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0728\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0731\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0723\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0732\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0737\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0724\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0725\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0722\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0721\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0170 - val_loss: 0.0729\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.0723\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0742\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0723\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0746\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0724\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0726\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0725\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0728\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0739\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0734\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0729\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0727\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0745\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0728\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0730\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0735\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0719\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0736\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0752\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0741\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0737\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0727\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0738\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0730\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0728\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0720\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0736\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0735\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0724\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0733\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0755\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0720\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0786\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0728\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0743\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0167 - val_loss: 0.0730\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0761\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0744\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0732\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0732\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0732\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0738\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0736\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0736\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0732\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0746\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0731\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0744\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0749\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0752\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0745\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0745\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0736\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0744\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0736\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.96 20.92 20.88 20.9  20.89]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.3152867\n",
            "MSE:  0.22579546\n",
            "RMSE:  0.4751794005715596\n",
            "R2:  0.9740564823150635\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 2s 4ms/step - loss: 0.1052 - val_loss: 0.0740\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0741\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0745\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0743\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0744\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0734\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0736\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0748\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0736\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0734\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0743\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0735\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0745\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0733\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0171 - val_loss: 0.0733\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0735\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0178 - val_loss: 0.0750\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0759\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0745\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0734\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0738\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0739\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0760\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0733\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0733\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0732\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0738\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0746\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0727\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0721\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0743\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0734\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0746\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0734\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0721\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0736\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0718\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0750\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0754\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0744\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.0738\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0729\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0170 - val_loss: 0.0748\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0168 - val_loss: 0.0738\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0747\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0744\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0747\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0726\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0732\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0743\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0752\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0753\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0730\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0724\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0738\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0739\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0724\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0727\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0751\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0750\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0734\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0728\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0728\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0731\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0745\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0760\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0722\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0732\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0739\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0159 - val_loss: 0.0747\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0748\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0725\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0740\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0725\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0167 - val_loss: 0.0743\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.0739\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0740\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0727\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0743\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0743\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0735\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0727\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0737\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0812\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0735\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0734\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0735\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0726\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0735\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0731\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0744\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0735\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0734\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0731\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0734\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0731\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0732\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0736\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.81 20.81 20.81 20.79 20.72]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.31738782\n",
            "MSE:  0.22372866\n",
            "RMSE:  0.47299963717618093\n",
            "R2:  0.9742940068244934\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 2s 6ms/step - loss: 0.0697 - val_loss: 0.0761\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0770\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0759\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0760\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0753\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0759\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0749\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0750\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0756\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0756\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0750\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0766\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0785\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0758\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0776\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0755\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0786\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0779\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0761\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0747\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0769\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0755\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0751\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0752\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0757\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0751\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0779\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0182 - val_loss: 0.0770\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0773\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0173 - val_loss: 0.0756\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0759\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0757\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0766\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0762\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0785\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0761\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0766\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0751\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0761\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0754\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0785\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0761\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0761\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0762\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0759\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0759\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0784\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0758\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0758\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0762\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0757\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0752\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0766\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0762\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0759\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0759\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0164 - val_loss: 0.0750\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0759\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0752\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0750\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0751\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0760\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0771\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0755\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0753\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0749\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0793\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0747\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0746\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0753\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0758\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0751\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0765\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0754\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0162 - val_loss: 0.0749\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0780\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0757\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0750\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0749\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0761\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0748\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0162 - val_loss: 0.0760\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0758\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0752\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0769\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0164 - val_loss: 0.0779\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0761\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.0748\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0748\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0753\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0748\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0750\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0749\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0761\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0750\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0755\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0769\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0762\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.91 20.93 20.92 20.97 20.95]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.32307824\n",
            "MSE:  0.24051337\n",
            "RMSE:  0.4904216241572474\n",
            "R2:  0.9723654985427856\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 5s 20ms/step - loss: 0.2199 - val_loss: 0.0878\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0192 - val_loss: 0.0809\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0777\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0754\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0775\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0164 - val_loss: 0.0759\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0748\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0161 - val_loss: 0.0751\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0170 - val_loss: 0.0751\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0165 - val_loss: 0.0760\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0747\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0750\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0747\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0756\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0165 - val_loss: 0.0759\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0174 - val_loss: 0.0737\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0164 - val_loss: 0.0731\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0756\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0751\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.0738\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0745\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0164 - val_loss: 0.0741\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0167 - val_loss: 0.0755\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0170 - val_loss: 0.0742\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0165 - val_loss: 0.0758\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0170 - val_loss: 0.0788\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0745\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.0752\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0735\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0167 - val_loss: 0.0738\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0165 - val_loss: 0.0732\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0159 - val_loss: 0.0781\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0166 - val_loss: 0.0753\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0162 - val_loss: 0.0750\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0171 - val_loss: 0.0751\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0165 - val_loss: 0.0739\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0756\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0751\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0744\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0165 - val_loss: 0.0739\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0165 - val_loss: 0.0739\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0746\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0738\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0162 - val_loss: 0.0742\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0736\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0764\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0753\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0160 - val_loss: 0.0737\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0164 - val_loss: 0.0740\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0808\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0168 - val_loss: 0.0742\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0748\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.0735\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0734\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0163 - val_loss: 0.0736\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0161 - val_loss: 0.0752\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0738\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0740\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0161 - val_loss: 0.0741\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.0738\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0157 - val_loss: 0.0759\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0737\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0737\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.0748\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0742\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0739\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0170 - val_loss: 0.0736\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0157 - val_loss: 0.0745\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0741\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0733\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0731\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0737\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0739\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0735\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0155 - val_loss: 0.0736\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0157 - val_loss: 0.0742\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0742\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0742\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0743\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0755\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0745\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0731\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0154 - val_loss: 0.0729\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0153 - val_loss: 0.0734\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0151 - val_loss: 0.0747\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.0730\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.0734\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0743\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0741\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0735\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0739\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0150 - val_loss: 0.0732\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.86 20.85 20.87 20.83 20.82]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.30725545\n",
            "MSE:  0.22148204\n",
            "RMSE:  0.4706187825596475\n",
            "R2:  0.9745521545410156\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 5s 20ms/step - loss: 0.1745 - val_loss: 0.1042\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0214 - val_loss: 0.0786\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0174 - val_loss: 0.0808\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.0778\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.0749\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0769\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0764\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0169 - val_loss: 0.0750\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0163 - val_loss: 0.0747\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0165 - val_loss: 0.0754\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0749\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0763\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0180 - val_loss: 0.0729\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0739\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0170 - val_loss: 0.0738\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0741\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0191 - val_loss: 0.0734\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0168 - val_loss: 0.0740\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0177 - val_loss: 0.0732\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0166 - val_loss: 0.0744\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0160 - val_loss: 0.0742\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0174 - val_loss: 0.0740\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0164 - val_loss: 0.0729\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0160 - val_loss: 0.0741\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0736\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0728\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0747\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0730\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0767\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0190 - val_loss: 0.0767\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0167 - val_loss: 0.0729\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0162 - val_loss: 0.0732\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0753\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0740\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0730\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0738\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0738\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0730\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.0724\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0159 - val_loss: 0.0739\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0163 - val_loss: 0.0729\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0734\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0745\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0734\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0163 - val_loss: 0.0745\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0163 - val_loss: 0.0746\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0166 - val_loss: 0.0724\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0738\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0731\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0751\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0725\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0737\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.0733\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0156 - val_loss: 0.0738\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0162 - val_loss: 0.0767\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0167 - val_loss: 0.0732\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0733\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0743\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0727\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0734\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0740\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0156 - val_loss: 0.0728\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0159 - val_loss: 0.0729\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0723\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0739\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0733\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0725\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0735\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0154 - val_loss: 0.0729\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.0739\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0731\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0741\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0733\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0738\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0724\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0157 - val_loss: 0.0732\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0152 - val_loss: 0.0734\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0170 - val_loss: 0.0734\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0741\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0732\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0725\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0736\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0736\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0155 - val_loss: 0.0734\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0157 - val_loss: 0.0728\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0737\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0738\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0735\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0727\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0735\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0728\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0153 - val_loss: 0.0742\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0154 - val_loss: 0.0736\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.0735\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0728\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0731\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.93 20.94 20.92 20.92 20.91]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.31841215\n",
            "MSE:  0.22835985\n",
            "RMSE:  0.4778701165179504\n",
            "R2:  0.9737619161605835\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 4s 13ms/step - loss: 0.1408 - val_loss: 0.0866\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0179 - val_loss: 0.0813\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0174 - val_loss: 0.0799\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0185 - val_loss: 0.0765\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0786\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0169 - val_loss: 0.0759\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0176 - val_loss: 0.0760\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0766\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0170 - val_loss: 0.0779\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0756\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0757\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0763\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0176 - val_loss: 0.0761\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0165 - val_loss: 0.0738\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0176 - val_loss: 0.0753\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0162 - val_loss: 0.0798\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.0768\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0162 - val_loss: 0.0744\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0738\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0776\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0171 - val_loss: 0.0768\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0169 - val_loss: 0.0758\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0165 - val_loss: 0.0756\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0758\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0737\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0744\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0736\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0752\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0183 - val_loss: 0.0756\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0161 - val_loss: 0.0739\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0162 - val_loss: 0.0745\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0168 - val_loss: 0.0764\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0736\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0736\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0745\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0174 - val_loss: 0.0740\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0164 - val_loss: 0.0748\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0159 - val_loss: 0.0737\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0170 - val_loss: 0.0759\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0747\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0743\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0731\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0735\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0729\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0164 - val_loss: 0.0740\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0163 - val_loss: 0.0730\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0171 - val_loss: 0.0748\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0760\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0759\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0735\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0730\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.0745\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0161 - val_loss: 0.0732\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0159 - val_loss: 0.0737\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0741\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0750\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0743\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0743\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0764\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0162 - val_loss: 0.0734\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0160 - val_loss: 0.0754\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0163 - val_loss: 0.0747\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0730\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0739\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0731\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0157 - val_loss: 0.0733\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0740\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0154 - val_loss: 0.0734\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0159 - val_loss: 0.0787\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0158 - val_loss: 0.0736\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0736\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0743\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0738\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0735\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0748\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0156 - val_loss: 0.0754\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0156 - val_loss: 0.0731\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.0761\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0734\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0729\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0741\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0755\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0156 - val_loss: 0.0731\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0158 - val_loss: 0.0730\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0727\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0736\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0733\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0732\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0733\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0737\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0153 - val_loss: 0.0737\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0152 - val_loss: 0.0735\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0157 - val_loss: 0.0738\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0736\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0739\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0158 - val_loss: 0.0734\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0743\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.0748\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0152 - val_loss: 0.0728\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.87 20.87 20.87 20.89 20.87]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.3150122\n",
            "MSE:  0.22547944\n",
            "RMSE:  0.4748467530698168\n",
            "R2:  0.9740927815437317\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 3s 12ms/step - loss: 0.1813 - val_loss: 0.1053\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0279 - val_loss: 0.0826\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0176 - val_loss: 0.0778\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0165 - val_loss: 0.0823\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0175 - val_loss: 0.0782\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0783\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0171 - val_loss: 0.0789\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0165 - val_loss: 0.0807\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0168 - val_loss: 0.0789\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.0767\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0162 - val_loss: 0.0765\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0164 - val_loss: 0.0763\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0758\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0751\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0783\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.0766\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0765\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0190 - val_loss: 0.0788\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0161 - val_loss: 0.0776\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0167 - val_loss: 0.0761\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0785\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.0761\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0170 - val_loss: 0.0773\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0182 - val_loss: 0.0777\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0758\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0169 - val_loss: 0.0754\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0169 - val_loss: 0.0767\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0169 - val_loss: 0.0773\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0763\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.0753\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0759\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0778\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0172 - val_loss: 0.0758\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0162 - val_loss: 0.0762\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0166 - val_loss: 0.0770\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0166 - val_loss: 0.0772\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0785\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0749\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0755\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0759\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.0752\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0164 - val_loss: 0.0749\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0167 - val_loss: 0.0758\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0166 - val_loss: 0.0754\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0756\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0173 - val_loss: 0.0750\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0760\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0174 - val_loss: 0.0799\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0754\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0163 - val_loss: 0.0759\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0159 - val_loss: 0.0791\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0162 - val_loss: 0.0755\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0760\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0746\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0760\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0767\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0752\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0162 - val_loss: 0.0752\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0160 - val_loss: 0.0753\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0167 - val_loss: 0.0750\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0171 - val_loss: 0.0748\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0770\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0753\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0755\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0758\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0751\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0163 - val_loss: 0.0749\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0169 - val_loss: 0.0760\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0759\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0748\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0757\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0758\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0767\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0752\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0160 - val_loss: 0.0769\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0161 - val_loss: 0.0759\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0156 - val_loss: 0.0760\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0755\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0759\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0765\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0755\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0757\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0162 - val_loss: 0.0751\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.0162 - val_loss: 0.0754\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0759\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0749\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0758\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0757\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0753\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0766\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0160 - val_loss: 0.0753\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0154 - val_loss: 0.0761\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0154 - val_loss: 0.0760\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0766\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0776\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0757\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0766\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0768\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0755\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0155 - val_loss: 0.0759\n",
            "36/36 [==============================] - 1s 7ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.95 20.95 20.94 20.91 20.94]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.30938244\n",
            "MSE:  0.21783292\n",
            "RMSE:  0.4667257470244017\n",
            "R2:  0.9749714732170105\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_4 (GRU)                 (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 3s 11ms/step - loss: 0.1125 - val_loss: 0.0749\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0174 - val_loss: 0.0760\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0167 - val_loss: 0.0752\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0759\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0165 - val_loss: 0.0768\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0772\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0169 - val_loss: 0.0754\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0166 - val_loss: 0.0736\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0165 - val_loss: 0.0749\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0745\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0766\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0747\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0746\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.0756\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0738\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0759\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0163 - val_loss: 0.0757\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0164 - val_loss: 0.0783\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0167 - val_loss: 0.0763\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0736\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0746\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.0748\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0738\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0740\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0745\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0737\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0163 - val_loss: 0.0734\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0740\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0738\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.0738\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0746\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0744\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0754\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0740\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0742\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0743\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0742\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0738\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0741\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0749\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0745\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0751\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0735\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0737\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0734\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0739\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0733\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0735\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0738\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0748\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0742\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0734\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0734\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0755\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0736\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0744\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0749\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0733\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0769\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0737\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0735\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0730\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0756\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0742\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0742\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0731\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0736\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.0732\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.0733\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0739\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0740\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0735\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0742\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0729\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0730\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0734\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0727\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.0742\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.0742\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0152 - val_loss: 0.0736\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0738\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0735\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0742\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0730\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0738\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0755\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.0734\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.0737\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.0735\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.0731\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0735\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0739\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0730\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.0728\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0742\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0741\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0735\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.82 20.78 20.77 20.79 20.78]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.3061826\n",
            "MSE:  0.21757679\n",
            "RMSE:  0.4664512695617033\n",
            "R2:  0.9750009179115295\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_5 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 3s 11ms/step - loss: 0.1040 - val_loss: 0.0745\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0754\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0800\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.0762\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0168 - val_loss: 0.0768\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0166 - val_loss: 0.0730\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0174 - val_loss: 0.0745\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0765\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0744\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0761\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0171 - val_loss: 0.0747\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0735\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0733\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0739\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0171 - val_loss: 0.0740\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0163 - val_loss: 0.0750\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.0754\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0761\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0170 - val_loss: 0.0744\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0738\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0743\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0732\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0739\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0730\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0746\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0166 - val_loss: 0.0743\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.0734\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0732\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0725\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0730\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0742\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0735\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0752\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0801\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.0725\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0167 - val_loss: 0.0729\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0156 - val_loss: 0.0729\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.0739\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0733\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0729\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0759\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0736\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0741\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0730\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0732\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0724\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.0732\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0744\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0738\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0738\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0734\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0723\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0725\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0766\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0725\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0732\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0726\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0728\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0733\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0729\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0729\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0740\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0154 - val_loss: 0.0733\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0732\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0736\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0735\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0156 - val_loss: 0.0734\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0727\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0733\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0732\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0735\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0156 - val_loss: 0.0724\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0731\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.0740\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0729\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0725\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0732\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.0732\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0748\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0726\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0152 - val_loss: 0.0727\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0732\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0755\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0743\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0735\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0729\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0153 - val_loss: 0.0731\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0153 - val_loss: 0.0737\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0729\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0158 - val_loss: 0.0733\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0727\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0725\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0729\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0729\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 0.0150 - val_loss: 0.0745\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0739\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0736\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.0749\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.0732\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0151 - val_loss: 0.0734\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.83 20.82 20.83 20.83 20.84]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.30460152\n",
            "MSE:  0.21628737\n",
            "RMSE:  0.46506706451485036\n",
            "R2:  0.9751490354537964\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_6 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 3s 11ms/step - loss: 0.1254 - val_loss: 0.0758\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0760\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0759\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.0773\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0175 - val_loss: 0.0751\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0164 - val_loss: 0.0760\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0165 - val_loss: 0.0768\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0764\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0752\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0752\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0738\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0744\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0801\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0738\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0164 - val_loss: 0.0755\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0165 - val_loss: 0.0744\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0164 - val_loss: 0.0760\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0763\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0733\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0747\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0751\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0739\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0757\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0743\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0166 - val_loss: 0.0744\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.0735\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0749\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0162 - val_loss: 0.0758\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0746\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0747\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0741\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0160 - val_loss: 0.0743\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0166 - val_loss: 0.0769\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0163 - val_loss: 0.0767\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0738\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.0741\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0163 - val_loss: 0.0733\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0738\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0737\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0737\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0751\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0747\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0162 - val_loss: 0.0736\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0736\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0737\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0742\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0741\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0735\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0739\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0734\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0748\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0738\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.0743\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.0741\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0154 - val_loss: 0.0747\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.0757\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0154 - val_loss: 0.0731\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.0736\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0738\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0158 - val_loss: 0.0739\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.0733\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0735\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0739\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0747\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0740\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0738\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.0737\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0739\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0153 - val_loss: 0.0740\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0737\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0153 - val_loss: 0.0733\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0736\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0149 - val_loss: 0.0734\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0154 - val_loss: 0.0733\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0153 - val_loss: 0.0734\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.0735\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0150 - val_loss: 0.0732\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0150 - val_loss: 0.0740\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0740\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0154 - val_loss: 0.0732\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.0733\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.0746\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0152 - val_loss: 0.0735\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0154 - val_loss: 0.0733\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0150 - val_loss: 0.0730\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0155 - val_loss: 0.0733\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0730\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0150 - val_loss: 0.0735\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0150 - val_loss: 0.0729\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0152 - val_loss: 0.0734\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0151 - val_loss: 0.0729\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0151 - val_loss: 0.0734\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0150 - val_loss: 0.0735\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0151 - val_loss: 0.0732\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0736\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0741\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0734\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0149 - val_loss: 0.0734\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.85 20.84 20.84 20.82 20.79]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.30971643\n",
            "MSE:  0.22086015\n",
            "RMSE:  0.46995760812722326\n",
            "R2:  0.9746236801147461\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_7 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - 5s 19ms/step - loss: 0.1451 - val_loss: 0.0771\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0167 - val_loss: 0.0759\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0173 - val_loss: 0.0803\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0168 - val_loss: 0.0789\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0171 - val_loss: 0.0767\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0186 - val_loss: 0.0801\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0172 - val_loss: 0.0754\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0174 - val_loss: 0.0775\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.0167 - val_loss: 0.0769\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0165 - val_loss: 0.0749\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0169 - val_loss: 0.0759\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0759\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0170 - val_loss: 0.0764\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0171 - val_loss: 0.0773\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0752\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0164 - val_loss: 0.0784\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.0159 - val_loss: 0.0773\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0174 - val_loss: 0.0767\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0750\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0163 - val_loss: 0.0748\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0750\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0163 - val_loss: 0.0754\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0167 - val_loss: 0.0753\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0764\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.0163 - val_loss: 0.0748\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0163 - val_loss: 0.0750\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0162 - val_loss: 0.0753\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0161 - val_loss: 0.0758\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0763\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0752\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0751\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0758\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0766\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0160 - val_loss: 0.0753\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0159 - val_loss: 0.0759\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0162 - val_loss: 0.0760\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0162 - val_loss: 0.0753\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0761\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0751\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0757\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0760\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0761\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0755\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0161 - val_loss: 0.0756\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.0766\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0160 - val_loss: 0.0754\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0158 - val_loss: 0.0756\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0159 - val_loss: 0.0770\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0761\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0758\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0755\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0163 - val_loss: 0.0768\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0161 - val_loss: 0.0767\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0161 - val_loss: 0.0750\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0158 - val_loss: 0.0753\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0756\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0159 - val_loss: 0.0783\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0750\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0750\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0764\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0760\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0158 - val_loss: 0.0756\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0159 - val_loss: 0.0747\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0155 - val_loss: 0.0754\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0759\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0761\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0155 - val_loss: 0.0759\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0767\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0753\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0768\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0752\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0159 - val_loss: 0.0759\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0156 - val_loss: 0.0752\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0156 - val_loss: 0.0777\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0158 - val_loss: 0.0753\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0157 - val_loss: 0.0771\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0158 - val_loss: 0.0754\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0753\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0750\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0758\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0757\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0156 - val_loss: 0.0760\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0154 - val_loss: 0.0750\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0156 - val_loss: 0.0755\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0771\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0750\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.0752\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0760\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0160 - val_loss: 0.0761\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0749\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0154 - val_loss: 0.0757\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0157 - val_loss: 0.0764\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.0155 - val_loss: 0.0748\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.0152 - val_loss: 0.0754\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.0755\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.0155 - val_loss: 0.0750\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.0767\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0778\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0152 - val_loss: 0.0747\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0154 - val_loss: 0.0764\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [20.72 20.72 20.72 20.54 20.28]\n",
            "Predicted_not_normlized [20.91 20.91 20.91 20.92 20.92]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.3131947\n",
            "MSE:  0.22887287\n",
            "RMSE:  0.478406590086781\n",
            "R2:  0.9737029075622559\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"SAUDI ELECTRICITY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxVz_uvnLCIU",
        "outputId": "3b2a6988-1a7e-47cb-8e39-f7751f35d504"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[12713900.   13733807.   37350652.   ...  1696735.8    909617.25\n",
            "  2446316.2 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[20073634.   9659883.   2466405.  ...  1372106.6  4646211.5  3383550.2]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '18.000413521171446' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.369999885559082' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "SPIMACO_BRNN_900\n",
            "SPIMACO_GRU_256\n",
            "SPIMACO_LSTM_600\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0870\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0871\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0862\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0862\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0868\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0899\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0856\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0854\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0859\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0859\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0901\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0862\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0856\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0870\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0863\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0881\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0898\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0874\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0887\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0883\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0867\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0865\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0884\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0897\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0874\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0880\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0871\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0888\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0876\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0922\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0878\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0877\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0899\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0884\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0881\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0903\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0919\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0874\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0877\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0893\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0890\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0127 - val_loss: 0.0877\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0913\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0869\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0876\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0877\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0879\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0873\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0869\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0880\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0914\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0885\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0884\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0879\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0878\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0891\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0900\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0914\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0885\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0881\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0888\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0906\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0880\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0873\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0915\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0898\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0885\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0908\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0887\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0895\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0881\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0111 - val_loss: 0.0900\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0908\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0879\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0890\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0891\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0879\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0900\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0880\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0874\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0904\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0894\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0888\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0889\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0901\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0911\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0889\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0899\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0915\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0908\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0917\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0903\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0881\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0892\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0889\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0897\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0893\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0880\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0920\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0892\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.08 26.09 26.08 26.07 26.11]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.3769114\n",
            "MSE:  0.30748814\n",
            "RMSE:  0.5545161345209545\n",
            "R2:  0.9747623801231384\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 6ms/step - loss: 0.1276 - val_loss: 0.0870\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0126 - val_loss: 0.0863\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0862\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0890\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0861\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0853\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0863\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0862\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0873\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0909\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0902\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0865\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0880\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0871\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0878\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0864\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0872\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0893\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0870\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0896\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0871\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0876\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0865\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0873\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0860\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0879\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0873\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0871\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0870\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0118 - val_loss: 0.0883\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0888\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0881\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0876\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0878\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0895\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0863\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0867\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0870\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0891\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0887\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0887\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0872\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0896\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0940\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0931\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0898\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0889\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0893\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0890\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0888\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0901\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0897\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0900\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0884\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0891\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0868\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0886\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0892\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0128 - val_loss: 0.0898\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0879\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0880\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0884\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0890\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0885\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0899\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0878\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0927\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0906\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0902\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0893\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0883\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0884\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0877\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0874\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0879\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0898\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0879\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0898\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0893\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0887\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0894\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0889\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0884\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0886\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0889\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0897\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0901\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0121 - val_loss: 0.0883\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0886\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0886\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0896\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0934\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0904\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0944\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0893\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0880\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0886\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0908\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0889\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0882\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.14 26.11 26.09 26.1  26.1 ]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.36506793\n",
            "MSE:  0.28620157\n",
            "RMSE:  0.5349780990449501\n",
            "R2:  0.9765095114707947\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1182 - val_loss: 0.0859\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0868\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0859\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0873\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0860\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0845\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0854\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0849\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0862\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0854\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0856\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0849\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0854\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0854\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0845\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0840\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0118 - val_loss: 0.0860\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0846\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0857\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0866\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0860\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0861\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0864\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0855\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0852\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0852\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0856\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0852\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0858\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0850\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0864\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0848\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0855\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0905\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0866\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0864\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0849\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0853\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0872\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0854\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0935\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0863\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0851\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0857\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0892\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0871\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0879\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0875\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0877\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0878\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0866\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0923\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0879\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0899\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0857\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0881\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0882\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0910\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0866\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0880\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0901\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0875\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0894\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0883\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0896\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0870\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0902\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0896\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0898\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0106 - val_loss: 0.0920\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0894\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0109 - val_loss: 0.0884\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0131 - val_loss: 0.0889\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0891\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0883\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0124 - val_loss: 0.0892\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0892\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0885\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0882\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0891\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0913\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0912\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0885\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0878\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0896\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0884\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0887\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0883\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0897\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0880\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0905\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0864\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0884\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0882\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0881\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0904\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0889\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0899\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0886\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0880\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.1  26.16 26.13 26.14 26.06]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.3614451\n",
            "MSE:  0.29017857\n",
            "RMSE:  0.5386822506553347\n",
            "R2:  0.9761829972267151\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0824 - val_loss: 0.0876\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0902\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0901\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0884\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0881\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0883\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0882\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0873\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0871\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0880\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0883\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0874\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0889\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0884\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0905\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0895\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0875\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0890\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0874\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0868\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0908\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0878\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0907\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0887\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0894\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0871\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0870\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0882\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0889\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0908\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0873\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0893\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0877\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0890\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0875\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0877\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0882\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0885\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0889\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0872\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0869\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0877\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0901\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0909\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0865\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0883\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0864\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0867\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0870\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0894\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0873\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0882\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0866\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0876\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0889\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0889\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0111 - val_loss: 0.0914\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0864\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0896\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0877\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0870\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0874\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0872\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0886\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0877\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0872\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0928\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0885\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0887\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0867\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0876\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0878\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0871\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0880\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0872\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0878\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0883\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0882\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0869\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0885\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0110 - val_loss: 0.0882\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0884\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0109 - val_loss: 0.0877\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0888\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0880\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0872\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0883\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0874\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0898\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0879\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0891\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0875\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0883\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0876\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0881\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0886\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0877\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0868\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.18 26.19 26.21 26.2  26.2 ]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.35895473\n",
            "MSE:  0.27799177\n",
            "RMSE:  0.5272492500686919\n",
            "R2:  0.9771832823753357\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 6s 24ms/step - loss: 0.1513 - val_loss: 0.2610\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0121 - val_loss: 0.1604\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.1397\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0124 - val_loss: 0.1300\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0120 - val_loss: 0.1217\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.1136\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0148 - val_loss: 0.1070\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0125 - val_loss: 0.1024\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0130 - val_loss: 0.1037\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.1030\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0116 - val_loss: 0.0949\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0120 - val_loss: 0.1035\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0123 - val_loss: 0.0927\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0121 - val_loss: 0.1026\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0122 - val_loss: 0.0954\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0123 - val_loss: 0.0918\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0981\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.0909\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0889\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0120 - val_loss: 0.0935\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0127 - val_loss: 0.0907\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0135 - val_loss: 0.0891\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0120 - val_loss: 0.0895\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0854\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0908\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0896\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0118 - val_loss: 0.0863\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0875\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0113 - val_loss: 0.0878\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0123 - val_loss: 0.0857\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0115 - val_loss: 0.0870\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0112 - val_loss: 0.0866\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0115 - val_loss: 0.0858\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0114 - val_loss: 0.0852\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0119 - val_loss: 0.0883\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0120 - val_loss: 0.0882\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0892\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0894\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0118 - val_loss: 0.0879\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0865\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0112 - val_loss: 0.0867\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0110 - val_loss: 0.0864\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0109 - val_loss: 0.0874\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0868\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0890\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0865\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0113 - val_loss: 0.0897\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0880\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0111 - val_loss: 0.0879\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0107 - val_loss: 0.0885\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0118 - val_loss: 0.0866\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0893\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0900\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0883\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0892\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0107 - val_loss: 0.0891\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0107 - val_loss: 0.0906\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0111 - val_loss: 0.0870\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0864\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0874\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0892\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0111 - val_loss: 0.0880\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0116 - val_loss: 0.0882\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0105 - val_loss: 0.0872\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0886\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0880\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0869\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0873\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0107 - val_loss: 0.0864\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0110 - val_loss: 0.0902\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0107 - val_loss: 0.0877\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0888\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0881\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0902\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0897\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0915\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0106 - val_loss: 0.0876\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0106 - val_loss: 0.0883\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0882\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0873\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0911\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0104 - val_loss: 0.0889\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0102 - val_loss: 0.0882\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0107 - val_loss: 0.0877\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0105 - val_loss: 0.0892\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0874\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0881\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0889\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0889\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0106 - val_loss: 0.0900\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0104 - val_loss: 0.0876\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0105 - val_loss: 0.0894\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0104 - val_loss: 0.0878\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0894\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0102 - val_loss: 0.0889\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0887\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0884\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0107 - val_loss: 0.0868\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0869\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.12 26.14 26.14 26.16 26.16]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.35347813\n",
            "MSE:  0.27688533\n",
            "RMSE:  0.5261989459102255\n",
            "R2:  0.9772740602493286\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 5s 20ms/step - loss: 0.1495 - val_loss: 0.1963\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0124 - val_loss: 0.1582\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0122 - val_loss: 0.1612\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.1419\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0145 - val_loss: 0.1491\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0141 - val_loss: 0.1379\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0126 - val_loss: 0.1413\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0130 - val_loss: 0.1178\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0120 - val_loss: 0.1156\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0118 - val_loss: 0.1116\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.1063\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0157 - val_loss: 0.1150\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0121 - val_loss: 0.0997\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.1065\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0118 - val_loss: 0.1026\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.0125 - val_loss: 0.1015\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0125 - val_loss: 0.0967\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0121 - val_loss: 0.0948\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.0983\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0117 - val_loss: 0.0977\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0117 - val_loss: 0.0946\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0118 - val_loss: 0.0912\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0118 - val_loss: 0.0965\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0123 - val_loss: 0.0966\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0886\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.0997\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0949\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0134 - val_loss: 0.0956\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0139 - val_loss: 0.0911\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0121 - val_loss: 0.0895\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0117 - val_loss: 0.0934\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.0901\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0894\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0871\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.0921\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0115 - val_loss: 0.0921\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0112 - val_loss: 0.0899\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0114 - val_loss: 0.0873\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0116 - val_loss: 0.0870\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.0878\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0891\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0905\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0117 - val_loss: 0.0879\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0116 - val_loss: 0.0894\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0114 - val_loss: 0.0867\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0123 - val_loss: 0.0866\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0117 - val_loss: 0.0873\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0884\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.0869\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0116 - val_loss: 0.0886\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0118 - val_loss: 0.0890\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0117 - val_loss: 0.0888\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.0867\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0885\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0882\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0877\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0114 - val_loss: 0.0872\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0120 - val_loss: 0.0871\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0112 - val_loss: 0.0863\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0866\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0888\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0113 - val_loss: 0.0869\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0868\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0109 - val_loss: 0.0907\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0114 - val_loss: 0.0883\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0115 - val_loss: 0.0902\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.0867\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0872\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0112 - val_loss: 0.0864\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0901\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0111 - val_loss: 0.0863\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.0111 - val_loss: 0.0867\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0112 - val_loss: 0.0865\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0869\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0875\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0860\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0113 - val_loss: 0.0858\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0110 - val_loss: 0.0865\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0868\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0869\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0116 - val_loss: 0.0859\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0871\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0869\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0113 - val_loss: 0.0883\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0113 - val_loss: 0.0856\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0916\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0864\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0114 - val_loss: 0.0883\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0867\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.0862\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0865\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0111 - val_loss: 0.0874\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0877\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0864\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0867\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0880\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0109 - val_loss: 0.0873\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0880\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0113 - val_loss: 0.0870\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.08 26.11 26.13 26.13 26.16]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.36231822\n",
            "MSE:  0.27970397\n",
            "RMSE:  0.5288704706483582\n",
            "R2:  0.9770427942276001\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 15ms/step - loss: 0.1638 - val_loss: 0.1574\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0115 - val_loss: 0.1333\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0118 - val_loss: 0.1446\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0117 - val_loss: 0.1158\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0114 - val_loss: 0.1164\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0134 - val_loss: 0.1157\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0122 - val_loss: 0.1092\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0123 - val_loss: 0.1114\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0112 - val_loss: 0.1016\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0118 - val_loss: 0.1071\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0114 - val_loss: 0.1066\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.0114 - val_loss: 0.1004\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0125 - val_loss: 0.0980\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.1035\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0117 - val_loss: 0.1032\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0993\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0114 - val_loss: 0.0919\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0116 - val_loss: 0.0883\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0116 - val_loss: 0.0963\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0127 - val_loss: 0.0965\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0125 - val_loss: 0.0906\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0117 - val_loss: 0.0921\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0901\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0127 - val_loss: 0.0873\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0106 - val_loss: 0.0901\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0109 - val_loss: 0.0909\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0887\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0116 - val_loss: 0.0870\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0109 - val_loss: 0.0872\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0902\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0116 - val_loss: 0.0867\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0851\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0106 - val_loss: 0.0859\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0869\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0862\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0870\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0866\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0852\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0119 - val_loss: 0.0875\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0120 - val_loss: 0.0882\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0110 - val_loss: 0.0871\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0866\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0863\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0129 - val_loss: 0.0862\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0113 - val_loss: 0.0852\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0106 - val_loss: 0.0921\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.0113 - val_loss: 0.0855\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0852\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0112 - val_loss: 0.0854\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0870\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0858\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0102 - val_loss: 0.0878\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.0105 - val_loss: 0.0858\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0106 - val_loss: 0.0854\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0118 - val_loss: 0.0861\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0866\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0857\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0859\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0105 - val_loss: 0.0857\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0886\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0106 - val_loss: 0.0855\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0860\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0857\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0866\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0886\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0112 - val_loss: 0.0851\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0110 - val_loss: 0.0858\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0108 - val_loss: 0.0879\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0871\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0881\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0862\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0863\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0104 - val_loss: 0.0859\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0107 - val_loss: 0.0862\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0103 - val_loss: 0.0865\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0875\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0870\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0908\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0869\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0104 - val_loss: 0.0863\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0105 - val_loss: 0.0861\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0106 - val_loss: 0.0862\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0105 - val_loss: 0.0867\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0102 - val_loss: 0.0862\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0856\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0860\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0103 - val_loss: 0.0859\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0105 - val_loss: 0.0868\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0107 - val_loss: 0.0868\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0104 - val_loss: 0.0868\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0850\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0863\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0104 - val_loss: 0.0871\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0104 - val_loss: 0.0860\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0105 - val_loss: 0.0855\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0856\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0857\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0871\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0863\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0878\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.03 26.06 26.07 26.06 26.01]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.38260156\n",
            "MSE:  0.30609435\n",
            "RMSE:  0.5532579402327937\n",
            "R2:  0.9748766422271729\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_11 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 14ms/step - loss: 0.1733 - val_loss: 0.2160\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0129 - val_loss: 0.1804\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.0116 - val_loss: 0.1706\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0118 - val_loss: 0.1528\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0111 - val_loss: 0.1432\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.1426\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.1200\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0129 - val_loss: 0.1362\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0119 - val_loss: 0.1234\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0125 - val_loss: 0.1300\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0113 - val_loss: 0.1240\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0117 - val_loss: 0.1285\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0118 - val_loss: 0.1087\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0124 - val_loss: 0.1155\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0117 - val_loss: 0.1182\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0151 - val_loss: 0.0985\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0132 - val_loss: 0.1037\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0111 - val_loss: 0.0992\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0110 - val_loss: 0.0953\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.1013\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0116 - val_loss: 0.1009\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0120 - val_loss: 0.1129\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0951\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0125 - val_loss: 0.0964\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0123 - val_loss: 0.1084\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0122 - val_loss: 0.0946\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0134 - val_loss: 0.0885\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0940\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0924\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0889\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0911\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0115 - val_loss: 0.0905\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0129 - val_loss: 0.1001\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0116 - val_loss: 0.0904\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0903\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0889\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0888\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0910\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0113 - val_loss: 0.0926\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0119 - val_loss: 0.0874\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0111 - val_loss: 0.0897\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0877\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0111 - val_loss: 0.0902\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0911\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0882\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0909\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0113 - val_loss: 0.0894\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0113 - val_loss: 0.0881\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0115 - val_loss: 0.0895\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0112 - val_loss: 0.0894\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0873\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.0883\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0882\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0876\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0113 - val_loss: 0.0917\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0111 - val_loss: 0.0883\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0868\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0877\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0895\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0904\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0889\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0881\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0111 - val_loss: 0.0877\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0109 - val_loss: 0.0901\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0893\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0889\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0868\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0903\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0883\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0110 - val_loss: 0.0872\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0107 - val_loss: 0.0873\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0110 - val_loss: 0.0875\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0874\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0900\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0866\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0890\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0878\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0108 - val_loss: 0.0889\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0114 - val_loss: 0.0867\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0887\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0900\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0877\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0874\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0105 - val_loss: 0.0891\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.0107 - val_loss: 0.0883\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0111 - val_loss: 0.0875\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0113 - val_loss: 0.0888\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0878\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0887\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0883\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0884\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0108 - val_loss: 0.0880\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.0109 - val_loss: 0.0871\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0106 - val_loss: 0.0875\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0867\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0902\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0871\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.0109 - val_loss: 0.0873\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.0108 - val_loss: 0.0873\n",
            "36/36 [==============================] - 1s 6ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.13 26.12 26.11 26.13 26.16]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.3568886\n",
            "MSE:  0.2773283\n",
            "RMSE:  0.5266197037682916\n",
            "R2:  0.9772377014160156\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_8 (GRU)                 (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 13ms/step - loss: 0.1550 - val_loss: 0.0947\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0961\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.1089\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0983\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0118 - val_loss: 0.0941\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0115 - val_loss: 0.0937\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0119 - val_loss: 0.0937\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0121 - val_loss: 0.0896\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0907\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0119 - val_loss: 0.0962\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0920\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0119 - val_loss: 0.0912\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0115 - val_loss: 0.0912\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0130 - val_loss: 0.0897\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0125 - val_loss: 0.0899\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0115 - val_loss: 0.0991\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0110 - val_loss: 0.0873\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0111 - val_loss: 0.0904\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0117 - val_loss: 0.0914\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0925\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0887\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.0865\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0116 - val_loss: 0.0900\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0107 - val_loss: 0.0878\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0107 - val_loss: 0.0869\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0867\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0854\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0880\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0886\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0860\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0118 - val_loss: 0.0852\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0113 - val_loss: 0.0873\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0114 - val_loss: 0.0854\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0868\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0874\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0852\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0854\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0860\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0114 - val_loss: 0.0858\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0868\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0106 - val_loss: 0.0864\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0856\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0871\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0858\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0852\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0845\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0107 - val_loss: 0.0861\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0108 - val_loss: 0.0852\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0107 - val_loss: 0.0861\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0859\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0850\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0852\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0852\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0851\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0107 - val_loss: 0.0850\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0111 - val_loss: 0.0852\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0887\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0850\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0860\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0850\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0858\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0855\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0851\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0107 - val_loss: 0.0852\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0103 - val_loss: 0.0846\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0851\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0846\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0854\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0850\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0860\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0855\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0106 - val_loss: 0.0853\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0103 - val_loss: 0.0853\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0104 - val_loss: 0.0853\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0860\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0103 - val_loss: 0.0852\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0862\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0864\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0859\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0854\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0104 - val_loss: 0.0866\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0103 - val_loss: 0.0855\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0103 - val_loss: 0.0862\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0867\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0860\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.0867\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0854\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0103 - val_loss: 0.0852\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0102 - val_loss: 0.0856\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0105 - val_loss: 0.0854\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0103 - val_loss: 0.0885\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0854\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0856\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0102 - val_loss: 0.0868\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0875\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0866\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0103 - val_loss: 0.0864\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0103 - val_loss: 0.0874\n",
            "36/36 [==============================] - 1s 7ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.07 26.06 26.09 26.07 26.09]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.3535077\n",
            "MSE:  0.27937484\n",
            "RMSE:  0.5285592094319862\n",
            "R2:  0.9770697951316833\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_9 (GRU)                 (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 17ms/step - loss: 0.1236 - val_loss: 0.0896\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0928\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0153 - val_loss: 0.0919\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0120 - val_loss: 0.0919\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0124 - val_loss: 0.0921\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0125 - val_loss: 0.0890\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0121 - val_loss: 0.0947\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0124 - val_loss: 0.0922\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0125 - val_loss: 0.0906\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0127 - val_loss: 0.0900\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0124 - val_loss: 0.0887\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0130 - val_loss: 0.0912\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0119 - val_loss: 0.0883\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0903\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0123 - val_loss: 0.0901\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0122 - val_loss: 0.0898\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0120 - val_loss: 0.0933\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0121 - val_loss: 0.0876\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0117 - val_loss: 0.0934\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0119 - val_loss: 0.0889\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0115 - val_loss: 0.0901\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.0887\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0867\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0871\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0114 - val_loss: 0.0877\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0120 - val_loss: 0.0866\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0115 - val_loss: 0.0875\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.0112 - val_loss: 0.0867\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0119 - val_loss: 0.0880\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0121 - val_loss: 0.0871\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0879\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0879\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0879\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0120 - val_loss: 0.0869\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0120 - val_loss: 0.0865\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0114 - val_loss: 0.0874\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0120 - val_loss: 0.0878\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0115 - val_loss: 0.0861\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0863\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0863\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0868\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0117 - val_loss: 0.0864\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0114 - val_loss: 0.0868\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0114 - val_loss: 0.0864\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0114 - val_loss: 0.0865\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0876\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0119 - val_loss: 0.0880\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0864\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0859\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0867\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0112 - val_loss: 0.0872\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0113 - val_loss: 0.0860\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0871\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0114 - val_loss: 0.0861\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0877\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0117 - val_loss: 0.0863\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0117 - val_loss: 0.0887\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0113 - val_loss: 0.0862\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0860\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0869\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0110 - val_loss: 0.0864\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0110 - val_loss: 0.0862\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0875\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0864\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0119 - val_loss: 0.0877\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0864\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0861\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0863\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0110 - val_loss: 0.0872\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0110 - val_loss: 0.0866\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0113 - val_loss: 0.0870\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0861\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0866\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0867\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0869\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0865\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0109 - val_loss: 0.0869\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0113 - val_loss: 0.0862\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0115 - val_loss: 0.0875\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0870\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0868\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0867\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0871\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0863\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0111 - val_loss: 0.0866\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0111 - val_loss: 0.0868\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0111 - val_loss: 0.0862\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0870\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0108 - val_loss: 0.0865\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0864\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0109 - val_loss: 0.0863\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0108 - val_loss: 0.0864\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0115 - val_loss: 0.0865\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0111 - val_loss: 0.0881\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0868\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0879\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0869\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0108 - val_loss: 0.0867\n",
            "36/36 [==============================] - 1s 5ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.11 26.16 26.1  26.14 26.11]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.3526364\n",
            "MSE:  0.27598664\n",
            "RMSE:  0.5253443077120294\n",
            "R2:  0.9773479104042053\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_10 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 14ms/step - loss: 0.1273 - val_loss: 0.0938\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0926\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0934\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0900\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0117 - val_loss: 0.0893\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0113 - val_loss: 0.0937\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0119 - val_loss: 0.0888\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0110 - val_loss: 0.0903\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0934\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0111 - val_loss: 0.0870\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0119 - val_loss: 0.0875\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0880\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0887\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0107 - val_loss: 0.0903\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0111 - val_loss: 0.0907\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0116 - val_loss: 0.0859\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0871\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0865\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0115 - val_loss: 0.0863\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0113 - val_loss: 0.0879\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0861\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0861\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0107 - val_loss: 0.0861\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0106 - val_loss: 0.0864\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0854\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0862\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0857\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0859\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0109 - val_loss: 0.0851\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0856\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0109 - val_loss: 0.0857\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0852\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0112 - val_loss: 0.0855\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0848\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0855\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0856\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0848\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0850\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0865\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0110 - val_loss: 0.0848\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0105 - val_loss: 0.0861\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0108 - val_loss: 0.0866\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0105 - val_loss: 0.0852\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0868\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0856\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0851\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0846\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0112 - val_loss: 0.0848\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0848\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0107 - val_loss: 0.0848\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0847\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0861\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0844\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0848\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0850\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0853\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0846\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0106 - val_loss: 0.0860\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0850\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0848\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0103 - val_loss: 0.0850\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0103 - val_loss: 0.0850\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0847\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0104 - val_loss: 0.0865\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0111 - val_loss: 0.0850\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0845\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0852\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0851\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0103 - val_loss: 0.0854\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0108 - val_loss: 0.0847\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0104 - val_loss: 0.0843\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0852\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0850\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0846\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0845\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0853\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0848\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0105 - val_loss: 0.0849\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0103 - val_loss: 0.0847\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0852\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0850\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0856\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0103 - val_loss: 0.0847\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0102 - val_loss: 0.0854\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0849\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.0846\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0854\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0844\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0105 - val_loss: 0.0847\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0103 - val_loss: 0.0847\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0103 - val_loss: 0.0848\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0844\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0845\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0102 - val_loss: 0.0856\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0103 - val_loss: 0.0850\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0847\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0849\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0102 - val_loss: 0.0853\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0851\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0103 - val_loss: 0.0854\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.09 26.09 26.07 26.08 26.09]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.35286087\n",
            "MSE:  0.27699453\n",
            "RMSE:  0.5263026946408891\n",
            "R2:  0.9772651195526123\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_11 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1035 - val_loss: 0.0905\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0122 - val_loss: 0.0912\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0112 - val_loss: 0.0914\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0126 - val_loss: 0.0925\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0118 - val_loss: 0.0936\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0117 - val_loss: 0.0905\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0946\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0124 - val_loss: 0.0915\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0114 - val_loss: 0.0895\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0113 - val_loss: 0.0915\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0116 - val_loss: 0.0913\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0896\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0910\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0122 - val_loss: 0.0928\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0903\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0115 - val_loss: 0.0890\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0113 - val_loss: 0.0893\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0111 - val_loss: 0.0894\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0113 - val_loss: 0.0909\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0888\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0892\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0884\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0110 - val_loss: 0.0878\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0878\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0114 - val_loss: 0.0878\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0114 - val_loss: 0.0884\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0882\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0871\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0877\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0877\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0875\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0873\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0109 - val_loss: 0.0881\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0109 - val_loss: 0.0870\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0112 - val_loss: 0.0876\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0111 - val_loss: 0.0872\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0113 - val_loss: 0.0867\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0872\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0874\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0869\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0107 - val_loss: 0.0869\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0113 - val_loss: 0.0873\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0111 - val_loss: 0.0871\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0876\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0866\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0867\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0866\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0869\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0865\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0115 - val_loss: 0.0880\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0871\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0110 - val_loss: 0.0869\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0109 - val_loss: 0.0867\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0873\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0870\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0886\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0871\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0866\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0867\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0110 - val_loss: 0.0885\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0109 - val_loss: 0.0878\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0874\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0109 - val_loss: 0.0870\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0105 - val_loss: 0.0871\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0865\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0869\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0118 - val_loss: 0.0876\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0872\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0113 - val_loss: 0.0866\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0876\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0867\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0103 - val_loss: 0.0871\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0104 - val_loss: 0.0867\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0883\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0873\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0868\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0108 - val_loss: 0.0872\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0865\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0106 - val_loss: 0.0865\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0104 - val_loss: 0.0869\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0108 - val_loss: 0.0870\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0868\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0876\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0107 - val_loss: 0.0880\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0876\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0877\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0873\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0874\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0111 - val_loss: 0.0869\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0105 - val_loss: 0.0866\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0109 - val_loss: 0.0874\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0107 - val_loss: 0.0868\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0868\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0875\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0105 - val_loss: 0.0871\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0872\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0871\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0104 - val_loss: 0.0870\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0106 - val_loss: 0.0864\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [25.85 25.85 25.85 26.35 26.25]\n",
            "Predicted_not_normlized [26.22 26.21 26.22 26.22 26.23]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.35904852\n",
            "MSE:  0.27643508\n",
            "RMSE:  0.5257709360457262\n",
            "R2:  0.9773109555244446\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"SPIMACO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G90maKmHLCIU",
        "outputId": "3e91651a-3ae2-42ba-c7fe-b89fb1b633bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.9316651e+08 2.8920675e+08 1.8334110e+08 ... 9.4469936e+07 8.9680896e+07\n",
            " 5.9570704e+07]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[6.6367450e+08 7.2399955e+08 1.6893843e+08 ... 1.1727689e+08 9.4607304e+07\n",
            " 1.0791855e+08]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '52.75059357527347' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "<ipython-input-6-81f741971fba>:115: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '10.416666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['vidya'] = ta.vidya(company['close'],length=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (4724, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (4714, 5, 34)\n",
            "y shape: (4714, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "STC_BRNN_1024\n",
            "STC_GRU_729\n",
            "STC_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 2s 4ms/step - loss: 0.0591 - val_loss: 0.0784\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0814\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0770\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0788\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0771\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0767\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0766\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0766\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0765\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0763\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0766\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0766\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0775\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0765\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0771\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0771\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0761\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0761\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0758\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0761\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0781\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0780\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0778\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0764\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0762\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0776\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0763\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0757\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0755\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0770\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0778\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0099 - val_loss: 0.0759\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0779\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0759\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0757\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0767\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0759\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0777\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0763\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0757\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0759\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0756\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0756\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0754\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0755\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0757\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0755\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.0092 - val_loss: 0.0757\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0762\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0763\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0763\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0758\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0765\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0758\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0759\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0760\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0763\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0089 - val_loss: 0.0763\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.05 106.96 106.92 107.14 107.25]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  1.2496223\n",
            "MSE:  3.7479606\n",
            "RMSE:  1.9359650222755485\n",
            "R2:  0.9820157885551453\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 2s 4ms/step - loss: 0.0608 - val_loss: 0.0758\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0760\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0763\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0758\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0757\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0761\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0759\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0770\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0759\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0768\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0763\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0770\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0762\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0759\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0759\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0760\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0764\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0770\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0761\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0758\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0763\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0760\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0770\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0760\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0763\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0763\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0764\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0761\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0776\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0760\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0761\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0762\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0761\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0762\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0761\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0761\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0763\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0764\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0766\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0769\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0763\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0767\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0765\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0770\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.56 107.3  106.93 107.49 107.48]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  1.2681613\n",
            "MSE:  3.8256302\n",
            "RMSE:  1.9559218256331927\n",
            "R2:  0.9816430807113647\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 2s 6ms/step - loss: 0.0640 - val_loss: 0.0781\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0784\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0779\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0781\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0780\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0776\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0789\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0780\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0774\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0774\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0775\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0789\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0779\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0774\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0779\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0774\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0777\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0780\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0773\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0776\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0772\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0771\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0801\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0772\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0782\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0772\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0770\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0769\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0775\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0770\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0773\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0771\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0776\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0768\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0773\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0783\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0771\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0767\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0770\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0766\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0765\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0764\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.01 106.9  106.86 106.91 107.03]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  1.2579693\n",
            "MSE:  3.7385297\n",
            "RMSE:  1.9335277815845895\n",
            "R2:  0.982060968875885\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 2s 4ms/step - loss: 0.0983 - val_loss: 0.0792\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0786\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0804\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0804\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0784\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0786\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0783\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0780\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0780\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0778\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0775\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0780\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0792\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0780\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0797\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0781\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0783\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0774\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0769\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0787\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0778\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0782\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0769\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0767\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0773\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0777\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0768\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0762\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0764\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0763\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0766\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0758\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0772\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0759\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0756\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0755\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0758\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0761\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0759\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0757\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0759\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0760\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0752\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0755\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0753\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0755\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0761\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0752\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0764\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0750\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0750\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0749\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0753\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0751\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0754\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0751\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0753\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0750\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0745\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0747\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0750\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0752\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0748\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0747\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0757\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0748\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0751\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0750\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0744\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0753\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0751\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0748\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0760\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0757\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0751\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0745\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0746\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0752\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0750\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0750\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0755\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0758\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0751\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0746\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0747\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0760\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0746\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0746\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0749\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0751\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0751\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0762\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0746\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0742\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.49 107.4  107.47 107.2  107.3 ]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  1.2683823\n",
            "MSE:  3.823946\n",
            "RMSE:  1.9554912424108444\n",
            "R2:  0.981651246547699\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 5s 19ms/step - loss: 0.1173 - val_loss: 0.0998\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0100 - val_loss: 0.0885\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0861\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0846\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0822\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0803\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0811\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0097 - val_loss: 0.0810\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0094 - val_loss: 0.0795\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0101 - val_loss: 0.0793\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0792\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0781\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0783\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0798\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0100 - val_loss: 0.0787\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0097 - val_loss: 0.0785\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0097 - val_loss: 0.0787\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0799\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0792\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0781\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0784\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0784\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0095 - val_loss: 0.0778\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0776\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0790\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0093 - val_loss: 0.0774\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0784\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0796\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0771\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0793\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0774\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0094 - val_loss: 0.0776\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0094 - val_loss: 0.0769\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0778\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0772\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0088 - val_loss: 0.0768\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0767\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0771\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0780\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0780\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.07 107.09 107.24 107.14 107.42]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  1.2627113\n",
            "MSE:  3.8283322\n",
            "RMSE:  1.9566124260428377\n",
            "R2:  0.9816300272941589\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_21 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 12ms/step - loss: 0.1343 - val_loss: 0.1102\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0101 - val_loss: 0.0923\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0930\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0093 - val_loss: 0.0847\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0845\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0829\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0814\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0865\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0864\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0804\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0805\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0779\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0096 - val_loss: 0.0810\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0101 - val_loss: 0.0797\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0786\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0793\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0780\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0768\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0097 - val_loss: 0.0778\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0102 - val_loss: 0.0773\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0782\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0774\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0770\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0773\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0778\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0768\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0766\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0764\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0093 - val_loss: 0.0766\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0766\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0092 - val_loss: 0.0768\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0770\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0775\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0778\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0767\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0766\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 3s 21ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0768\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0770\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0094 - val_loss: 0.0765\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0099 - val_loss: 0.0767\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0089 - val_loss: 0.0767\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0091 - val_loss: 0.0768\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0771\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0088 - val_loss: 0.0779\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0093 - val_loss: 0.0769\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0769\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [106.85 106.81 106.71 106.83 107.07]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  1.2476088\n",
            "MSE:  3.7220802\n",
            "RMSE:  1.9292693515196084\n",
            "R2:  0.9821399450302124\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_22 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 4s 18ms/step - loss: 0.1583 - val_loss: 0.1175\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0105 - val_loss: 0.1034\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0098 - val_loss: 0.0921\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0880\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0880\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0856\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0850\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0882\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0098 - val_loss: 0.0838\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0848\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0099 - val_loss: 0.0836\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0101 - val_loss: 0.0819\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0796\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.0821\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0818\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0799\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0812\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0096 - val_loss: 0.0854\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0095 - val_loss: 0.0815\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0099 - val_loss: 0.0807\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0805\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0801\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0101 - val_loss: 0.0808\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0807\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0822\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0096 - val_loss: 0.0786\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0100 - val_loss: 0.0798\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0101 - val_loss: 0.0804\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0792\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0791\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0793\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0099 - val_loss: 0.0790\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0102 - val_loss: 0.0791\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0093 - val_loss: 0.0797\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0787\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0781\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0097 - val_loss: 0.0786\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0788\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0776\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0778\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0796\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0785\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0093 - val_loss: 0.0798\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0092 - val_loss: 0.0777\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0778\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0780\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0779\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0779\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0089 - val_loss: 0.0782\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0092 - val_loss: 0.0774\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0774\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.47 107.48 107.72 107.69 107.8 ]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  1.2829373\n",
            "MSE:  3.9422212\n",
            "RMSE:  1.985502748601313\n",
            "R2:  0.9810836911201477\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_23 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 13ms/step - loss: 0.1151 - val_loss: 0.1092\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0112 - val_loss: 0.0957\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0100 - val_loss: 0.0902\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0862\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0852\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0102 - val_loss: 0.0817\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0097 - val_loss: 0.0859\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0818\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0835\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0825\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0097 - val_loss: 0.0918\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0806\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0097 - val_loss: 0.0834\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0096 - val_loss: 0.0815\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0800\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0097 - val_loss: 0.0792\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0831\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0798\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0800\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0839\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0097 - val_loss: 0.0833\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0798\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0092 - val_loss: 0.0798\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0797\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0790\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0791\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0097 - val_loss: 0.0792\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0789\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0099 - val_loss: 0.0788\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0789\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0787\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0791\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0806\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0797\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0784\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0096 - val_loss: 0.0804\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0094 - val_loss: 0.0788\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 0.0094 - val_loss: 0.0783\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 0.0094 - val_loss: 0.0791\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0100 - val_loss: 0.0783\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0837\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0099 - val_loss: 0.0789\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0781\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0783\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0784\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0782\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0795\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0784\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0783\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0792\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0092 - val_loss: 0.0784\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0780\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0795\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0094 - val_loss: 0.0789\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0780\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0097 - val_loss: 0.0786\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 3s 19ms/step - loss: 0.0092 - val_loss: 0.0791\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0793\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0781\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0789\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0779\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [106.72 107.06 106.71 106.76 107.25]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  1.2884451\n",
            "MSE:  3.8774598\n",
            "RMSE:  1.969126650187994\n",
            "R2:  0.9813944101333618\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_20 (GRU)                (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 11ms/step - loss: 0.0924 - val_loss: 0.0791\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0804\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0792\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0097 - val_loss: 0.0806\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0097 - val_loss: 0.0789\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0792\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0790\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0792\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0096 - val_loss: 0.0808\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0791\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0801\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0094 - val_loss: 0.0794\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0098 - val_loss: 0.0815\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0790\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0797\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0094 - val_loss: 0.0789\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0782\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0787\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0784\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0779\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0778\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0784\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0784\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0786\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0780\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0778\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0783\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0776\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0773\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0774\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0775\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0778\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0087 - val_loss: 0.0777\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0777\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0787\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0777\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0785\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0088 - val_loss: 0.0772\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0781\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0776\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0778\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0777\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0775\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0777\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.51 107.51 107.31 107.11 107.37]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  1.278485\n",
            "MSE:  3.8437455\n",
            "RMSE:  1.9605472373924064\n",
            "R2:  0.9815561771392822\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_21 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 12ms/step - loss: 0.1056 - val_loss: 0.0786\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0791\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0791\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 3s 18ms/step - loss: 0.0095 - val_loss: 0.0795\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0789\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0096 - val_loss: 0.0783\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0778\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0778\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0096 - val_loss: 0.0786\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0100 - val_loss: 0.0780\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0784\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0791\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0094 - val_loss: 0.0793\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0788\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0776\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0094 - val_loss: 0.0780\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0773\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0772\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0093 - val_loss: 0.0774\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0774\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0775\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0771\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0782\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0767\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0768\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0769\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0775\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0772\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0771\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0771\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0091 - val_loss: 0.0769\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0772\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0771\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0770\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0769\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0768\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0770\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0776\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0772\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0775\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0773\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0779\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0770\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0771\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0779\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0772\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0773\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0088 - val_loss: 0.0778\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0776\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0775\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0774\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0775\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0773\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [106.93 106.73 106.48 106.59 106.58]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  1.258913\n",
            "MSE:  3.7269917\n",
            "RMSE:  1.9305418030807784\n",
            "R2:  0.9821163415908813\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_22 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 12ms/step - loss: 0.1135 - val_loss: 0.0800\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0796\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0094 - val_loss: 0.0799\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0795\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0802\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0802\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0096 - val_loss: 0.0821\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0094 - val_loss: 0.0820\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0788\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0802\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0094 - val_loss: 0.0801\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0791\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.0791\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0792\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0093 - val_loss: 0.0789\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0098 - val_loss: 0.0793\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0792\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0796\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0787\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0791\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0094 - val_loss: 0.0785\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0801\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.0787\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0786\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0795\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0092 - val_loss: 0.0784\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0787\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0783\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0092 - val_loss: 0.0795\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0785\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0792\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0788\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0791\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0794\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0781\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0784\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0786\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0784\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0780\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0089 - val_loss: 0.0783\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0787\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0790\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0786\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0783\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0786\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0781\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0787\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0787\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0092 - val_loss: 0.0782\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0784\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0791\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0089 - val_loss: 0.0785\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0089 - val_loss: 0.0785\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0788\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0796\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0786\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.0789\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0089 - val_loss: 0.0780\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0787\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0088 - val_loss: 0.0793\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0786\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0089 - val_loss: 0.0778\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0789\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0786\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.0780\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.45 107.27 107.73 107.89 107.64]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  1.2991844\n",
            "MSE:  3.9882836\n",
            "RMSE:  1.9970687605052038\n",
            "R2:  0.9808626174926758\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_23 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 5s 16ms/step - loss: 0.1228 - val_loss: 0.0820\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0810\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0808\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0099 - val_loss: 0.0812\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0814\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0804\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0809\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0801\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0097 - val_loss: 0.0827\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0805\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0096 - val_loss: 0.0802\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0804\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0802\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0094 - val_loss: 0.0794\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0798\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0800\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0798\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0096 - val_loss: 0.0798\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0098 - val_loss: 0.0798\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0821\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0092 - val_loss: 0.0798\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0798\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0793\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0791\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0807\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0795\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0793\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0093 - val_loss: 0.0791\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0797\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0794\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0790\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0793\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0796\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0796\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0789\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0787\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0096 - val_loss: 0.0793\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0789\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0790\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0094 - val_loss: 0.0788\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0093 - val_loss: 0.0787\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0788\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0787\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0089 - val_loss: 0.0783\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0788\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0093 - val_loss: 0.0787\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0795\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0782\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0092 - val_loss: 0.0788\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0784\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 17ms/step - loss: 0.0091 - val_loss: 0.0788\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0802\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0093 - val_loss: 0.0791\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0789\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0785\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0093 - val_loss: 0.0786\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0090 - val_loss: 0.0782\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0091 - val_loss: 0.0780\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0783\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0785\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0784\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0786\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0785\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0091 - val_loss: 0.0782\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0091 - val_loss: 0.0779\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0093 - val_loss: 0.0778\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0090 - val_loss: 0.0783\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0781\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0778\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0091 - val_loss: 0.0781\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0777\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0780\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0776\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 3s 17ms/step - loss: 0.0089 - val_loss: 0.0774\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.0090 - val_loss: 0.0779\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [104.2 104.2 104.2 105.  102.6]\n",
            "Predicted_not_normlized [107.14 107.43 107.75 108.07 107.9 ]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  1.3170625\n",
            "MSE:  4.0706415\n",
            "RMSE:  2.017583088162458\n",
            "R2:  0.9804673790931702\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"STC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPpKJYyULCIV",
        "outputId": "8ad8e899-3c0a-489e-c53e-655d361e5f7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return rn / rd\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
            "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
            "/usr/local/lib/python3.10/dist-packages/pandas_ta/overlap/linreg.py:53: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return rn / rd\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:35: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  company['decay'] = ta.decay(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['ebsw'] = ta.ebsw(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['hwm'],company['hwu'],company['hwl'] = ta.hwc(company['close'])\n",
            "<ipython-input-6-81f741971fba>:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['jma'] = ta.jma(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  840945.6  9626038.   7505411.5 ... 17834854.  21154470.  16853946. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[  490900.94  1736300.    2911981.8  ... 26082650.   21951994.\n",
            " 12363582.  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  company['mfi'] = ta.mfi(high=company['high'],low= company['low'],close=company['close'],volume=company['volume_traded '],length=5)\n",
            "<ipython-input-6-81f741971fba>:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.538689886576379' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  company['ssf'] = ta.ssf(company['close'],length=5)\n",
            "<ipython-input-6-81f741971fba>:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  company['stc'],company['stc_macd'],company['stc_stoch'] = ta.stc(company['close'],tclength=5)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (5114, 34), Val shape: (366, 34), Test shape: (1160, 34)\n",
            "*******************************************\n",
            "Train data after multistep approach\n",
            "X shape: (5104, 5, 34)\n",
            "y shape: (5104, 5)\n",
            "Validation multistep approach\n",
            "X shape: (356, 5, 34)\n",
            "y shape: (356, 5)\n",
            "Test multistep approach\n",
            "X shape: (1150, 5, 34)\n",
            "y shape: (1150, 5)\n",
            "**********Models Order***************\n",
            "TASNEE_BRNN_1024\n",
            "TASNEE_GRU_512\n",
            "TASNEE_LSTM_1024\n",
            "*************************************\n",
            "Loaded 3 models\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 15)                0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12549 (49.02 KB)\n",
            "Trainable params: 12549 (49.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 4ms/step - loss: 0.0805 - val_loss: 0.0290\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0277\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0321\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0271\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0272\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0277\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0290\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0278\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0263\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0263\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0262\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0262\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0263\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0260\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0264\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0277\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0275\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0268\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0261\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0275\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0262\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0263\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0259\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0264\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0284\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0285\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0260\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0314\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0262\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0304\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0263\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0260\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0272\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0278\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0277\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0280\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0278\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.15 13.11 13.06 13.06 13.02]\n",
            "*************Prposed ANN of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.31030083\n",
            "MSE:  0.19483234\n",
            "RMSE:  0.4413981647932518\n",
            "R2:  0.9731305241584778\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 6ms/step - loss: 0.0649 - val_loss: 0.0272\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0300\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0269\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0275\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0273\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0285\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0274\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0267\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0280\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0283\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0264\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0276\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0287\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0291\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0260\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0289\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0262\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0276\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0277\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0273\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0261\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0315\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0272\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0282\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0284\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0290\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0300\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0283\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0274\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0283\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0280\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0276\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0281\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0278\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [12.98 13.04 13.03 13.05 13.08]\n",
            "*************Prposed ANN of ['BRNN', 'GRU']**********\n",
            "MAE:  0.31968337\n",
            "MSE:  0.20153813\n",
            "RMSE:  0.4489299841188864\n",
            "R2:  0.972205638885498\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0270\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0275\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0281\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0272\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0295\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0275\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0265\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0275\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0275\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0275\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0270\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0281\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0285\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0288\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0274\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0277\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0270\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0270\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0278\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0278\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0278\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0273\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0277\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0278\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0279\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0280\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0284\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0276\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0277\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0283\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0278\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0287\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0278\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0286\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0282\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0290\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0278\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0280\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0312\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0273\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0293\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0281\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0287\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0285\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0297\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.14 13.15 13.15 13.14 13.13]\n",
            "*************Prposed ANN of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.31570944\n",
            "MSE:  0.19977404\n",
            "RMSE:  0.4469608951260599\n",
            "R2:  0.9724489450454712\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11909 (46.52 KB)\n",
            "Trainable params: 11909 (46.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0690 - val_loss: 0.0308\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0275\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0270\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0271\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0271\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0282\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0284\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0274\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0282\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0292\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0267\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0270\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0293\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0272\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0288\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0269\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0275\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0285\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0270\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0273\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0272\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0311\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0267\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0269\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0279\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0292\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0271\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0277\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0262\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0276\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0263\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0275\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0263\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0272\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0267\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0279\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0265\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0263\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0275\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0272\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0264\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0262\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0268\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0264\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0274\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0276\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0261\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0262\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0262\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0071 - val_loss: 0.0265\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0261\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0264\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0262\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0260\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0260\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0261\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0259\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0260\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0260\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0262\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0266\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0300\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0264\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0266\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0259\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0259\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.21 13.19 13.2  13.2  13.18]\n",
            "*************Prposed ANN of ['GRU', 'LSTM']**********\n",
            "MAE:  0.3105739\n",
            "MSE:  0.19514148\n",
            "RMSE:  0.4417482081151866\n",
            "R2:  0.9730877876281738\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68229 (266.52 KB)\n",
            "Trainable params: 68229 (266.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 14ms/step - loss: 0.1096 - val_loss: 0.0302\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0074 - val_loss: 0.0271\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0076 - val_loss: 0.0280\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0272\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0281\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0075 - val_loss: 0.0265\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0073 - val_loss: 0.0272\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0073 - val_loss: 0.0269\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0276\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0073 - val_loss: 0.0265\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0272\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0071 - val_loss: 0.0269\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0080 - val_loss: 0.0275\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0067 - val_loss: 0.0273\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0071 - val_loss: 0.0263\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0261\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0280\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0279\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0289\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0263\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0281\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0261\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0276\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0066 - val_loss: 0.0279\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0263\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0276\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0263\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0065 - val_loss: 0.0276\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0278\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0284\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0280\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0275\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0267\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0267\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0281\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.18 13.17 13.17 13.16 13.17]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.31636685\n",
            "MSE:  0.19916262\n",
            "RMSE:  0.44627639118127543\n",
            "R2:  0.9725332260131836\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_17 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 13ms/step - loss: 0.1049 - val_loss: 0.0306\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0074 - val_loss: 0.0287\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0072 - val_loss: 0.0265\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0075 - val_loss: 0.0264\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0285\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0071 - val_loss: 0.0269\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0281\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0268\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0074 - val_loss: 0.0288\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0071 - val_loss: 0.0265\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0074 - val_loss: 0.0266\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0074 - val_loss: 0.0271\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0076 - val_loss: 0.0262\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0266\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0265\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0273\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0262\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0276\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0072 - val_loss: 0.0276\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0071 - val_loss: 0.0264\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0276\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0262\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0070 - val_loss: 0.0270\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0066 - val_loss: 0.0275\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0264\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0262\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0270\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0275\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0283\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0272\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0278\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0063 - val_loss: 0.0264\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0286\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0063 - val_loss: 0.0265\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0063 - val_loss: 0.0264\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0063 - val_loss: 0.0275\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.18 13.17 13.18 13.2  13.2 ]\n",
            "*************Prposed LSTM of ['BRNN', 'GRU']**********\n",
            "MAE:  0.3082486\n",
            "MSE:  0.19368155\n",
            "RMSE:  0.44009266411310716\n",
            "R2:  0.9732891321182251\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_18 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 18ms/step - loss: 0.1305 - val_loss: 0.0321\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0082 - val_loss: 0.0335\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0075 - val_loss: 0.0275\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0276\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0281\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0071 - val_loss: 0.0274\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0070 - val_loss: 0.0314\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0073 - val_loss: 0.0278\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0078 - val_loss: 0.0272\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0077 - val_loss: 0.0292\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0078 - val_loss: 0.0287\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0072 - val_loss: 0.0295\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0073 - val_loss: 0.0305\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0277\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0074 - val_loss: 0.0277\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0281\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0071 - val_loss: 0.0267\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0282\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0284\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0067 - val_loss: 0.0284\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0066 - val_loss: 0.0290\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0072 - val_loss: 0.0272\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0275\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0278\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0277\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0300\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0273\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0283\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0065 - val_loss: 0.0276\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0277\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0277\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0067 - val_loss: 0.0278\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0066 - val_loss: 0.0275\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0065 - val_loss: 0.0289\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0063 - val_loss: 0.0265\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0277\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0278\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "36/36 [==============================] - 1s 7ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.14 13.15 13.13 13.09 13.06]\n",
            "*************Prposed LSTM of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.31047654\n",
            "MSE:  0.19593056\n",
            "RMSE:  0.4426404358650904\n",
            "R2:  0.9729790091514587\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_19 (LSTM)              (None, 128)               67072     \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67717 (264.52 KB)\n",
            "Trainable params: 67717 (264.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 13ms/step - loss: 0.1340 - val_loss: 0.0350\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0078 - val_loss: 0.0288\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0071 - val_loss: 0.0277\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0270\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0071 - val_loss: 0.0280\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0073 - val_loss: 0.0277\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0073 - val_loss: 0.0272\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0080 - val_loss: 0.0275\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0073 - val_loss: 0.0267\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0070 - val_loss: 0.0267\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0072 - val_loss: 0.0279\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0074 - val_loss: 0.0271\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0075 - val_loss: 0.0279\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0075 - val_loss: 0.0277\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0077 - val_loss: 0.0267\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0073 - val_loss: 0.0268\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0073 - val_loss: 0.0265\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0075 - val_loss: 0.0270\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0074 - val_loss: 0.0276\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0072 - val_loss: 0.0270\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0079 - val_loss: 0.0312\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0076 - val_loss: 0.0266\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0071 - val_loss: 0.0269\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0071 - val_loss: 0.0267\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0070 - val_loss: 0.0267\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0074 - val_loss: 0.0267\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0072 - val_loss: 0.0267\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0074 - val_loss: 0.0271\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0076 - val_loss: 0.0270\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0071 - val_loss: 0.0272\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0069 - val_loss: 0.0274\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0263\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0072 - val_loss: 0.0296\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0282\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0265\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0071 - val_loss: 0.0265\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0073 - val_loss: 0.0267\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0072 - val_loss: 0.0269\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0070 - val_loss: 0.0272\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0270\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0070 - val_loss: 0.0272\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0280\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0270\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0287\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0070 - val_loss: 0.0270\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0264\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0283\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0285\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0069 - val_loss: 0.0263\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0281\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0278\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0280\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0280\n",
            "36/36 [==============================] - 0s 6ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.16 13.17 13.16 13.14 13.15]\n",
            "*************Prposed LSTM of ['GRU', 'LSTM']**********\n",
            "MAE:  0.31556335\n",
            "MSE:  0.19978563\n",
            "RMSE:  0.4469738637496577\n",
            "R2:  0.9724473357200623\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_16 (GRU)                (None, 128)               51072     \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51717 (202.02 KB)\n",
            "Trainable params: 51717 (202.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 0.0985 - val_loss: 0.0306\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0279\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0278\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0288\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0279\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0072 - val_loss: 0.0269\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0273\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0267\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0274\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0076 - val_loss: 0.0267\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0068 - val_loss: 0.0262\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0273\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0275\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0282\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0275\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0266\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0282\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0262\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0261\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0279\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0291\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0272\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0259\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0270\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0277\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0267\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0269\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0063 - val_loss: 0.0279\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0281\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0062 - val_loss: 0.0269\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0260\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0272\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.16 13.15 13.13 13.11 13.11]\n",
            "*************Prposed GRU of ['BRNN', 'GRU', 'LSTM']**********\n",
            "MAE:  0.30684507\n",
            "MSE:  0.19481994\n",
            "RMSE:  0.44138412082531625\n",
            "R2:  0.9731321334838867\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_17 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1175 - val_loss: 0.0292\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0072 - val_loss: 0.0270\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0073 - val_loss: 0.0275\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0070 - val_loss: 0.0262\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0071 - val_loss: 0.0267\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0263\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0072 - val_loss: 0.0265\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0278\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0285\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0276\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0276\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0287\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0290\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0066 - val_loss: 0.0280\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0071 - val_loss: 0.0280\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0066 - val_loss: 0.0261\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0277\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0283\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0268\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0261\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0263\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0267\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0063 - val_loss: 0.0261\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0275\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0263\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0264\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0283\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0268\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0266\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0262\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0276\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0274\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0262\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0266\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0261\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0263\n",
            "36/36 [==============================] - 0s 5ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.17 13.19 13.18 13.17 13.15]\n",
            "*************Prposed GRU of ['BRNN', 'GRU']**********\n",
            "MAE:  0.31124166\n",
            "MSE:  0.19737577\n",
            "RMSE:  0.4442699341431343\n",
            "R2:  0.9727796316146851\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_18 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.1046 - val_loss: 0.0293\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0273\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0279\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0072 - val_loss: 0.0289\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0276\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0071 - val_loss: 0.0270\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0283\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0280\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0266\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0068 - val_loss: 0.0274\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0274\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0284\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0065 - val_loss: 0.0275\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0271\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0293\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0269\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0272\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0273\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0281\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0277\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0281\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0274\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0272\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0266\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0271\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0269\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0270\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0274\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0280\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0265\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0274\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0063 - val_loss: 0.0270\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0266\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0271\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0270\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0274\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0275\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0268\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0269\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0282\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0275\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0269\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0273\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0064 - val_loss: 0.0264\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0275\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0278\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.0268\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0264\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0269\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0270\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0063 - val_loss: 0.0265\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0268\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0272\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0273\n",
            "36/36 [==============================] - 0s 4ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.21 13.17 13.16 13.15 13.14]\n",
            "*************Prposed GRU of ['BRNN', 'LSTM']**********\n",
            "MAE:  0.3086538\n",
            "MSE:  0.19615762\n",
            "RMSE:  0.44289684956783004\n",
            "R2:  0.9729477167129517\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_19 (GRU)                (None, 128)               50688     \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51333 (200.52 KB)\n",
            "Trainable params: 51333 (200.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 4s 13ms/step - loss: 0.0926 - val_loss: 0.0281\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0072 - val_loss: 0.0273\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0276\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0071 - val_loss: 0.0269\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0071 - val_loss: 0.0274\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0072 - val_loss: 0.0269\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0268\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0299\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0072 - val_loss: 0.0270\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0272\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0071 - val_loss: 0.0273\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0071 - val_loss: 0.0293\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0072 - val_loss: 0.0273\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0073 - val_loss: 0.0267\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0276\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0070 - val_loss: 0.0271\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0270\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0070 - val_loss: 0.0265\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0272\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0277\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0269\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0275\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0271\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0264\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0268\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0069 - val_loss: 0.0265\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0268\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0070 - val_loss: 0.0276\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0264\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0267\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0272\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.0266\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0069 - val_loss: 0.0267\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0070 - val_loss: 0.0264\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0273\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0273\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0068 - val_loss: 0.0266\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0068 - val_loss: 0.0279\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0267\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0269\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0284\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0068 - val_loss: 0.0265\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0270\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0269\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0279\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0267\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0268\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0265\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0066 - val_loss: 0.0265\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0264\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0266\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.0263\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0263\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0068 - val_loss: 0.0261\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0267\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0270\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0067 - val_loss: 0.0262\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0067 - val_loss: 0.0261\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0067 - val_loss: 0.0271\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0066 - val_loss: 0.0262\n",
            "36/36 [==============================] - 1s 6ms/step\n",
            "Actual [13.   13.   13.   13.26 13.1 ]\n",
            "Predicted_not_normlized [13.2  13.18 13.16 13.16 13.16]\n",
            "*************Prposed GRU of ['GRU', 'LSTM']**********\n",
            "MAE:  0.3137165\n",
            "MSE:  0.19934931\n",
            "RMSE:  0.4464855137340746\n",
            "R2:  0.9725074768066406\n"
          ]
        }
      ],
      "source": [
        "stacking_process(dataset,selected_companies_dic,\"TASNEE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x-SHYsfcWRmw",
        "mkibQhFkXVab",
        "1RxWj3V2c-ff",
        "IbHLvWAcK5wq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}